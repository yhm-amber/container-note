[src/gh]: https://github.com/kvcache-ai/ktransformers.git "(Apache-2.0) (Languages: Python 64.9%, C++ 21.3%, Cuda 6.7%, Vue 2.3%, HTML 1.2%, TypeScript 1.1%, Other 2.5%) A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations // 一个灵活的框架，用于体验前沿的 LLM 推理优化"
[site]: https://kvcache-ai.github.io/ktransformers/ "KTransformers, pronounced as Quick Transformers, is designed to enhance your 🤗 Transformers experience with advanced kernel optimizations and placement/parallelism strategies. // KTransformers，发音为 Quick Transformers，旨在通过高级内核优化和放置/并行策略来增强您的🤗 Transformers 体验。 /// KTransformers is a flexible, Python-centric framework designed with extensibility at its core. By implementing and injecting an optimized module with a single line of code, users gain access to a Transformers-compatible interface, RESTful APIs compliant with OpenAI and Ollama, and even a simplified ChatGPT-like web UI. // KTransformers 是一个以 Python 为中心的灵活框架，其核心设计理念是可扩展性。通过一行代码实现和注入优化模块，用户即可获得与 Transformers 兼容的接口、符合 OpenAI 和 Ollama 的 RESTful API，甚至还有简化版的 ChatGPT 类似网页 UI。 /// Our vision for KTransformers is to serve as a flexible platform for experimenting with innovative LLM inference optimizations. Please let us know if you need any other features. // 我们的愿景是让 KTransformers 成为一个灵活的平台，用于实验创新的 LLM 推理优化。如需其他功能，请告知我们。"
