[src/gh]: https://github.com/ray-project/ray.git "(Apache-2.0) (Languages: Python 73.8%, C++ 19.2%, Java 2.6%, TypeScript 1.5%, Starlark 1.4%, Cython 0.9%, Other 0.6%) Ray is an AI compute engine. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads. // Ray 是一个 AI 计算引擎。Ray 由一个核心分布式运行时和一组用于加速 ML 工作负载的 AI 库组成。 /// Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a set of AI libraries for simplifying ML compute: // Ray 是一个用于扩展 AI 和 Python 应用的统一框架。Ray 由一个核心分布式运行时和一组用于简化机器学习计算的 AI 库组成： ///: - Learn more about [Ray AI Libraries] (. {[.docs-latest]}: .../ray-air/getting-started.html): // 了解更多关于 Ray AI 库： /// - - Data (. {[.docs-latest]}: .../data/dataset.html): Scalable Datasets for ML // 数据：可扩展数据集用于机器学习 /// - - Train (. {[.docs-latest]}: .../train/train.html): Distributed Training // 训练：分布式训练 /// - - Tune (. {[.docs-latest]}: .../tune/index.html): Scalable Hyperparameter Tuning // 调优：可扩展超参数调优 /// - - RLlib (. {[.docs-latest]}: .../rllib/index.html): Scalable Reinforcement Learning // RLlib：可扩展强化学习 /// - - Serve (. {[.docs-latest]}: .../serve/index.html): Scalable and Programmable Serving // 服务：可扩展和可编程的服务 /// - Or more about [Ray Core] (. {[.docs-latest]}: .../ray-core/walkthrough.html) and its key abstractions: // 更多关于 Ray Core 及其关键抽象： /// - - Tasks (. {[.docs-latest]}: .../ray-core/tasks.html): Stateless functions executed in the cluster. // 任务：在集群中执行的无状态函数。 /// - - Actors (. {[.docs-latest]}: .../ray-core/actors.html): Stateful worker processes created in the cluster. // 角色：在集群中创建的有状态工作进程。 /// - - Objects (. {[.docs-latest]}: .../ray-core/objects.html): Immutable values accessible across the cluster. // 对象：跨集群不可变值。 /// - Learn more about Monitoring and Debugging: // 了解更多关于监控和调试： /// - - Monitor Ray apps and clusters with the [Ray Dashboard] (. {[.docs-latest]}: .../ray-core/ray-dashboard.html). // 使用 Ray 控制台监控 Ray 应用和集群。 /// - - Debug Ray apps with the [Ray Distributed Debugger] (. {[.docs-latest]}: .../ray-observability/ray-distributed-debugger.html). // 使用 Ray 分布式调试器调试 Ray 应用。 /// Ray runs on any machine, cluster, cloud provider, and Kubernetes, and features a growing [ecosystem of community integrations] (. {[.docs-latest]}: .../ray-overview/ray-libraries.html). // Ray 可在任何机器、集群、云服务提供商和 Kubernetes 上运行，并拥有不断增长的社区集成生态系统。"
[docs/.site]: https://docs.ray.io/ "(: from ray.train import ScalingConfig ;: from ray.train.torch import TorchTrainer) Ray Libraries // Ray 库 ///: Scale the entire ML pipeline from data ingest to model serving with high-level Python APIs that integrate with popular ecosystem frameworks. // 使用高级 Python API，从数据摄取到模型服务，扩展整个机器学习流程，并与流行的生态系统框架集成。 /// Ray Core // Ray 核心 ///: Scale generic Python code with simple, foundational primitives that enable a high degree of control for building distributed applications or custom platforms. // 使用简单的基础原语扩展通用 Python 代码，这些原语能够为构建分布式应用程序或自定义平台提供高度的控制。 /// Ray Clusters // Ray 集群 ///: Deploy a Ray cluster on AWS, GCP, Azure, or Kubernetes to seamlessly scale workloads for production. // 在 AWS、GCP、Azure 或 Kubernetes 上部署 Ray 集群，以无缝扩展生产工作负载。"
[cluster.docs/.docs-latest]: https://docs.ray.io/en/latest/cluster/getting-started.html "Ray enables seamless scaling of workloads from a laptop to a large cluster. While Ray works out of the box on single machines with just a call to ray.init, to run Ray applications on multiple nodes you must first deploy a Ray cluster. // Ray 能够无缝地将工作负载从笔记本电脑扩展到大型集群。虽然只需调用 ray.init 就可以在单机上立即使用 Ray，但要运行分布在多个节点上的 Ray 应用，你必须首先部署一个 Ray 集群。 /// A Ray cluster is a set of worker nodes connected to a common Ray head node. Ray clusters can be fixed-size, or they may autoscale up and down according to the resources requested by applications running on the cluster. // Ray 集群是一组连接到同一个 Ray 头节点的计算节点。Ray 集群可以是固定大小的，也可以根据集群上运行的应用请求的资源自动扩展或缩减。 /// Ray provides native cluster deployment support on the following technology stacks: // Ray 在以下技术栈上提供原生的集群部署支持： /// - On AWS and GCP. Community-supported Azure, Aliyun and vSphere integrations also exist. // 在 AWS 和 GCP 上。社区支持的 Azure、阿里云和 vSphere 集成也存在。 /// - On Kubernetes, via the officially supported KubeRay project. // 通过官方支持的 KubeRay 项目在 Kubernetes 上。 /// - On Anyscale, a fully managed Ray platform by the creators of Ray. You can either bring an existing AWS, GCP, Azure and Kubernetes clusters, or use the Anyscale hosted compute layer. // 在 Anyscale 上，这是一个由 Ray 创建者提供的完全托管的 Ray 平台。你可以选择使用现有的 AWS、GCP、Azure 和 Kubernetes 集群，或者使用 Anyscale 托管的计算层。 /// Advanced users may want to [deploy Ray manually](.../cluster/vms/user-guides/launching-clusters/on-premises.html#on-prem '(: pip install -U -- ray[default]) (:: ray start --head --port=6379) (:::: ray start --address=<head-node-address:port>)') or onto [platforms not listed here](.../cluster/vms/user-guides/community/index.html#ref-cluster-setup '(Yarn / Slurm / LSF / Spark Standalone cluster)'). // 高级用户可能希望手动部署 Ray 或部署到此处未列出的平台。 /// Multi-node Ray clusters are only supported on Linux. At your own risk, you may deploy Windows and OSX clusters by setting the environment variable RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER=1 during deployment. // 多节点 Ray 集群仅在 Linux 上受支持。在部署时，你可以通过设置环境变量 RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER=1 自行承担风险部署 Windows 和 OSX 集群。"
[site/io]: https://ray.io/ "The AI Compute Engine /// Ray is at the center of the world's most powerful AI platforms. It precisely orchestrates infrastructure for any distributed workload on any accelerator at any scale. // Ray 是世界上最强大 AI 平台的核心。它精确地协调任何规模下任何加速器上的任何分布式工作负载的基础设施。 /// Ray is Python-native, built by developers for developers. // Ray 是纯 Python 开发，由开发者为开发者构建。 /// - Parallel Python Code // 并行 Python 代码 ///: (. {[.docs-latest]}: .../ray-overview/) Ray is Python-native. Scale and distribute any Python code for use cases like simulation, backtesting, and more. // Ray 是纯 Python 开发的。可扩展和分发任何 Python 代码，用于模拟、回测等用例。 /// - Multi-Modal Data Processing // 多模态数据处理 ///: (. https://anyscale.com/product/library/ray-data) Process structured and unstructured data including images, videos, audio, and more. // 处理结构化和非结构化数据，包括图像、视频、音频等。 /// - Model Training // 模型训练 ///: (. https://anyscale.com/product/library/ray-train) Run distributed training, including Gen AI foundation models, time series models, and traditional AI / ML models like XGBoost at scale with 1 line of code.  And yes – it’s compatible with your framework of choice. // 使用一行代码即可大规模运行分布式训练，包括生成式 AI 基础模型、时间序列模型以及 XGBoost 等传统 AI/ML 模型。是的——它兼容您选择的框架。 /// - Model Serving // 模型服务 ///: (. https://anyscale.com/product/library/ray-serve) Deploy models and business logic - not instances. Ray Serve offers independent scaling and fractional resources to let you get the most of the models you deploy. Get support for any ML model – from LLMs to stable diffusion models to object detection models and beyond. // 部署模型和业务逻辑——而不是实例。Ray Serve 提供独立的扩展和分数资源，让您充分利用部署的模型。支持任何 ML 模型 —— 从 LLMs 到稳定扩散模型到目标检测模型等等。 /// - Batch Inference // 批量推理 ///: (. https://anyscale.com/use-case/llm-batch-inference) Leverage heterogeneous compute to streamline offline batch inference workflows. Use CPUs and GPUs in the same pipeline to increase utilization, fully saturate GPUs, and decrease costs. // 利用异构计算来简化离线批量推理工作流。在同一管道中使用 CPU 和 GPU 来提高利用率，充分饱和 GPU，并降低成本。 /// - Reinforcement Learning // 强化学习 ///: (. https://anyscale.com/product/library/ray-rllib) Run best-in-class reinforcement learning workflows. Ray RLlib supports production-level, highly distributed RL workloads while maintaining unified and simple APIs for a large variety of industry applications. // 运行一流的强化学习工作流。Ray RLlib 支持生产级、高度分布式 RL 工作负载，同时保持统一且简单的 API，适用于各种行业应用。 /// - Gen AI // 生成式 AI ///: (. {[.docs-latest]}: .../ray-overview/use-cases.html) Build end-to-end GenAI workflows with Ray. Ray supports multimodal models, RAG applications, and more. // 使用 Ray 构建端到端的生成式 AI 工作流。Ray 支持多模态模型、RAG 应用等。 /// - LLM Inference // LLM 推理 ///: (. https://anyscale.com/product/library/ray-llm) Serve Large Language Models and scale seamlessly with Ray. Ray's flexility to support any accelerator, any model, coupled with seamless scaling is built for LLM inference (online and batch). // 使用 Ray 服务大型语言模型并实现无缝扩展。Ray 的灵活性支持任何加速器、任何模型，结合无缝扩展功能，专为 LLM 推理（在线和批量）而设计。 /// - LLM Fine Tuning  LLM 微调 ///: (. https://anyscale.com/product/library/llmforge) From the framework behind ChatGPT, easily fine tune Large Language models at scale. // 源自 ChatGPT 的框架，轻松实现大规模的 Large Language 模型微调。 /// Key Concepts in Ray // Ray 中的关键概念 --- Ray is the AI Compute Engine designed to power your AI platform and optimize any workload at any scale. // Ray 是专为赋能您的 AI 平台而设计的 AI 计算引擎，可优化任何规模的工作负载。 /// - Core // 核心 --- Scale Python Code // 扩展 Python 代码 ///: (. {[.docs-latest]}: .../ray-core/walkthrough.html) Ray Core provides a small number of core primitives (i.e., tasks, actors, objects) for building and scaling distributed Python applications. // Ray Core 提供了少量核心原语（即任务、演员、对象），用于构建和扩展分布式 Python 应用程序。 /// - Ray Libraries // RAY 库 --- End-to-End AI Solutions // 端到端 AI 解决方案 ///: (. {[.docs-latest]}: .../ray-overview/index.html) Seamlessly scale any AI workload - including data processing, training, and serving - with Ray's high-level ML libraries for developers. // 无缝扩展任何 AI 工作负载——包括数据处理、训练和部署——使用 Ray 为开发者提供的高级 ML 库。 /// - Ecosystem & Tools // 生态系统与工具 --- A Full ML Ecosystem // 一个完整的机器学习生态系统 ///: (. {[.docs-latest]}: .../ray-overview/ray-libraries.html) Run end-to-end AI and ML workflows on Ray. Get easy-to-use tools to deploy Ray clusters, debug and optimize applications, and integrate with common tools and frameworks to build AI applications. // 在 Ray 上运行端到端的 AI 和 ML 工作流。获得易于使用的工具来部署 Ray 集群、调试和优化应用程序，并与常用工具和框架集成以构建 AI 应用。"
[pkg.pip/pypi]: https://pypi.org/project/ray/ "(: pip install -- ray) Ray provides a simple, universal API for building distributed applications. // Ray 提供了一个简单、通用的 API 用于构建分布式应用。 "
[discuss]: https://discuss.ray.io/
[twitter]: https://twitter.com/raydistributed
[try/anyscale.com]: https://anyscale.com/ray-on-anyscale
[knows_by]: https://modin.readthedocs.io "Modin uses Ray, Dask or Unidist to provide an effortless way to speed up your pandas notebooks, scripts, and libraries. Unlike other distributed DataFrame libraries, Modin provides seamless integration and compatibility with existing pandas code. Even using the DataFrame constructor is identical. // Modin 使用 Ray、Dask 或 Unidist 来提供一种轻松的方式，加速你的 pandas 笔记本、脚本和库。与其他分布式 DataFrame 库不同，Modin 提供了与现有 pandas 代码的无缝集成和兼容性。即使使用 DataFrame 构造函数也是完全相同的。"
