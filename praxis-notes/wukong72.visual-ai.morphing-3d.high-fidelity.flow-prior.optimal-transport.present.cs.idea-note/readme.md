[site/ghio]: https://visual-ai.github.io/wukong/ "Figure 1. High-fidelity textured 3D morphing of Wukong. Taking an image of Wukong (bottom left) as the source and an image of another character (bottom right) as the target, we demonstrate two types of textured 3D morphing by our method: (i) Purple arrows indicate texture-controlled morphing, where the geometric structure changes while preserving detailed textures from the source; (ii) Green arrows indicate textured 3D morphing guided by the target prompt. // 图 1. 悟空的超高清纹理 3D 变形。以悟空的图像（左下）为源图像，以另一位角色的图像（右下）为目标图像，我们通过该方法展示了两种类型的纹理 3D 变形：(i) 紫色箭头表示纹理控制变形，其中几何结构发生变化，同时保留源图像的详细纹理；(ii) 绿色箭头表示由目标提示引导的纹理 3D 变形。 ///  Figure 2. Architecture. Given a source and a target (image or text), we extract features using pretrained encoders and treat the condition tokens as empirical distributions. We compute their Wasserstein barycenter to obtain interpolated condition tokens. These are fed into a shared geometry flow model and texture flow model to generate 3D outputs at different α values, producing textured 3D morphs. The top-right shows our texture-controlled morphing branch, and the bottom-right illustrates the recursive initialization. // 图 2. 架构。给定一个源和一个目标（图像或文本），我们使用预训练的编码器提取特征，并将条件标记视为经验分布。我们计算它们的 Wasserstein 中心以获得插值条件标记。这些标记被输入到共享的几何流模型和纹理流模型中，以在不同的α值下生成 3D 输出，从而产生带纹理的 3D 变形。右上角展示了我们的纹理控制变形分支，右下角说明了递归初始化。 /// (~ @inproceedings{ yinwukong, title={Wukong's 72 Transformations: High-fidelity Textured 3D Morphing via Flow Models}, author={Yin, Minghao and Cao, Yukang and Han, Kai}, booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems} })"
[site.src/gh]: https://github.com/Visual-AI/visual-ai.github.io.git "(src: .@main/wukong) "
[paper/arxiv]: https://arxiv.org/abs/2511.22425 "(License: arXiv.org perpetual non-exclusive license // 许可证：arXiv.org 永久非排他性许可) (arXiv:2511.22425v1 [cs.CV]) [Submitted on 27 Nov 2025] Wukong's 72 Transformations: High-fidelity Textured 3D Morphing via Flow Models // 《悟空的 72 变：基于流模型的超真实纹理 3D 变形》 /// We present WUKONG, a novel training-free framework for high-fidelity textured 3D morphing that takes a pair of source and target prompts (image or text) as input. Unlike conventional methods -- which rely on manual correspondence matching and deformation trajectory estimation (limiting generalization and requiring costly preprocessing) -- WUKONG leverages the generative prior of flow-based transformers to produce high-fidelity 3D transitions with rich texture details. To ensure smooth shape transitions, we exploit the inherent continuity of flow-based generative processes and formulate morphing as an optimal transport barycenter problem. We further introduce a sequential initialization strategy to prevent abrupt geometric distortions and preserve identity coherence. For faithful texture preservation, we propose a similarity-guided semantic consistency mechanism that selectively retains high-frequency details and enables precise control over blending dynamics. This avoids common artifacts like oversmoothing while maintaining semantic fidelity. Extensive quantitative and qualitative evaluations demonstrate that WUKONG significantly outperforms state-of-the-art methods, achieving superior results across diverse geometry and texture variations. // 我们提出了 WUKONG，一个新颖的无训练框架，用于高保真纹理 3D 变形，它将一对源和目标提示（图像或文本）作为输入。与依赖手动对应匹配和变形轨迹估计的常规方法（这限制了泛化能力并需要昂贵的预处理）不同，WUKONG 利用基于流的转换器的生成先验来生成具有丰富纹理细节的高保真 3D 过渡。为确保平滑的形状过渡，我们利用基于流生成过程的固有连续性，将变形表述为最优传输巴里中心问题。我们进一步引入了一种顺序初始化策略，以防止突发的几何变形并保持身份一致性。为了忠实保留纹理，我们提出了一种基于相似性的语义一致性机制，该机制选择性地保留高频细节并实现对混合动态的精确控制。这避免了常见的伪影（如过度平滑），同时保持了语义保真度。 大量的定量和定性评估表明，WUKONG 显著优于最先进的方法，在各种几何和纹理变化中取得了优异的结果。"

