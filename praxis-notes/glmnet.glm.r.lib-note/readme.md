[site/stanford.edu]: https://glmnet.stanford.edu/
[package/cran]: https://cran.r-project.org/web/packages/glmnet/ "(Version: 	4.1-8) (Depends: 	R (≥ 3.6.0), Matrix (≥ 1.0-6)) (Imports: 	methods, utils, foreach, shape, survival, Rcpp) (LinkingTo: 	RcppEigen, Rcpp) (Suggests: 	knitr, lars, testthat, xfun, rmarkdown) (Published: 	2023-08-22) (DOI: 	10.32614/CRAN.package.glmnet) (Author: 	Jerome Friedman [aut], Trevor Hastie [aut, cre], Rob Tibshirani [aut], Balasubramanian Narasimhan [aut], Kenneth Tay [aut], Noah Simon [aut], Junyang Qian [ctb], James Yang [aut]) (Maintainer: 	Trevor Hastie <hastie at stanford.edu>) (License: 	GPL-2) (NeedsCompilation: 	yes) (SystemRequirements: 	C++17) glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models /// Extremely efficient procedures for fitting the entire lasso or elastic-net regularization path for linear regression, logistic and multinomial regression models, Poisson regression, Cox model, multiple-response Gaussian, and the grouped multinomial regression; see <doi:10.18637/jss.v033.i01> and <doi:10.18637/jss.v039.i05>. There are two new and important additions. The family argument can be a GLM family object, which opens the door to any programmed family (<doi:10.18637/jss.v106.i01>). This comes with a modest computational cost, so when the built-in families suffice, they should be used instead. The other novelty is the relax option, which refits each of the active sets in the path unpenalized. The algorithm uses cyclical coordinate descent in a path-wise fashion, as described in the papers cited. // glmnet: 拉索和弹性网正则化广义线性模型 /// 用于拟合线性回归、逻辑回归和多项式回归模型、泊松回归、Cox 模型、多反应高斯模型和分组多项式回归的整个拉索或弹性网正则化路径的极其高效的程序；参见 <doi:10.18637/jss.v033.i01> 和 <doi:10.18637/jss.v039.i05> 。有两个新的重要补充。族参数可以是一个 GLM 族对象，这为任何编程族打开了大门（<doi:10.18637/jss.v106.i01>）。这将带来适度的计算成本，因此当内置族已经足够时，应该改用内置族。另一个新颖之处在于放松选项，它可以将路径中的每个活动集重新编译，而不进行惩罚。正如所引用的论文中描述的那样，该算法以路径方式使用循环坐标下降。"
[src/gh.mirror]: https://github.com/cran/glmnet.git "(Languages: C++ 53.1%, Fortran 28.9%, R 15.3%, C 0.8%, MATLAB 0.7%, Python 0.6%, Other 0.6%) ❗ This is a read-only mirror of the CRAN R package repository. glmnet — Lasso and Elastic-Net Regularized Generalized Linear Models. Homepage: https://glmnet.stanford.edu"
[reference-manual.pdf]: https://cran.r-project.org/web/packages/glmnet/glmnet.pdf

[knows.by]: https://stackoverflow.com/questions/16284766/how-to-speed-up-glm-estimation "Interesting technical question, although I agree with the other commenters' concerns. (1) There is a fastLm function in the RcppArmadillo package that illustrates how to speed up linear regression gallery.rcpp.org/articles/fast-linear-model-with-armadillo , but re-implementing GLM would be more work. (2) Installing an optimized BLAS library might be lower-hanging fruit: r-bloggers.com/faster-r-through-better-blas . (3) Linear regression might work OK, although N/P is only 133 in this case. (4) Try penalized GLM via the glmnet package ... – Ben Bolker (users/190277/ben-bolker) ///, You should seriously consider using glmnet it's really fast (it uses gradient descent) and with 1500 parameters to fit I don't think that regularization (through elasticnet) would hurt.... – dickoa (users/592920/dickoa)"
