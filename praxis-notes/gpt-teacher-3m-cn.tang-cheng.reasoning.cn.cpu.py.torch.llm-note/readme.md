[src/gh]: https://github.com/helloworldtang/GPT_teacher-3.37M-cn.git "(MIT) (Languages: Python 100.0%) (src & nn-weights<LFS>) 本项目面向课堂教学，目标是让初学者用一台普通 CPU 电脑，在 45 分钟内从零跑通一个小参数的中文 GPT：看清核心流程、跑通训练、得到“可用的中文回答”，并支持简单的推理演示。 /// 项目收获 /// - 了解 GPT 的核心原理：分词 → 批处理 → 前向 → 损失 → 反向 → 优化 → 保存 → 推理（完整链路） /// - 掌握高效小模型技术：RMSNorm、RoPE、权重共享、短序列、小词表、量化 /// - 学会仅用 CPU 训练：控制模型/数据规模、梯度累积、学习率预热与退火、禁用无关耗时特性 /// - 学会可用答案保障：目标对齐（忽略前缀）、推理首步约束与后处理、停止词、提示词规范化 /// 使用技术 /// - 模型结构：Decoder-only Transformer（因果自注意力） /// - 归一化：RMSNorm（简洁高效） /// - 位置编码：RoPE（相对位置，计算高效） /// - 前馈：SiLU（现代 LLM 常用） /// - 权重共享：词嵌入与输出层共享，降参数且表示一致 /// - 训练：AdamW、学习率线性预热+余弦退火、梯度裁剪 /// - 数据与分词：外置jsonl+HF ByteLevel BPE（显式设置 ByteLevel 解码器，避免乱码） /// - 推理：温度/top-k/top-p 采样、重复惩罚、停止词、输出清理、提示规范化 /// - 量化：导出动态量化权重以加速 CPU 推理"
[model/hf]: https://huggingface.co/GPTcn/GPT_teacher-3.37M-cn "(Text Generation) (PyTorch) (Chinese) (Tags: gpt, cpu, chinese, teaching, small-model) (License: MIT)"

