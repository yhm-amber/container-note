[docs]: https://docs.openwebui.com/ "(: docker run -d -p 3000:8080 --gpus all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always -- ghcr.io/open-webui/open-webui:ollama # if already have ollama, use: ghcr.io/open-webui/open-webui:main # if ollama on same node, use option: --add-host=host.docker.internal:host-gateway ... and if ollama on another node, replace it to this option: -e OLLAMA_BASE_URL=https://your.ollama.server #>> http://localhost:3000/) (: update: ;: docker run --rm --volume /var/run/docker.sock:/var/run/docker.sock -- containrrr/watchtower --run-once open-webui # the 'open-webui' here is your container name.)"
[src/gh]: https://github.com/open-webui/open-webui.git "(BSD-3-Clause) (Languages: JavaScript 43.1%, Svelte 27.8%, Python 20.2%, TypeScript 4.7%, CSS 3.8%, Shell 0.2%, Other 0.2%) User-friendly AI Interface"
[app/pypi]: https://pypi.org/project/open-webui/ "(: pip install -- open-webui ;: open-webui serve #>> http://localhost:8080/) Open WebUI"
[site]: https://openwebui.com/
