[main-cli.src/gh]: https://github.com/dask/dask.git "(BSD-3-Clause) (Languages: Python 99.9%, Other 0.1%) Parallel computing with task scheduling // åŸºäºä»»åŠ¡è°ƒåº¦çš„å¹¶è¡Œè®¡ç®—"
[main-cli.pkg.pip/pypi]: https://pypi.org/project/dask/ "(: pip install -- dask # Install only core parts of dask) (: pip install -- dask[complete] # Install everything)  (: pip install dask[array] # Install requirements for dask array) (: pip install dask[dataframe] # Install requirements for dask dataframe) (: pip install dask[diagnostics] # Install requirements for dask diagnostics) (: pip install dask[distributed] # Install requirements for distributed dask)"
[dash-ext-jupylab.src/gh]: https://github.com/dask/dask-labextension.git "(BSD-3-Clause) (Languages: TypeScript 67.6%, Python 24.6%, CSS 6.1%, JavaScript 1.7%) JupyterLab extension for Dask // Dask çš„ JupyterLab æ‰©å±• /// This package provides a JupyterLab extension to manage Dask clusters, as well as embed Dask's dashboard plots directly into JupyterLab panes. // æ­¤è½¯ä»¶åŒ…æä¾›äº†ä¸€ä¸ª JupyterLab æ‰©å±•ï¼Œç”¨äºç®¡ç† Dask é›†ç¾¤ï¼Œå¹¶å°† Dask çš„ä»ªè¡¨æ¿å›¾è¡¨ç›´æ¥åµŒå…¥åˆ° JupyterLab é¢æ¿ä¸­ã€‚"
[dash-ext-jupylab.pkg.pip/pypi]: https://pypi.org/project/dask-labextension/ "(: pip install -- dask-labextension) (;: (~ if JupyterLab 2.x): jupyter labextension install -- dask-labextension) (;: (~ if Notebook 5.2 or earlier): jupyter serverextension enable --py --sys-prefix -- dask_labextension)"
[site/org]: https://dask.org/ "Parallel Python / Fast and Easy // å¹¶è¡Œ Python / å¿«é€Ÿç®€ä¾¿ /// What you can do with Dask // Dask èƒ½åšä»€ä¹ˆ ///: - Big Pandas // å¤§æ•°æ® Pandas ///: (: import dask.dataframe as dd ;: df = dd.read_parquet('s3://data/uber/') ;: df.base_passenger_fare.sum().compute() # How much did NYC pay Uber? ;: df.driver_pay.sum().compute() # And how much did drivers make?) Dask DataFrames use pandas under the hood, so your current code likely just works. Itâ€™s faster than Spark and easier too. // Dask DataFrames ä½¿ç”¨ pandas ä½œä¸ºåº•å±‚æŠ€æœ¯ï¼Œå› æ­¤æ‚¨å½“å‰çš„ä»£ç å¾ˆå¯èƒ½ç›´æ¥é€‚ç”¨ã€‚å®ƒæ¯” Spark æ›´å¿«ï¼Œä¹Ÿæ›´ç®€å•ã€‚ ///; Docs (. {[.docs-stable]}: .../dataframe.html) ///; Performance Benchmarks // æ€§èƒ½åŸºå‡† (_. https://docs.coiled.io/blog/tpch.html) /// - Parallel For Loops // å¹¶è¡Œå¾ªç¯ ///: (: from dask.distributed import Client ;: client = Client() # start distributed scheduler locally, or `client = Client('<url-of-scheduler>')` if you have a remote cluster. `client = Client()` same as `from dask.distributed import Client, LocalCluster; cluster = LocalCluster(); client = Client(cluster)`. ;: def f(x): return x + 1 # Define your own code ;: futures = client.map(f, range(100)) # Run your code in parallel ;: results = client.gather(futures)) Parallelize your Python code, no matter how complex. Dask is flexible and supports arbitrary dependencies and fine-grained task scheduling. // å¹¶è¡ŒåŒ–ä½ çš„ Python ä»£ç ï¼Œæ— è®ºå¤šä¹ˆå¤æ‚ã€‚Dask çµæ´»ä¸”æ”¯æŒä»»æ„ä¾èµ–å…³ç³»å’Œç»†ç²’åº¦ä»»åŠ¡è°ƒåº¦ã€‚ ///; Docs (. {[.docs-stable]}: .../futures.html) ///; Process 5,000 files in parallel // å¹¶è¡Œå¤„ç† 5,000 ä¸ªæ–‡ä»¶ (_. https://docs.coiled.io/user_guide/arxiv-matplotlib.html) /// - Big Arrays // å¤§æ•°ç»„ ///: (: import xarray as xr ;: ds = xr.open_mfdataset('data/*.nc') # Open image/array files natively ;: ds.mean(dims=['lat', 'lon']).compute() # Process across dimensions) Use Dask and NumPy/Xarray to churn through terabytes of multi-dimensional array data in formats like HDF, NetCDF, TIFF, or Zarr. // ä½¿ç”¨ Dask å’Œ NumPy/Xarray å¤„ç† HDFã€NetCDFã€TIFF æˆ– Zarr ç­‰æ ¼å¼çš„ TB çº§å¤šç»´åº¦æ•°ç»„æ•°æ®ã€‚ ///; Docs (. {[.docs-stable]}: .../array.html) ///; Aggregate 250 TB of Water Model Data // èšåˆ 250 TB çš„æ°´æ¨¡å‹æ•°æ® (_. https://docs.coiled.io/blog/coiled-xarray.html) /// - Machine Learning // æœºå™¨å­¦ä¹  ///: (: import xgboost as xgb ;: import dask.dataframe as dd ;: df = dd.read_parquet('s3://my-data/') ;: dtrain = xgb.dask.DaskDMatrix(df) ;: model = xgb.dask.train(dtrain, {'tree_method': 'hist', ...}, ...)) Use Dask with common machine learning libraries to train or predict on large datasets, increasing model accuracy by using all of your data. // ä½¿ç”¨ Dask ä¸å¸¸è§çš„æœºå™¨å­¦ä¹ åº“ä¸€èµ·è®­ç»ƒæˆ–é¢„æµ‹å¤§å‹æ•°æ®é›†ï¼Œé€šè¿‡ä½¿ç”¨æ‰€æœ‰æ•°æ®æ¥æé«˜æ¨¡å‹ç²¾åº¦ã€‚ ///; Docs (. {[.docs-stable]}: .../array.html) ///; Example: XGBoost Model Training // ç¤ºä¾‹ï¼šXGBoost æ¨¡å‹è®­ç»ƒ (_. https://docs.coiled.io/user_guide/xgboost.html)"
[docs/.site]: https://docs.dask.org "Dask is a Python library for parallel and distributed computing. Dask is: // Dask æ˜¯ä¸€ä¸ªç”¨äºå¹¶è¡Œå’Œåˆ†å¸ƒå¼è®¡ç®—çš„ Python åº“ã€‚Dask æ˜¯ï¼š /// - Easy to use and set up (itâ€™s just a Python library) // æ˜“äºä½¿ç”¨å’Œè®¾ç½®ï¼ˆå®ƒåªæ˜¯ä¸€ä¸ª Python åº“ï¼‰ /// - Powerful at providing scale, and unlocking complex algorithms // åœ¨æä¾›æ‰©å±•æ€§æ–¹é¢éå¸¸å¼ºå¤§ï¼Œå¹¶èƒ½è§£é”å¤æ‚çš„ç®—æ³• /// - and Fun ğŸ‰ // ä»¥åŠæœ‰è¶£ ğŸ‰ /// Dashboard (. {[.docs-stable]}: .../dashboard.html) (: client.dashboard_link #> 'http://127.0.0.1:8787/status' # run this or run `client` on jupyter will display the dashboard link.)"
[dash/.docs-stable]: https://docs.dask.org/en/stable/dashboard.html "Profiling parallel code can be challenging, but the interactive dashboard provided with Daskâ€™s distributed scheduler makes this easier with live monitoring of your Dask computations. The dashboard is built with Bokeh and will start up automatically, returning a link to the dashboard whenever the scheduler is created. // åˆ†æå¹¶è¡Œä»£ç å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä½† Dask åˆ†å¸ƒå¼è°ƒåº¦å™¨æä¾›çš„äº¤äº’å¼ä»ªè¡¨æ¿é€šè¿‡å®æ—¶ç›‘æ§æ‚¨çš„ Dask è®¡ç®—ï¼Œä½¿è¿™ä¸€è¿‡ç¨‹å˜å¾—æ›´å®¹æ˜“ã€‚è¯¥ä»ªè¡¨æ¿ä½¿ç”¨ Bokeh æ„å»ºï¼Œå¹¶åœ¨è°ƒåº¦å™¨åˆ›å»ºæ—¶è‡ªåŠ¨å¯åŠ¨ï¼Œå¹¶è¿”å›ä»ªè¡¨æ¿çš„é“¾æ¥ã€‚"
[deploy-k8s/.docs-stable]: https://docs.dask.org/en/stable/deploying-kubernetes.html "Dask Kubernetes OperatorÂ¶ ///: The Dask Kubernetes Operator is a set of Custom Resource Definitions (CRDs) and a controller that allows you to create and manage your Dask clusters as native Kubernetes resources. // Dask Kubernetes Operator æ˜¯ä¸€ç»„è‡ªå®šä¹‰èµ„æºå®šä¹‰ï¼ˆCRDsï¼‰å’Œæ§åˆ¶å™¨ï¼Œå®ƒå…è®¸æ‚¨å°† Dask é›†ç¾¤ä½œä¸ºåŸç”Ÿ Kubernetes èµ„æºè¿›è¡Œåˆ›å»ºå’Œç®¡ç†ã€‚ ///; Install Operator (i.e., The CRDs) by Helm: (: helm upgrade --install --repo https://helm.dask.org --create-namespace -n dask-operator --generate-name -- dask-kubernetes-operator) ///; Creating clusters can either be done via the Kubernetes API with kubectl or the Python API with KubeCluster. // åˆ›å»ºé›†ç¾¤å¯ä»¥é€šè¿‡ Kubernetes APIï¼ˆ kubectl ï¼‰æˆ– Python APIï¼ˆ KubeCluster ï¼‰æ¥å®Œæˆã€‚ ///; Kubernetes API: (: kubectl apply -f - <(echo 'apiVersion: kubernetes.dask.org/v1; kind: DaskCluster; metadata: {name: your-dask-cluster}; spec: {worker: {replicas: 10, spec: {template: {spec: {containers: [{name: dask-worker, image: ghcr.io/dask/dask:latest}]}}}}}')) ///; Dask Python API: (: from dask_kubernetes.operator import KubeCluster; cluster = KubeCluster(name='your-dask-cluster', image='ghcr.io/dask/dask:latest'); cluster.scale(10)) ///; This is a good choice if you want to do the following: // è¿™æ˜¯å¦‚æœä½ æƒ³è¦åšä»¥ä¸‹äº‹æƒ…çš„ä¸€ä¸ªå¥½é€‰æ‹©ï¼š ///; - Have a Kubernetes native experience. // è·å¾—åŸç”Ÿçš„ Kubernetes ä½“éªŒã€‚ ///; - Manage Dask clusters via the Kubernetes API and tools like kubectl. // é€šè¿‡ Kubernetes API å’Œ kubectl ç­‰å·¥å…·ç®¡ç† Dask é›†ç¾¤ã€‚ ///; - Integrate Dask with other tools and workloads running on Kubernetes. // å°† Dask ä¸åœ¨ Kubernetes ä¸Šè¿è¡Œçš„å…¶ä»–å·¥å…·å’Œå·¥ä½œè´Ÿè½½é›†æˆã€‚ ///; - Compose Dask clusters as part of a larger Kubernetes application. // å°† Dask é›†ç¾¤ä½œä¸ºæ›´å¤§ Kubernetes åº”ç”¨ç¨‹åºçš„ä¸€éƒ¨åˆ†è¿›è¡Œç»„åˆã€‚ /// Dask Gateway - GatewayÂ¶ ///: Dask Gateway provides a secure, multi-tenant server for managing Dask clusters. It allows users to launch and use Dask clusters in a shared, centrally managed cluster environment, without requiring users to have direct access to the underlying cluster backend (e.g. Kubernetes, Hadoop/YARN, HPC Job queues, etcâ€¦). // Dask Gateway æä¾›äº†ä¸€ä¸ªå®‰å…¨çš„ã€å¤šç§Ÿæˆ·æœåŠ¡å™¨ï¼Œç”¨äºç®¡ç† Dask é›†ç¾¤ã€‚å®ƒå…è®¸ç”¨æˆ·åœ¨å…±äº«çš„ã€é›†ä¸­ç®¡ç†çš„é›†ç¾¤ç¯å¢ƒä¸­å¯åŠ¨å’Œä½¿ç”¨ Dask é›†ç¾¤ï¼Œè€Œæ— éœ€ç”¨æˆ·ç›´æ¥è®¿é—®åº•å±‚é›†ç¾¤åç«¯ï¼ˆä¾‹å¦‚ Kubernetesã€Hadoop/YARNã€HPC ä»»åŠ¡é˜Ÿåˆ—ç­‰ï¼‰ã€‚ ///; Install Dask Gateway by Helm: (: helm upgrade --install --repo https://helm.dask.org --create-namespace -n dask-gateway --generate-name -- dask-gateway) ///; When running on Kubernetes, Dask Gateway is composed of the following components: // åœ¨ Kubernetes ä¸Šè¿è¡Œæ—¶ï¼ŒDask Gateway ç”±ä»¥ä¸‹ç»„ä»¶ç»„æˆï¼š ///; - Multiple active Dask Clusters (potentially more than one per user) // å¤šä¸ªæ´»è·ƒçš„ Dask é›†ç¾¤ï¼ˆå¯èƒ½æ¯ä¸ªç”¨æˆ·æœ‰å¤šä¸ªï¼‰ ///; - A Traefik Proxy for proxying both the connection between the userâ€™s client and their respective scheduler, and the Dask Web UI for each cluster // ä¸€ä¸ª Traefik ä»£ç†ï¼Œç”¨äºä»£ç†ç”¨æˆ·å®¢æˆ·ç«¯ä¸å…¶å„è‡ªè°ƒåº¦å™¨ä¹‹é—´çš„è¿æ¥ï¼Œä»¥åŠæ¯ä¸ªé›†ç¾¤çš„ Dask Web UI ///; - A Gateway API Server that handles user API requests // ä¸€ä¸ª Gateway API æœåŠ¡å™¨ï¼Œç”¨äºå¤„ç†ç”¨æˆ· API è¯·æ±‚ ///; - A Gateway Controller for managing the kubernetes objects used by each cluster (e.g. pods, secrets, etcâ€¦). // ä¸€ä¸ª Gateway æ§åˆ¶å™¨ï¼Œç”¨äºç®¡ç†æ¯ä¸ªé›†ç¾¤ä½¿ç”¨çš„ Kubernetes å¯¹è±¡ï¼ˆä¾‹å¦‚ï¼špodsã€secrets ç­‰ï¼‰ã€‚ ///; Connect Gateway: (: from dask_gateway import Gateway; gateway = Gateway('<gateway service address>') # get address by `kubectl get service --namespace dask-gateway` and look the `LoadBalancer`â€™s ;: cluster = gateway.new_cluster() # crate cluster ;: gateway.list_clusters() # list all dask clusters) ///; This is a good choice if you want to do the following: // å¦‚æœä½ æƒ³è¦åšåˆ°ä»¥ä¸‹å‡ ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼š ///; - Abstract users away from Kubernetes. // å°†ç”¨æˆ·ä¸ Kubernetes åˆ†ç¦»ã€‚ ///; - Provide a consistent Dask user experience across Kubernetes/Hadoop/HPC. // åœ¨ Kubernetes/Hadoop/HPC ä¸Šæä¾›ä¸€è‡´çš„ Dask ç”¨æˆ·ä½“éªŒã€‚ ///; Dask Gateway - DaskHubÂ¶ ///: You can also deploy Dask Gateway alongside JupyterHub using the DaskHub helm chart. // æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ DaskHub helm å›¾è¡¨åœ¨ JupyterHub æ—è¾¹éƒ¨ç½² Dask Gatewayã€‚ ///; Install DHub by Helm: (: helm upgrade --install --wait --render-subchart-notes --repo https://helm.dask.org --create-namespace -n daskhub -- dhub daskhub # The output explains how to find the IPs for your JupyterHub and Dask Gateway. ;: kubectl -n dhub get service -- proxy-public # JupyterHub is available at the `proxy-public`â€™s external ip field `EXTERNAL-IP`.) ///; This chart will deploy the following // è¿™å¼ å›¾è¡¨å°†éƒ¨ç½²ä»¥ä¸‹å†…å®¹ ///; - A standard Dask Gateway deployment using the Dask Gateway helm chart, configured to use JupyterHub for authentication. // ä½¿ç”¨ Dask Gateway helm å›¾è¡¨çš„æ ‡å‡† Dask Gateway éƒ¨ç½²ï¼Œé…ç½®ä¸ºä½¿ç”¨ JupyterHub è¿›è¡Œèº«ä»½éªŒè¯ã€‚ ///; - A standard JupyterHub deployment using the JupyterHub helm chart, configured proxy Dask Gateway requests and set Dask Gateway-related environment variables. // ä½¿ç”¨ JupyterHub helm å›¾è¡¨çš„æ ‡å‡† JupyterHub éƒ¨ç½²ï¼Œé…ç½®ä¸ºä»£ç† Dask Gateway è¯·æ±‚å¹¶è®¾ç½® Dask Gateway ç›¸å…³çš„ç¯å¢ƒå˜é‡ã€‚ ///; To create a Dask cluster: (: from dask_gateway import GatewayCluster; cluster = GatewayCluster() ;: from dask_gateway import Gateway; gateway = Gateway(); cluster = gateway.new_cluster() # If necessary (say to set options, create clusters that outlive the notebook session, etc.), users can connect to the Gateway. ;: client = cluster.get_client() # connect the dask cluster.) ///; Single Cluster Helm ChartÂ¶ ///: You can deploy a single Dask cluster and (optionally) Jupyter on Kubernetes easily using Helm // æ‚¨å¯ä»¥ä½¿ç”¨ Helm åœ¨ Kubernetes ä¸Šè½»æ¾éƒ¨ç½²å•ä¸ª Dask é›†ç¾¤å’Œ Jupyter (å¯é€‰)ã€‚ ///; Install Single Dask Cluster by Helm: (: helm upgrade --install --repo https://helm.dask.org -n yourdask-ns -- yourdask dask) ///; This is a good choice if you want to do the following: // è¿™æ˜¯å¦‚æœä½ æƒ³è¦åšä»¥ä¸‹äº‹æƒ…çš„ä¸€ä¸ªå¥½é€‰æ‹©ï¼š ///; - Try out Dask for the first time on a cloud-based system like Amazon, Google, or Microsoft Azure where you already have a Kubernetes cluster. If you donâ€™t already have Kubernetes deployed, see our Cloud documentation. // åœ¨ Amazonã€Google æˆ– Microsoft Azure ç­‰å·²ç»éƒ¨ç½²äº† Kubernetes é›†ç¾¤çš„äº‘ç³»ç»Ÿä¸Šé¦–æ¬¡å°è¯• Daskã€‚å¦‚æœä½ è¿˜æ²¡æœ‰éƒ¨ç½² Kubernetesï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„äº‘æ–‡æ¡£ã€‚ ///; You can also use the HelmCluster cluster manager from dask-kubernetes to manage your Helm Dask cluster from within your Python session. // ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ dask-kubernetes ä¸­çš„ HelmCluster é›†ç¾¤ç®¡ç†å™¨ï¼Œä»ä½ çš„ Python ä¼šè¯ä¸­ç®¡ç†ä½ çš„ Helm Dask é›†ç¾¤ã€‚ ///; Install Single Dask Cluster by HelmCluster dask python api: (: from dask_kubernetes import HelmCluster; cluster = HelmCluster(release_name='yourdask'); cluster.scale(10))"
[kubernetes-operator.src/gh]: https://github.com/dask/dask-kubernetes.git "(BSD-3-Clause) (Languages: Python 93.2%, Go 3.7%, Smarty 1.3%, Other 1.8%) Native Kubernetes integration for Dask // Dask çš„åŸç”Ÿ Kubernetes é›†æˆ"
[kubernetes-operator.pkg.pip/pypi]: https://pypi.org/project/dask-kubernetes/ "(: pip install -- dask-kubernetes) (: from dask_kubernetes.operator import KubeCluster; cluster = KubeCluster(name='your-dask-cluster', image='ghcr.io/dask/dask:latest'); cluster.scale(10) # same as using CRD kind `DaskCluster` by yaml)"
[kubernetes-operator.pkg.oci/ghcr]: https://github.com/dask/dask-kubernetes/pkgs/container/dask-kubernetes-operator "(: docker pull -- ghcr.io/dask/dask-kubernetes-operator:2025.7.0)"
[kubernetes-operator.docs/.site]: https://kubernetes.dask.org "KubeCluster deploys Dask clusters on Kubernetes clusters using custom Kubernetes resources. It is designed to dynamically launch ad-hoc deployments. // KubeCluster åœ¨ Kubernetes é›†ç¾¤ä¸Šéƒ¨ç½² Dask é›†ç¾¤ï¼Œä½¿ç”¨è‡ªå®šä¹‰ Kubernetes èµ„æºã€‚å®ƒæ—¨åœ¨åŠ¨æ€åœ°å¯åŠ¨ä¸´æ—¶éƒ¨ç½²ã€‚"
[charts-helm.src/gh]: https://github.com/dask/helm-chart.git "(Languages: YAML 97.5%, Mustache 2.5%) Helm charts for Dask /// This repository contains two Helm charts. // æ­¤å­˜å‚¨åº“åŒ…å«ä¸¤ä¸ª Helm å›¾è¡¨ã€‚ /// - dask: Install Dask on Kubernetes for a single user with Jupyter and dask-kubernetes. // dask: ç”¨äºå•ä¸ªç”¨æˆ·åœ¨ Kubernetes ä¸Šå®‰è£… Daskï¼Œå¹¶é…å¤‡ Jupyter å’Œ dask-kubernetesã€‚ /// - daskhub: Install Dask on Kubernetes for multiple users with JupyterHub and dask-gateway. // daskhub: ç”¨äºå¤šä¸ªç”¨æˆ·åœ¨ Kubernetes ä¸Šå®‰è£… Daskï¼Œå¹¶é…å¤‡ JupyterHub å’Œ dask-gatewayã€‚ /// This repository also contains a gh-pages branch that using GitHub Pages is built into the website available at https://helm.dask.org. This website is human readable but also readable by helm as a Helm chart repository thanks to a index.yaml file. // è¯¥ä»“åº“è¿˜åŒ…å«ä¸€ä¸ª gh-pages åˆ†æ”¯ï¼Œä½¿ç”¨ GitHub Pages æ„å»ºï¼Œå¹¶æ‰˜ç®¡åœ¨ https://helm.dask.org ç½‘ç«™ä¸Šã€‚è¯¥ç½‘ç«™æ—¢äººç±»å¯è¯»ï¼Œä¹Ÿä½œä¸º Helm å›¾è¡¨ä»“åº“è¢« helm è¯»å–ï¼Œè¿™å¾—ç›Šäºä¸€ä¸ª index.yaml æ–‡ä»¶ã€‚ /// The Helm chart repository also publishes Helm charts not maintained in this repository, specifically dask-gateway and dask-kubernetes-operator. // Helm å›¾è¡¨ä»“åº“è¿˜ä¼šå‘å¸ƒæœ¬ä»“åº“æœªç»´æŠ¤çš„ Helm å›¾è¡¨ï¼Œç‰¹åˆ«æ˜¯ dask-gateway å’Œ dask-kubernetes-operator ã€‚"
[charts-helm.site/.site]: https://helm.dask.org/ "Dask community Helm charts for Kubernetes"
[dask-kubernetes-operator.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/dask-kubernetes-operator "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n dask-operator --generate-name -- dask/dask-kubernetes-operator)"
[dask-gateway.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/dask-gateway "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n dask-gateway --generate-name -- dask/dask-gateway)"
[daskhub.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/daskhub "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n daskhub --generate-name -- dask/daskhub)"
[dask.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/dask "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n dask --generate-name -- dask/dask)"
[gateway.src/gh]: https://github.com/dask/dask-gateway.git "(BSD-3-Clause) (Languages: Python 87.5%, Go 4.6%, Shell 4.3%, Dockerfile 3.2%, Mustache 0.4%) A multi-tenant server for securely deploying and managing Dask clusters. // ä¸€ä¸ªç”¨äºå®‰å…¨éƒ¨ç½²å’Œç®¡ç† Dask é›†ç¾¤çš„å¤šç§Ÿæˆ·æœåŠ¡å™¨ã€‚ /// Dask-Gateway is composed of two packages: // Dask-Gateway ç”±ä¸¤ä¸ªåŒ…ç»„æˆï¼š /// - dask-gateway: the client library, installed by users. // dask-gateway : å®¢æˆ·ç«¯åº“ï¼Œç”±ç”¨æˆ·å®‰è£…ã€‚ /// - dask-gateway-server: the gateway server, installed by administrators. // dask-gateway-server : ç½‘å…³æœåŠ¡å™¨ï¼Œç”±ç®¡ç†å‘˜å®‰è£…ã€‚"
[gateway-client.pkg.pip/pypi]: https://pypi.org/project/dask-gateway/ "(: pip install -- dask-gateway) (: pip install -- dask-gateway[kerberos] # Install the kerberos dependencies if your Dask-Gateway server uses Kerberos for authentication // å®‰è£… Kerberos ä¾èµ–é¡¹è‹¥æ‚¨çš„ Dask-Gateway æœåŠ¡å™¨ä½¿ç”¨ Kerberos è¿›è¡Œèº«ä»½éªŒè¯)"
[gateway-client.pkg.oci/ghcr]: https://github.com/dask/dask-gateway/pkgs/container/dask-gateway "(: docker pull -- ghcr.io/dask/dask-gateway:2025.4.0)"
[gateway-server.pkg.pip/pypi]: https://pypi.org/project/dask-gateway-server/ "(: pip install -- dask-gateway-server) (: pip install -- dask-gateway dask-gateway-server[local] # Install Locally for Quickstart) /// To start the Gateway server, run: // è¦å¯åŠ¨ç½‘å…³æœåŠ¡å™¨ï¼Œè¯·è¿è¡Œï¼š /// (: dask-gateway-server) /// This starts dask-gateway locally with the default configuration. This uses: // è¿™å°†åœ¨æœ¬åœ°å¯åŠ¨ dask-gateway çš„é»˜è®¤é…ç½®ã€‚å®ƒä½¿ç”¨ï¼š /// - UnsafeLocalBackend to manage local clusters without any process isolation // UnsafeLocalBackend ç”¨äºç®¡ç†æ— éœ€ä»»ä½•è¿›ç¨‹éš”ç¦»çš„æœ¬åœ°é›†ç¾¤ /// - SimpleAuthenticator to authenticate users using a simple and insecure authentication scheme // SimpleAuthenticator ä½¿ç”¨ç®€å•ä¸”ä¸å®‰å…¨çš„è®¤è¯æ–¹æ¡ˆæ¥éªŒè¯ç”¨æˆ· /// Both of these options are insecure and not-advised for any real-world deployments. They are perfectly fine for testing and experimentation though. // è¿™ä¸¤ç§é€‰é¡¹éƒ½ä¸å®‰å…¨ï¼Œä¸æ¨èç”¨äºä»»ä½•å®é™…éƒ¨ç½²ã€‚ä¸è¿‡ï¼Œå®ƒä»¬å¯¹äºæµ‹è¯•å’Œå®éªŒæ¥è¯´å®Œå…¨åˆé€‚ã€‚ /// To connect to the gateway, create a Gateway client with the URL output above. By default this is http://127.0.0.1:8000. // è¦è¿æ¥åˆ°ç½‘å…³ï¼Œè¯·ä½¿ç”¨ä¸Šé¢è¾“å‡ºçš„ URL åˆ›å»ºä¸€ä¸ª Gateway å®¢æˆ·ç«¯ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ http://127.0.0.1:8000 ã€‚ /// (: from dask_gateway import Gateway; gateway = Gateway('http://127.0.0.1:8000') ;: gateway #> Gateway<http://127.0.0.1:8000> # see gateway info ;: gateway.list_clusters() #> [] # see clusters in this gateway)"
[gateway-server.pkg.oci/ghcr]: https://github.com/dask/dask-gateway/pkgs/container/dask-gateway-server "(: docker pull -- ghcr.io/dask/dask-gateway-server:2025.4.0)"
[deploy-cli/.docs-stable]: https://docs.dask.org/en/stable/deploying-cli.html "Demo: (: dask scheduler #> Scheduler at:   tcp://192.0.0.100:8786 # launch dask scheduler on main node) (: dask worker tcp://192.0.0.100:8786 # launch dask worker on the rest of the nodes) The workers connect to the scheduler, which then sets up a long-running network connection back to the worker. The workers will learn the location of other workers from the scheduler. // å·¥ä½œè¿›ç¨‹è¿æ¥åˆ°è°ƒåº¦å™¨ï¼Œè°ƒåº¦å™¨éšåå»ºç«‹ä¸€æ¡é•¿è¿æ¥è¿”å›åˆ°å·¥ä½œè¿›ç¨‹ã€‚å·¥ä½œè¿›ç¨‹å°†ä»è°ƒåº¦å™¨é‚£é‡Œå­¦ä¹ å…¶ä»–å·¥ä½œè¿›ç¨‹çš„ä½ç½®ã€‚"
[distributed.src/gh]: https://github.com/dask/distributed.git "(BSD-3-Clause) (Languages: Python 98.9%, Other 1.1%) A distributed task scheduler for Dask // ä¸€ä¸ªç”¨äº Dask çš„åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦å™¨ /// A library for distributed computation. // ä¸€ä¸ªç”¨äºåˆ†å¸ƒå¼è®¡ç®—çš„åº“ã€‚"
[distributed.pkg.pip/pypi]: https://pypi.org/project/distributed/ "(: pip install -- distributed)"
[distributed.docs/.site]: https://distributed.dask.org "Dask.distributed is a lightweight library for distributed computing in Python. It extends both the concurrent.futures and dask APIs to moderate sized clusters. // Dask.distributed æ˜¯ä¸€ä¸ªç”¨äº Python çš„è½»é‡çº§åˆ†å¸ƒå¼è®¡ç®—åº“ã€‚å®ƒæ‰©å±•äº† concurrent.futures å’Œ dask APIï¼Œé€‚ç”¨äºä¸­ç­‰è§„æ¨¡çš„é›†ç¾¤ã€‚"
[distributed.qs/.docs]: https://distributed.dask.org/en/stable/quickstart.html "(: pip install -U -- dask distributed) (: dask scheduler #> Scheduler started at 127.0.0.1:8786 # at scheduler node ;: dask worker 127.0.0.1:8786 # run at more worker nodes if 'Scheduler started at 127.0.0.1:8786' output on scheduler node) (:: from dask.distributed import Client; client = Client('127.0.0.1:8786') # connect the scheduler node '127.0.0.1:8786') (:: DATA = range(10); A = client.map(lambda x: x**2, DATA); B = client.map(lambda x: -x, A); total = client.submit(sum, B) # submit calc on cluster by client ;: total.result() #> -285 # result for single future ;: client.gather(A) #> [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] # gather for many futures ;: client.restart() # When things go wrong, or when you want to reset the cluster state, call the restart method.)"
[ml.src/gh]: https://github.com/dask/dask-ml.git "(BSD-3-Clause) (Languages: Python 99.9%, Shell 0.1%) Scalable Machine Learning with Dask // ä½¿ç”¨ Dask è¿›è¡Œå¯æ‰©å±•æœºå™¨å­¦ä¹  /// Dask-ML provides scalable machine learning in Python using Dask alongside popular machine learning libraries like Scikit-Learn, XGBoost, and others. // Dask-ML ä½¿ç”¨ Dask ç»“åˆ Scikit-Learnã€XGBoost ç­‰æµè¡Œçš„æœºå™¨å­¦ä¹ åº“ï¼Œæä¾›å¯æ‰©å±•çš„ Python æœºå™¨å­¦ä¹ åŠŸèƒ½ã€‚"
[ml.try/mybinder]: https://mybinder.org/v2/gh/dask/dask-examples/main?filepath=machine-learning.ipynb "Try Dask-ML on a small cloud instance // åœ¨å°å‹äº‘å®ä¾‹ä¸Šå°è¯• Dask-ML"
[ml.pkg.pip/pypi]: https://pypi.org/project/dask-ml/ "(: pip install -- dask-ml) (: pip install -- dask-ml[complete] # Install all optional dependencies)"
[examples.src/gh]: http://github.com/dask/dask-examples.git "(CC-BY-SA-4.0) (Languages: Jupyter Notebook 97.1%, Python 2.7%, Other 0.2%) Easy-to-run example notebooks for Dask"
[examples.docs/.site]: https://examples.dask.org/ "This repository includes easy-to-run example notebooks for Dask. They are intended to be educational and give users a start on common workflows. // æ­¤å­˜å‚¨åº“åŒ…å«æ˜“äºè¿è¡Œçš„ Dask ç¤ºä¾‹ç¬”è®°æœ¬ã€‚å®ƒä»¬æ—¨åœ¨æä¾›æ•™è‚²åŠŸèƒ½ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£å¸¸è§çš„å·¥ä½œæµç¨‹ã€‚"
[glm.src/gh]: https://github.com/dask/dask-glm.git "(BSD-3-Clause) (Languages: Python 100.0%) Generalized Linear Models in Dask // Dask ä¸­çš„å¹¿ä¹‰çº¿æ€§æ¨¡å‹"
[glm.pkg.pip/pypi]: https://pypi.org/project/dask-glm/ "(: pip install -- dask-glm)"
[glm.docs/readthedocs.io]: https://dask-glm.readthedocs.io/ "Dask-glm is a library for fitting Generalized Linear Models on large datasets // Dask-glm æ˜¯ä¸€ä¸ªç”¨äºåœ¨å¤§å‹æ•°æ®é›†ä¸Šæ‹Ÿåˆå¹¿ä¹‰çº¿æ€§æ¨¡å‹çš„åº“ /// Dask-glm builds on the dask project to fit GLMâ€˜s on datasets in parallel. It offers a scikit-learn compatible API for specifying your model. // Dask-glm åŸºäº dask é¡¹ç›®ï¼Œåœ¨å¹¶è¡Œæ•°æ®é›†ä¸Šæ‹Ÿåˆ GLMã€‚å®ƒæä¾›äº†ä¸€ä¸ªä¸ scikit-learn å…¼å®¹çš„ API æ¥æŒ‡å®šæ‚¨çš„æ¨¡å‹ã€‚"
[jobqueue.src/gh]: https://github.com/dask/dask-jobqueue.git "(BSD-3-Clause) (Languages: Python 92.9%, Shell 4.8%, Dockerfile 2.3%) Deploy Dask on job schedulers like PBS, SLURM, and SGE // åœ¨ PBSã€SLURM å’Œ SGE ç­‰ä½œä¸šè°ƒåº¦å™¨ä¸Šéƒ¨ç½² Dask"
[jobqueue.docs/.site]: https://jobqueue.dask.org "Easily deploy Dask on job queuing systems like PBS, Slurm, MOAB, SGE, LSF, and HTCondor. // è½»æ¾åœ¨ PBSã€Slurmã€MOABã€SGEã€LSF å’Œ HTCondor ç­‰ä½œä¸šé˜Ÿåˆ—ç³»ç»Ÿä¸Šéƒ¨ç½² Daskã€‚ /// The dask-jobqueue project makes it easy to deploy Dask on common job queuing systems typically found in high performance supercomputers, academic research institutions, and other clusters. // dask-jobqueue é¡¹ç›®ä½¿å¾—åœ¨é€šå¸¸åœ¨é«˜æ€§èƒ½è¶…çº§è®¡ç®—æœºã€å­¦æœ¯ç ”ç©¶æœºæ„å’Œå…¶ä»–é›†ç¾¤ä¸­å¸¸è§çš„å·¥ä½œé˜Ÿåˆ—ç³»ç»Ÿä¸Šéƒ¨ç½² Dask å˜å¾—å®¹æ˜“ã€‚ /// There are two common deployment patterns for Dask on HPC, Dynamic Clusters and Batch Runners, and dask-jobqueue has support for both. // åœ¨ HPC ä¸Šï¼ŒDask æœ‰ä¸¤ç§å¸¸è§çš„éƒ¨ç½²æ¨¡å¼ï¼šåŠ¨æ€é›†ç¾¤å’Œæ‰¹å¤„ç†è¿è¡Œå™¨ï¼Œ dask-jobqueue éƒ½æ”¯æŒè¿™ä¸¤ç§æ¨¡å¼ã€‚"
[jobqueue.pkg.pip/pypi]: https://pypi.org/project/dask-jobqueue/ "(: pip install -- dask-jobqueue)"
[deploy-hpc/.docs-stable]: https://docs.dask.org/en/stable/deploying-hpc.html "(: from dask_jobqueue import PBSCluster; cluster = PBSCluster(cores=36, memory='100GB', project='P48500028', queue='premium', interface='ib0', walltime='02:00:00'); cluster.scale(100) # Start 100 workers in 100 jobs that match the description above) Dask-jobqueue provides a lot of possibilities like adaptive dynamic scaling of workers, we recommend reading the dask-jobqueue documentation first to get a basic system running and then returning to this documentation for fine-tuning if necessary. // dask-jobqueue æä¾›äº†è®¸å¤šå¯èƒ½æ€§ï¼Œä¾‹å¦‚å·¥ä½œèŠ‚ç‚¹çš„è‡ªé€‚åº”åŠ¨æ€æ‰©å±•ã€‚æˆ‘ä»¬å»ºè®®æ‚¨é¦–å…ˆé˜…è¯» dask-jobqueue æ–‡æ¡£æ¥æ­å»ºåŸºæœ¬ç³»ç»Ÿï¼Œå¦‚æœ‰å¿…è¦ï¼Œå†è¿”å›æ­¤æ–‡æ¡£è¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚"
