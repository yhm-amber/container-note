[main-cli.src/gh]: https://github.com/dask/dask.git "(BSD-3-Clause) (Languages: Python 99.9%, Other 0.1%) Parallel computing with task scheduling // 基于任务调度的并行计算"
[main-cli.pkg.pip/pypi]: https://pypi.org/project/dask/ "(: pip install -- dask # Install only core parts of dask) (: pip install -- dask[complete] # Install everything)  (: pip install dask[array] # Install requirements for dask array) (: pip install dask[dataframe] # Install requirements for dask dataframe) (: pip install dask[diagnostics] # Install requirements for dask diagnostics) (: pip install dask[distributed] # Install requirements for distributed dask)"
[dash-ext-jupylab.src/gh]: https://github.com/dask/dask-labextension.git "(BSD-3-Clause) (Languages: TypeScript 67.6%, Python 24.6%, CSS 6.1%, JavaScript 1.7%) JupyterLab extension for Dask // Dask 的 JupyterLab 扩展 /// This package provides a JupyterLab extension to manage Dask clusters, as well as embed Dask's dashboard plots directly into JupyterLab panes. // 此软件包提供了一个 JupyterLab 扩展，用于管理 Dask 集群，并将 Dask 的仪表板图表直接嵌入到 JupyterLab 面板中。"
[dash-ext-jupylab.pkg.pip/pypi]: https://pypi.org/project/dask-labextension/ "(: pip install -- dask-labextension) (;: (~ if JupyterLab 2.x): jupyter labextension install -- dask-labextension) (;: (~ if Notebook 5.2 or earlier): jupyter serverextension enable --py --sys-prefix -- dask_labextension)"
[site/org]: https://dask.org/ "Parallel Python / Fast and Easy // 并行 Python / 快速简便 /// What you can do with Dask // Dask 能做什么 ///: - Big Pandas // 大数据 Pandas ///: (: import dask.dataframe as dd ;: df = dd.read_parquet('s3://data/uber/') ;: df.base_passenger_fare.sum().compute() # How much did NYC pay Uber? ;: df.driver_pay.sum().compute() # And how much did drivers make?) Dask DataFrames use pandas under the hood, so your current code likely just works. It’s faster than Spark and easier too. // Dask DataFrames 使用 pandas 作为底层技术，因此您当前的代码很可能直接适用。它比 Spark 更快，也更简单。 ///; Docs (. {[.docs-stable]}: .../dataframe.html) ///; Performance Benchmarks // 性能基准 (_. https://docs.coiled.io/blog/tpch.html) /// - Parallel For Loops // 并行循环 ///: (: from dask.distributed import Client ;: client = Client() # start distributed scheduler locally, or `client = Client('<url-of-scheduler>')` if you have a remote cluster. `client = Client()` same as `from dask.distributed import Client, LocalCluster; cluster = LocalCluster(); client = Client(cluster)`. ;: def f(x): return x + 1 # Define your own code ;: futures = client.map(f, range(100)) # Run your code in parallel ;: results = client.gather(futures)) Parallelize your Python code, no matter how complex. Dask is flexible and supports arbitrary dependencies and fine-grained task scheduling. // 并行化你的 Python 代码，无论多么复杂。Dask 灵活且支持任意依赖关系和细粒度任务调度。 ///; Docs (. {[.docs-stable]}: .../futures.html) ///; Process 5,000 files in parallel // 并行处理 5,000 个文件 (_. https://docs.coiled.io/user_guide/arxiv-matplotlib.html) /// - Big Arrays // 大数组 ///: (: import xarray as xr ;: ds = xr.open_mfdataset('data/*.nc') # Open image/array files natively ;: ds.mean(dims=['lat', 'lon']).compute() # Process across dimensions) Use Dask and NumPy/Xarray to churn through terabytes of multi-dimensional array data in formats like HDF, NetCDF, TIFF, or Zarr. // 使用 Dask 和 NumPy/Xarray 处理 HDF、NetCDF、TIFF 或 Zarr 等格式的 TB 级多维度数组数据。 ///; Docs (. {[.docs-stable]}: .../array.html) ///; Aggregate 250 TB of Water Model Data // 聚合 250 TB 的水模型数据 (_. https://docs.coiled.io/blog/coiled-xarray.html) /// - Machine Learning // 机器学习 ///: (: import xgboost as xgb ;: import dask.dataframe as dd ;: df = dd.read_parquet('s3://my-data/') ;: dtrain = xgb.dask.DaskDMatrix(df) ;: model = xgb.dask.train(dtrain, {'tree_method': 'hist', ...}, ...)) Use Dask with common machine learning libraries to train or predict on large datasets, increasing model accuracy by using all of your data. // 使用 Dask 与常见的机器学习库一起训练或预测大型数据集，通过使用所有数据来提高模型精度。 ///; Docs (. {[.docs-stable]}: .../array.html) ///; Example: XGBoost Model Training // 示例：XGBoost 模型训练 (_. https://docs.coiled.io/user_guide/xgboost.html)"
[docs/.site]: https://docs.dask.org "Dask is a Python library for parallel and distributed computing. Dask is: // Dask 是一个用于并行和分布式计算的 Python 库。Dask 是： /// - Easy to use and set up (it’s just a Python library) // 易于使用和设置（它只是一个 Python 库） /// - Powerful at providing scale, and unlocking complex algorithms // 在提供扩展性方面非常强大，并能解锁复杂的算法 /// - and Fun 🎉 // 以及有趣 🎉 /// Dashboard (. {[.docs-stable]}: .../dashboard.html) (: client.dashboard_link #> 'http://127.0.0.1:8787/status' # run this or run `client` on jupyter will display the dashboard link.)"
[dash/.docs-stable]: https://docs.dask.org/en/stable/dashboard.html "Profiling parallel code can be challenging, but the interactive dashboard provided with Dask’s distributed scheduler makes this easier with live monitoring of your Dask computations. The dashboard is built with Bokeh and will start up automatically, returning a link to the dashboard whenever the scheduler is created. // 分析并行代码可能具有挑战性，但 Dask 分布式调度器提供的交互式仪表板通过实时监控您的 Dask 计算，使这一过程变得更容易。该仪表板使用 Bokeh 构建，并在调度器创建时自动启动，并返回仪表板的链接。"
[deploy-k8s/.docs-stable]: https://docs.dask.org/en/stable/deploying-kubernetes.html "Dask Kubernetes Operator¶ ///: The Dask Kubernetes Operator is a set of Custom Resource Definitions (CRDs) and a controller that allows you to create and manage your Dask clusters as native Kubernetes resources. // Dask Kubernetes Operator 是一组自定义资源定义（CRDs）和控制器，它允许您将 Dask 集群作为原生 Kubernetes 资源进行创建和管理。 ///; Install Operator (i.e., The CRDs) by Helm: (: helm upgrade --install --repo https://helm.dask.org --create-namespace -n dask-operator --generate-name -- dask-kubernetes-operator) ///; Creating clusters can either be done via the Kubernetes API with kubectl or the Python API with KubeCluster. // 创建集群可以通过 Kubernetes API（ kubectl ）或 Python API（ KubeCluster ）来完成。 ///; Kubernetes API: (: kubectl apply -f - <(echo 'apiVersion: kubernetes.dask.org/v1; kind: DaskCluster; metadata: {name: your-dask-cluster}; spec: {worker: {replicas: 10, spec: {template: {spec: {containers: [{name: dask-worker, image: ghcr.io/dask/dask:latest}]}}}}}')) ///; Dask Python API: (: from dask_kubernetes.operator import KubeCluster; cluster = KubeCluster(name='your-dask-cluster', image='ghcr.io/dask/dask:latest'); cluster.scale(10)) ///; This is a good choice if you want to do the following: // 这是如果你想要做以下事情的一个好选择： ///; - Have a Kubernetes native experience. // 获得原生的 Kubernetes 体验。 ///; - Manage Dask clusters via the Kubernetes API and tools like kubectl. // 通过 Kubernetes API 和 kubectl 等工具管理 Dask 集群。 ///; - Integrate Dask with other tools and workloads running on Kubernetes. // 将 Dask 与在 Kubernetes 上运行的其他工具和工作负载集成。 ///; - Compose Dask clusters as part of a larger Kubernetes application. // 将 Dask 集群作为更大 Kubernetes 应用程序的一部分进行组合。 /// Dask Gateway - Gateway¶ ///: Dask Gateway provides a secure, multi-tenant server for managing Dask clusters. It allows users to launch and use Dask clusters in a shared, centrally managed cluster environment, without requiring users to have direct access to the underlying cluster backend (e.g. Kubernetes, Hadoop/YARN, HPC Job queues, etc…). // Dask Gateway 提供了一个安全的、多租户服务器，用于管理 Dask 集群。它允许用户在共享的、集中管理的集群环境中启动和使用 Dask 集群，而无需用户直接访问底层集群后端（例如 Kubernetes、Hadoop/YARN、HPC 任务队列等）。 ///; Install Dask Gateway by Helm: (: helm upgrade --install --repo https://helm.dask.org --create-namespace -n dask-gateway --generate-name -- dask-gateway) ///; When running on Kubernetes, Dask Gateway is composed of the following components: // 在 Kubernetes 上运行时，Dask Gateway 由以下组件组成： ///; - Multiple active Dask Clusters (potentially more than one per user) // 多个活跃的 Dask 集群（可能每个用户有多个） ///; - A Traefik Proxy for proxying both the connection between the user’s client and their respective scheduler, and the Dask Web UI for each cluster // 一个 Traefik 代理，用于代理用户客户端与其各自调度器之间的连接，以及每个集群的 Dask Web UI ///; - A Gateway API Server that handles user API requests // 一个 Gateway API 服务器，用于处理用户 API 请求 ///; - A Gateway Controller for managing the kubernetes objects used by each cluster (e.g. pods, secrets, etc…). // 一个 Gateway 控制器，用于管理每个集群使用的 Kubernetes 对象（例如：pods、secrets 等）。 ///; Connect Gateway: (: from dask_gateway import Gateway; gateway = Gateway('<gateway service address>') # get address by `kubectl get service --namespace dask-gateway` and look the `LoadBalancer`’s ;: cluster = gateway.new_cluster() # crate cluster ;: gateway.list_clusters() # list all dask clusters) ///; This is a good choice if you want to do the following: // 如果你想要做到以下几点，这是一个不错的选择： ///; - Abstract users away from Kubernetes. // 将用户与 Kubernetes 分离。 ///; - Provide a consistent Dask user experience across Kubernetes/Hadoop/HPC. // 在 Kubernetes/Hadoop/HPC 上提供一致的 Dask 用户体验。 ///; Dask Gateway - DaskHub¶ ///: You can also deploy Dask Gateway alongside JupyterHub using the DaskHub helm chart. // 您也可以使用 DaskHub helm 图表在 JupyterHub 旁边部署 Dask Gateway。 ///; Install DHub by Helm: (: helm upgrade --install --wait --render-subchart-notes --repo https://helm.dask.org --create-namespace -n daskhub -- dhub daskhub # The output explains how to find the IPs for your JupyterHub and Dask Gateway. ;: kubectl -n dhub get service -- proxy-public # JupyterHub is available at the `proxy-public`’s external ip field `EXTERNAL-IP`.) ///; This chart will deploy the following // 这张图表将部署以下内容 ///; - A standard Dask Gateway deployment using the Dask Gateway helm chart, configured to use JupyterHub for authentication. // 使用 Dask Gateway helm 图表的标准 Dask Gateway 部署，配置为使用 JupyterHub 进行身份验证。 ///; - A standard JupyterHub deployment using the JupyterHub helm chart, configured proxy Dask Gateway requests and set Dask Gateway-related environment variables. // 使用 JupyterHub helm 图表的标准 JupyterHub 部署，配置为代理 Dask Gateway 请求并设置 Dask Gateway 相关的环境变量。 ///; To create a Dask cluster: (: from dask_gateway import GatewayCluster; cluster = GatewayCluster() ;: from dask_gateway import Gateway; gateway = Gateway(); cluster = gateway.new_cluster() # If necessary (say to set options, create clusters that outlive the notebook session, etc.), users can connect to the Gateway. ;: client = cluster.get_client() # connect the dask cluster.) ///; Single Cluster Helm Chart¶ ///: You can deploy a single Dask cluster and (optionally) Jupyter on Kubernetes easily using Helm // 您可以使用 Helm 在 Kubernetes 上轻松部署单个 Dask 集群和 Jupyter (可选)。 ///; Install Single Dask Cluster by Helm: (: helm upgrade --install --repo https://helm.dask.org -n yourdask-ns -- yourdask dask) ///; This is a good choice if you want to do the following: // 这是如果你想要做以下事情的一个好选择： ///; - Try out Dask for the first time on a cloud-based system like Amazon, Google, or Microsoft Azure where you already have a Kubernetes cluster. If you don’t already have Kubernetes deployed, see our Cloud documentation. // 在 Amazon、Google 或 Microsoft Azure 等已经部署了 Kubernetes 集群的云系统上首次尝试 Dask。如果你还没有部署 Kubernetes，请查看我们的云文档。 ///; You can also use the HelmCluster cluster manager from dask-kubernetes to manage your Helm Dask cluster from within your Python session. // 你也可以使用 dask-kubernetes 中的 HelmCluster 集群管理器，从你的 Python 会话中管理你的 Helm Dask 集群。 ///; Install Single Dask Cluster by HelmCluster dask python api: (: from dask_kubernetes import HelmCluster; cluster = HelmCluster(release_name='yourdask'); cluster.scale(10))"
[kubernetes-operator.src/gh]: https://github.com/dask/dask-kubernetes.git "(BSD-3-Clause) (Languages: Python 93.2%, Go 3.7%, Smarty 1.3%, Other 1.8%) Native Kubernetes integration for Dask // Dask 的原生 Kubernetes 集成"
[kubernetes-operator.pkg.pip/pypi]: https://pypi.org/project/dask-kubernetes/ "(: pip install -- dask-kubernetes) (: from dask_kubernetes.operator import KubeCluster; cluster = KubeCluster(name='your-dask-cluster', image='ghcr.io/dask/dask:latest'); cluster.scale(10) # same as using CRD kind `DaskCluster` by yaml)"
[kubernetes-operator.pkg.oci/ghcr]: https://github.com/dask/dask-kubernetes/pkgs/container/dask-kubernetes-operator "(: docker pull -- ghcr.io/dask/dask-kubernetes-operator:2025.7.0)"
[kubernetes-operator.docs/.site]: https://kubernetes.dask.org "KubeCluster deploys Dask clusters on Kubernetes clusters using custom Kubernetes resources. It is designed to dynamically launch ad-hoc deployments. // KubeCluster 在 Kubernetes 集群上部署 Dask 集群，使用自定义 Kubernetes 资源。它旨在动态地启动临时部署。"
[charts-helm.src/gh]: https://github.com/dask/helm-chart.git "(Languages: YAML 97.5%, Mustache 2.5%) Helm charts for Dask /// This repository contains two Helm charts. // 此存储库包含两个 Helm 图表。 /// - dask: Install Dask on Kubernetes for a single user with Jupyter and dask-kubernetes. // dask: 用于单个用户在 Kubernetes 上安装 Dask，并配备 Jupyter 和 dask-kubernetes。 /// - daskhub: Install Dask on Kubernetes for multiple users with JupyterHub and dask-gateway. // daskhub: 用于多个用户在 Kubernetes 上安装 Dask，并配备 JupyterHub 和 dask-gateway。 /// This repository also contains a gh-pages branch that using GitHub Pages is built into the website available at https://helm.dask.org. This website is human readable but also readable by helm as a Helm chart repository thanks to a index.yaml file. // 该仓库还包含一个 gh-pages 分支，使用 GitHub Pages 构建，并托管在 https://helm.dask.org 网站上。该网站既人类可读，也作为 Helm 图表仓库被 helm 读取，这得益于一个 index.yaml 文件。 /// The Helm chart repository also publishes Helm charts not maintained in this repository, specifically dask-gateway and dask-kubernetes-operator. // Helm 图表仓库还会发布本仓库未维护的 Helm 图表，特别是 dask-gateway 和 dask-kubernetes-operator 。"
[charts-helm.site/.site]: https://helm.dask.org/ "Dask community Helm charts for Kubernetes"
[dask-kubernetes-operator.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/dask-kubernetes-operator "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n dask-operator --generate-name -- dask/dask-kubernetes-operator)"
[dask-gateway.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/dask-gateway "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n dask-gateway --generate-name -- dask/dask-gateway)"
[daskhub.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/daskhub "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n daskhub --generate-name -- dask/daskhub)"
[dask.helm/artifacthub.io]: https://artifacthub.io/packages/helm/dask/dask "(: helm repo add -- dask https://helm.dask.org/ ;: helm install --create-namespace -n dask --generate-name -- dask/dask)"
[gateway.src/gh]: https://github.com/dask/dask-gateway.git "(BSD-3-Clause) (Languages: Python 87.5%, Go 4.6%, Shell 4.3%, Dockerfile 3.2%, Mustache 0.4%) A multi-tenant server for securely deploying and managing Dask clusters. // 一个用于安全部署和管理 Dask 集群的多租户服务器。 /// Dask-Gateway is composed of two packages: // Dask-Gateway 由两个包组成： /// - dask-gateway: the client library, installed by users. // dask-gateway : 客户端库，由用户安装。 /// - dask-gateway-server: the gateway server, installed by administrators. // dask-gateway-server : 网关服务器，由管理员安装。"
[gateway-client.pkg.pip/pypi]: https://pypi.org/project/dask-gateway/ "(: pip install -- dask-gateway) (: pip install -- dask-gateway[kerberos] # Install the kerberos dependencies if your Dask-Gateway server uses Kerberos for authentication // 安装 Kerberos 依赖项若您的 Dask-Gateway 服务器使用 Kerberos 进行身份验证)"
[gateway-client.pkg.oci/ghcr]: https://github.com/dask/dask-gateway/pkgs/container/dask-gateway "(: docker pull -- ghcr.io/dask/dask-gateway:2025.4.0)"
[gateway-server.pkg.pip/pypi]: https://pypi.org/project/dask-gateway-server/ "(: pip install -- dask-gateway-server) (: pip install -- dask-gateway dask-gateway-server[local] # Install Locally for Quickstart) /// To start the Gateway server, run: // 要启动网关服务器，请运行： /// (: dask-gateway-server) /// This starts dask-gateway locally with the default configuration. This uses: // 这将在本地启动 dask-gateway 的默认配置。它使用： /// - UnsafeLocalBackend to manage local clusters without any process isolation // UnsafeLocalBackend 用于管理无需任何进程隔离的本地集群 /// - SimpleAuthenticator to authenticate users using a simple and insecure authentication scheme // SimpleAuthenticator 使用简单且不安全的认证方案来验证用户 /// Both of these options are insecure and not-advised for any real-world deployments. They are perfectly fine for testing and experimentation though. // 这两种选项都不安全，不推荐用于任何实际部署。不过，它们对于测试和实验来说完全合适。 /// To connect to the gateway, create a Gateway client with the URL output above. By default this is http://127.0.0.1:8000. // 要连接到网关，请使用上面输出的 URL 创建一个 Gateway 客户端。默认情况下，这是 http://127.0.0.1:8000 。 /// (: from dask_gateway import Gateway; gateway = Gateway('http://127.0.0.1:8000') ;: gateway #> Gateway<http://127.0.0.1:8000> # see gateway info ;: gateway.list_clusters() #> [] # see clusters in this gateway)"
[gateway-server.pkg.oci/ghcr]: https://github.com/dask/dask-gateway/pkgs/container/dask-gateway-server "(: docker pull -- ghcr.io/dask/dask-gateway-server:2025.4.0)"
[deploy-cli/.docs-stable]: https://docs.dask.org/en/stable/deploying-cli.html "Demo: (: dask scheduler #> Scheduler at:   tcp://192.0.0.100:8786 # launch dask scheduler on main node) (: dask worker tcp://192.0.0.100:8786 # launch dask worker on the rest of the nodes) The workers connect to the scheduler, which then sets up a long-running network connection back to the worker. The workers will learn the location of other workers from the scheduler. // 工作进程连接到调度器，调度器随后建立一条长连接返回到工作进程。工作进程将从调度器那里学习其他工作进程的位置。"
[distributed.src/gh]: https://github.com/dask/distributed.git "(BSD-3-Clause) (Languages: Python 98.9%, Other 1.1%) A distributed task scheduler for Dask // 一个用于 Dask 的分布式任务调度器 /// A library for distributed computation. // 一个用于分布式计算的库。"
[distributed.pkg.pip/pypi]: https://pypi.org/project/distributed/ "(: pip install -- distributed)"
[distributed.docs/.site]: https://distributed.dask.org "Dask.distributed is a lightweight library for distributed computing in Python. It extends both the concurrent.futures and dask APIs to moderate sized clusters. // Dask.distributed 是一个用于 Python 的轻量级分布式计算库。它扩展了 concurrent.futures 和 dask API，适用于中等规模的集群。"
[distributed.qs/.docs]: https://distributed.dask.org/en/stable/quickstart.html "(: pip install -U -- dask distributed) (: dask scheduler #> Scheduler started at 127.0.0.1:8786 # at scheduler node ;: dask worker 127.0.0.1:8786 # run at more worker nodes if 'Scheduler started at 127.0.0.1:8786' output on scheduler node) (:: from dask.distributed import Client; client = Client('127.0.0.1:8786') # connect the scheduler node '127.0.0.1:8786') (:: DATA = range(10); A = client.map(lambda x: x**2, DATA); B = client.map(lambda x: -x, A); total = client.submit(sum, B) # submit calc on cluster by client ;: total.result() #> -285 # result for single future ;: client.gather(A) #> [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] # gather for many futures ;: client.restart() # When things go wrong, or when you want to reset the cluster state, call the restart method.)"
[ml.src/gh]: https://github.com/dask/dask-ml.git "(BSD-3-Clause) (Languages: Python 99.9%, Shell 0.1%) Scalable Machine Learning with Dask // 使用 Dask 进行可扩展机器学习 /// Dask-ML provides scalable machine learning in Python using Dask alongside popular machine learning libraries like Scikit-Learn, XGBoost, and others. // Dask-ML 使用 Dask 结合 Scikit-Learn、XGBoost 等流行的机器学习库，提供可扩展的 Python 机器学习功能。"
[ml.try/mybinder]: https://mybinder.org/v2/gh/dask/dask-examples/main?filepath=machine-learning.ipynb "Try Dask-ML on a small cloud instance // 在小型云实例上尝试 Dask-ML"
[ml.pkg.pip/pypi]: https://pypi.org/project/dask-ml/ "(: pip install -- dask-ml) (: pip install -- dask-ml[complete] # Install all optional dependencies)"
[examples.src/gh]: http://github.com/dask/dask-examples.git "(CC-BY-SA-4.0) (Languages: Jupyter Notebook 97.1%, Python 2.7%, Other 0.2%) Easy-to-run example notebooks for Dask"
[examples.docs/.site]: https://examples.dask.org/ "This repository includes easy-to-run example notebooks for Dask. They are intended to be educational and give users a start on common workflows. // 此存储库包含易于运行的 Dask 示例笔记本。它们旨在提供教育功能，帮助用户了解常见的工作流程。"
[glm.src/gh]: https://github.com/dask/dask-glm.git "(BSD-3-Clause) (Languages: Python 100.0%) Generalized Linear Models in Dask // Dask 中的广义线性模型"
[glm.pkg.pip/pypi]: https://pypi.org/project/dask-glm/ "(: pip install -- dask-glm)"
[glm.docs/readthedocs.io]: https://dask-glm.readthedocs.io/ "Dask-glm is a library for fitting Generalized Linear Models on large datasets // Dask-glm 是一个用于在大型数据集上拟合广义线性模型的库 /// Dask-glm builds on the dask project to fit GLM‘s on datasets in parallel. It offers a scikit-learn compatible API for specifying your model. // Dask-glm 基于 dask 项目，在并行数据集上拟合 GLM。它提供了一个与 scikit-learn 兼容的 API 来指定您的模型。"
[jobqueue.src/gh]: https://github.com/dask/dask-jobqueue.git "(BSD-3-Clause) (Languages: Python 92.9%, Shell 4.8%, Dockerfile 2.3%) Deploy Dask on job schedulers like PBS, SLURM, and SGE // 在 PBS、SLURM 和 SGE 等作业调度器上部署 Dask"
[jobqueue.docs/.site]: https://jobqueue.dask.org "Easily deploy Dask on job queuing systems like PBS, Slurm, MOAB, SGE, LSF, and HTCondor. // 轻松在 PBS、Slurm、MOAB、SGE、LSF 和 HTCondor 等作业队列系统上部署 Dask。 /// The dask-jobqueue project makes it easy to deploy Dask on common job queuing systems typically found in high performance supercomputers, academic research institutions, and other clusters. // dask-jobqueue 项目使得在通常在高性能超级计算机、学术研究机构和其他集群中常见的工作队列系统上部署 Dask 变得容易。 /// There are two common deployment patterns for Dask on HPC, Dynamic Clusters and Batch Runners, and dask-jobqueue has support for both. // 在 HPC 上，Dask 有两种常见的部署模式：动态集群和批处理运行器， dask-jobqueue 都支持这两种模式。"
[jobqueue.pkg.pip/pypi]: https://pypi.org/project/dask-jobqueue/ "(: pip install -- dask-jobqueue)"
[deploy-hpc/.docs-stable]: https://docs.dask.org/en/stable/deploying-hpc.html "(: from dask_jobqueue import PBSCluster; cluster = PBSCluster(cores=36, memory='100GB', project='P48500028', queue='premium', interface='ib0', walltime='02:00:00'); cluster.scale(100) # Start 100 workers in 100 jobs that match the description above) Dask-jobqueue provides a lot of possibilities like adaptive dynamic scaling of workers, we recommend reading the dask-jobqueue documentation first to get a basic system running and then returning to this documentation for fine-tuning if necessary. // dask-jobqueue 提供了许多可能性，例如工作节点的自适应动态扩展。我们建议您首先阅读 dask-jobqueue 文档来搭建基本系统，如有必要，再返回此文档进行精细调整。"
