[site]: https://modin.org/ "Scale your Pandas workflows by changing a single line of code // 通过修改单行代码扩展你的 Pandas 工作流 /// (: import modin.pandas as pd # import pandas as pd )"
[src/gh]: https://github.com/modin-project/modin.git "(Apache-2.0) (Languages: Python 100.0%) Modin: Scale your Pandas workflows by changing a single line of code // Modin：通过修改一行代码扩展您的 Pandas 工作流程 /// Modin is a drop-in replacement for pandas. While pandas is single-threaded, Modin lets you instantly speed up your workflows by scaling pandas so it uses all of your cores. Modin works especially well on larger datasets, where pandas becomes painfully slow or runs out of memory. Also, Modin comes with the additional APIs to improve user experience. // Modin 是 pandas 的即插即用替代品。虽然 pandas 是单线程的，但 Modin 通过扩展 pandas 以使用所有核心，可以即时加速您的 workflows。Modin 在大型数据集上表现尤其出色，在那里 pandas 变得非常缓慢或耗尽内存。此外，Modin 还提供了额外的 API 来改善用户体验。 /// By simply replacing the import statement, Modin offers users effortless speed and scale for their pandas workflows: // 只需替换导入语句，Modin 就为用户提供了对 pandas workflows 无需费力即可实现的速度和扩展： /// (: import modin.pandas as pd # import pandas as pd )"
[pkg.pip/pypi]: https://pypi.org/project/modin/ "(: pip install -- modin)  (: pip install -- modin[ray] ray[default] # Install Modin dependencies and Ray to run on Ray) (: pip install -- modin[dask] # Install Modin dependencies and Dask to run on Dask) (: pip install -- modin[mpi] # Install Modin dependencies and MPI to run on MPI through unidist) (: pip install -- modin[all] # Install all of the above) (:: os.environ['MODIN_ENGINE'] = 'ray' {:or:} modin.config.Engine.put('ray') # Modin will use Ray) (:: os.environ['MODIN_ENGINE'] = 'dask' {:or:} modin.config.Engine.put('dask') # Modin will use Dask) (:: os.environ['MODIN_ENGINE'] = 'unidist' {:or:} modin.config.Engine.put('unidist') # Modin will use Unidist ;;:: os.environ['UNIDIST_BACKEND'] = 'mpi' {:or:} unidist.config.Backend.put('mpi') # Unidist will use MPI backend) /// Note: You should not change the engine after your first operation with Modin as it will result in undefined behavior. // 注意：在使用 Modin 进行第一次操作后，您不应更改引擎，因为这会导致未定义行为。"
[docs/readthedocs.io]: https://modin.readthedocs.io/ "Modin uses Ray, Dask or Unidist to provide an effortless way to speed up your pandas notebooks, scripts, and libraries. Unlike other distributed DataFrame libraries, Modin provides seamless integration and compatibility with existing pandas code. Even using the DataFrame constructor is identical. // Modin 使用 Ray、Dask 或 Unidist 来提供一种轻松的方式，加速你的 pandas 笔记本、脚本和库。与其他分布式 DataFrame 库不同，Modin 提供了与现有 pandas 代码的无缝集成和兼容性。即使使用 DataFrame 构造函数也是完全相同的。 /// It is not necessary to know in advance the available hardware resources in order to use Modin. Additionally, it is not necessary to specify how to distribute or place data. Modin acts as a drop-in replacement for pandas, which means that you can continue using your previous pandas notebooks, unchanged, while experiencing a considerable speedup thanks to Modin, even on a single machine. Once you’ve changed your import statement, you’re ready to use Modin just like you would pandas. // 无需事先了解可用的硬件资源即可使用 Modin。此外，无需指定如何分发或放置数据。Modin 作为 pandas 的即插即用替代品，这意味着即使是在单台机器上，你也可以继续使用你之前未更改的 pandas 笔记本，同时由于 Modin 的作用，体验到显著的加速效果。一旦你更改了导入语句，你就可以像使用 pandas 一样使用 Modin。 /// The modin.pandas DataFrame is an extremely light-weight parallel DataFrame. Modin transparently distributes the data and computation so that all you need to do is continue using the pandas API as you were before installing Modin. Unlike other parallel DataFrame systems, Modin is an extremely light-weight, robust DataFrame. Because it is so light-weight, Modin provides speed-ups of up to 4x on a laptop with 4 physical cores. // modin.pandas DataFrame 是一个极轻量级的并行 DataFrame。Modin 透明地分发数据和计算，因此您只需像安装 Modin 之前那样继续使用 pandas API。与其他并行 DataFrame 系统不同，Modin 是一个极轻量级、健壮的 DataFrame。由于它非常轻量级，Modin 在具有 4 个物理核心的笔记本电脑上可提供高达 4 倍的加速。 /// In pandas, you are only able to use one core at a time when you are doing computation of any kind. With Modin, you are able to use all of the CPU cores on your machine. Even in read_csv, we see large gains by efficiently distributing the work across your entire machine. // 在 pandas 中，当你进行任何计算时，只能使用一个核心。而使用 Modin，你可以使用你机器上的所有 CPU 核心。即使在 read_csv 中，通过高效地分配工作到整个机器，我们也看到了显著的提升。 /// We have focused heavily on bridging the solutions between DataFrames for small data (e.g. pandas) and large data. Often data scientists require different tools for doing the same thing on different sizes of data. The DataFrame solutions that exist for 1MB do not scale to 1TB+, and the overheads of the solutions for 1TB+ are too costly for datasets in the 1KB range. With Modin, because of its light-weight, robust, and scalable nature, you get a fast DataFrame at 1MB and 1TB+. // 我们重点致力于在处理小数据集（例如 pandas）和大数据集的解决方案之间建立桥梁。通常，数据科学家需要针对不同大小的数据使用不同的工具来完成相同任务。针对 1MB 数据集的 DataFrame 解决方案无法扩展到 1TB+，而针对 1TB+数据集的解决方案对于 1KB 范围的数据集来说开销太大。使用 Modin，由于其轻量级、健壮和可扩展的特性，你可以在 1MB 和 1TB+上获得快速 DataFrame。"
[unidist.src/gh]: https://github.com/modin-project/unidist.git "(Apache-2.0) (Languages: Python 99.2%, Other 0.8%) Unified Distributed Execution // 统一分布式执行 /// unidist is a framework that is intended to provide the unified API for distributed execution by supporting various performant execution backends. At the moment the following backends are supported under the hood: // unidist 是一个旨在通过支持各种高性能执行后端来提供统一分布式执行 API 的框架。目前，以下后端在底层得到支持： /// - MPI (. https://mpi-forum.org/ 'The MPI standard includes point-to-point message-passing, collective communications, group and communicator concepts, process topologies, environmental management, process creation and management, one-sided communications, extended collective operations, external interfaces, I/O, some miscellaneous topics, and multiple tool interfaces. Language bindings for C and Fortran are defined. // MPI 标准包括点对点消息传递、集体通信、组和通信器概念、进程拓扑、环境管理、进程创建和管理、单边通信、扩展集体操作、外部接口、I/O、一些杂项主题以及多个工具接口。定义了 C 和 Fortran 的语言绑定。') /// - Dask Distributed (. https://distributed.dask.org/ 'Dask.distributed is a lightweight library for distributed computing in Python. It extends both the concurrent.futures and dask APIs to moderate sized clusters. // Dask.distributed 是一个用于 Python 分布式计算的轻量级库。它扩展了 concurrent.futures 和 dask API，适用于中等规模的集群。') /// - Ray (. https://docs.ray.io/ 'An open source framework to build and scale your ML and Python applications easily') /// - Python Multiprocessing (. https://docs.python.org/3/library/multiprocessing.html 'multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both POSIX and Windows. // multiprocessing 是一个支持使用类似于 threading 模块的 API 来创建进程的包。 multiprocessing 包提供了本地和远程并发，通过使用子进程而不是线程来有效规避全局解释器锁。由于这个特性， multiprocessing 模块允许程序员充分利用给定机器上的多个处理器。它支持 POSIX 和 Windows 系统。') /// unidist is designed to work in a task-based parallel model. // unidist 设计用于基于任务的并行模型。 /// Also, the framework provides a Python Sequential backend (pyseq), that can be used for debugging. // 此外，该框架提供了一个 Python 顺序后端（ pyseq ），可用于调试。"
[unidist.pkg.pip/pypi]: https://pypi.org/project/unidist/ "(: pip install -- unidist # Install unidist with dependencies for Python Multiprocessing and Python Sequential backends)  (: pip install -- unidist[all] # Install unidist with dependencies for all the backends) (: pip install -- unidist[mpi] # Install unidist with dependencies for MPI backend) (: pip install -- unidist[dask] # Install unidist with dependencies for Dask backend) (: pip install -- unidist[ray] # Install unidist with dependencies for Ray backend) Note: There are different MPI implementations, each of which can be used as a backend in unidist. Mapping unidist[mpi] installs mpi4py package, which is just a Python wrapper for MPI. To enable unidist on MPI execution you need to have a working MPI implementation and certain software installed beforehand. Refer to Installation page of the mpi4py documentation for details. Also, you can find some instructions on MPI backend page. // 注意：存在不同的 MPI 实现，它们都可以作为 unidist 的后端使用。映射 unidist[mpi] 会安装 mpi4py 包，该包只是一个 MPI 的 Python 包装器。要在 MPI 执行上启用 unidist，你需要事先有一个可工作的 MPI 实现和某些软件的安装。请参考 mpi4py 文档的安装页面以获取详细信息。此外，你也可以在 MPI 后端页面找到一些说明。 (:: os.environ['UNIDIST_BACKEND'] = 'mpi' {:or:} unidist.config.Backend.put('mpi') # unidist will use MPI) (:: os.environ['UNIDIST_BACKEND'] = 'dask' {:or:} unidist.config.Backend.put('dask') # unidist will use Dask) (:: os.environ['UNIDIST_BACKEND'] = 'ray' {:or:} unidist.config.Backend.put('ray') # unidist will use Ray)"
[unidist.docs/readthedocs.io]: https://unidist.readthedocs.io "(0: unidist.init() # Initialize unidist's backend. MPI is used by default.) (1: @unidist.remote def foo(x): return x * x # Apply a decorator to make `foo` a remote function.) (2: refs = [foo.remote(i) for i in range(4)] # This will run `foo` on a pool of workers in parallel; `refs` will contain object references to actual data.) (3: print(unidist.get(refs)) #> [0, 1, 4, 9] # Get materialized data.) /// script.py: 0~3 in `if __name__ == '__main__':`; shell: (: mpiexec -n 1 python script.py # for MPI backend) (: python script.py # for any other supported backend)"
[unidist.pwby/unidist.docs]: https://unidist.readthedocs.io/en/latest/using_unidist#libraries-powered-by-unidist "Libraries powered by unidist // 由 Unidist 支持的库 /// Here you can find information on which libraries have already been integrated with unidist to use its performant backends to get better performance. // 在这里，您可以找到哪些库已经与 Unidist 集成，以使用其高性能后端来获得更好的性能。 /// - Modin"
[slack]: https://join.slack.com/t/modin-project/shared_invite/zt-yvk5hr3b-f08p_ulbuRWsAfg9rMY3uA
[discuss]: https://discuss.modin.org/
