[src/gh]: https://github.com/simonpcouch/detectors.git "(MIT) (Languages: Python 73.0%, R 27.0%) Prediction Data from GPT Detectors // 来自 GPT 检测器的预测数据 /// detectors is an R data package containing predictions from various GPT detectors. The data is based on the paper: // detectors 是一个包含来自各种 GPT 检测器预测的 R 数据包。这些数据基于以下论文： /// GPT Detectors Are Biased Against Non-Native English Writers. Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric Wu, James Zou. CellPress Patterns. // GPT 检测器对非母语英语写作者存在偏见。Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric Wu, James Zou. CellPress Patterns. /// The study authors carried out a series of experiments passing a number of essays to different GPT detection models. Juxtaposing detector predictions for papers written by native and non-native English writers, the authors argue that GPT detectors disproportionately classify real writing from non-native English writers as AI-generated. // 研究作者进行了一系列实验，将多篇论文分别输入不同的 GPT 检测模型。通过对比母语和非母语英语写作者的论文检测预测结果，作者认为 GPT 检测器过度将非母语英语写作者的真实写作归类为 AI 生成内容。"
[package/cran]: https://cran.r-project.org/web/packages/detectors/ "(Version: 	0.1.0) (Depends: 	R (≥ 2.10)) (Suggests: 	knitr) (Published: 	2023-10-26) (DOI: 	10.32614/CRAN.package.detectors) (Author: 	Simon Couch [cre, aut]) (Maintainer: 	Simon Couch <simonpatrickcouch at gmail.com>) (License: 	MIT + file LICENSE) (NeedsCompilation: 	no) detectors: Prediction Data from GPT Detectors // 检测器：来自 GPT 检测器的预测数据 /// Researchers carried out a series of experiments passing a number of essays to different GPT detection models. Juxtaposing detector predictions for papers written by native and non-native English writers, the authors argue that GPT detectors disproportionately classify real writing from non-native English writers as AI-generated. // 研究人员进行了一系列实验，将多篇论文分别输入不同的 GPT 检测模型。通过对比母语和非母语英语作者撰写的论文的检测器预测结果，作者指出 GPT 检测器不均衡地将非母语英语作者的真实写作归类为 AI 生成。 (src: gh:simonpcouch/detectors.git)"
[paper.doi/cell.com]: https://doi.org/10.1016/j.patter.2023.100779 "(~ https://cell.com/patterns/fulltext/S2666-3899(23)00130-7) GPT detectors are biased against non-native English writers // GPT 检测器对非英语母语者存在偏见 /// Summary // 摘要 /// GPT detectors frequently misclassify non-native English writing as AI generated, raising concerns about fairness and robustness. Addressing the biases in these detectors is crucial to prevent the marginalization of non-native English speakers in evaluative and educational settings and to create a more equitable digital landscape. // GPT 检测器经常将非母语英语写作错误地归类为 AI 生成内容，引发了关于公平性和鲁棒性的担忧。解决这些检测器中的偏见对于防止非母语英语使用者在评估和教育环境中被边缘化，以及创造一个更公平的数字环境至关重要。 /// Introduction  介绍 /// Generative language models based on GPT, such as ChatGPT, have gained significant attention in recent times. Within a mere 2 months of its launch, ChatGPT amassed over 100 million monthly active users, marking its place as one of the fastest-growing consumer internet applications in history.1 Despite their immense potential for enhancing productivity and fostering creativity, these powerful models also pose risks, such as the proliferation of AI-generated content masquerading as human written, which may lead to the spread of fake content and exam cheating. // 基于 GPT 的生成式语言模型，如 ChatGPT，近年来受到了广泛关注。在仅有的 2 个月内，ChatGPT 就吸引了超过 1 亿月活跃用户，成为历史上增长最快的消费者互联网应用之一。 1 尽管这些强大的模型在提高生产力和促进创造力方面具有巨大潜力，但它们也带来了风险，例如 AI 生成内容冒充人类写作的泛滥，这可能导致虚假内容的传播和考试作弊。 /// Educators, in particular, are increasingly concerned about determining when and where students have used AI and AI writing tools in their work. However, multiple studies have demonstrated the difficulty humans face in detecting AI-generated content with the naked eye,2 thus creating an urgent and pressing demand for effective detection methods. While several GPT detectors have been developed and implemented to mitigate the risks associated with AI-generated content, their accuracy, reliability, and effectiveness remain uncertain due to limited evaluation.3 This knowledge gap is especially worrisome given the potentially harmful consequences of mistakenly flagging an innocent student’s work as AI generated.4 // 教育工作者，尤其是，越来越关注确定学生何时何地使用 AI 和 AI 写作工具完成作业。然而，多项研究表明，人类肉眼难以检测 AI 生成的内容， 2 因此迫切需要有效的检测方法。尽管已经开发并实施了几种 GPT 检测器来降低 AI 生成内容的风险，但由于缺乏评估，它们的准确性、可靠性和有效性仍不确定。 3 鉴于错误地将无辜学生的作品标记为 AI 生成可能带来的潜在危害，这一知识空白尤其令人担忧。 4 /// Given the transformative impact of generative language models and the potential risks associated with their misuse, developing trustworthy and accurate detection methods is crucial. In our recent preprint,5,6 we exposed an alarming bias in GPT detectors against non-native English speakers: over half of the non-native English writing samples were misclassified as AI generated, while the accuracy for native samples remained near perfect. Our analysis further revealed a trend where more literary language was classified as more “human”: enhancement of word choice in non-native English writing samples reduced misclassification, while simplifying native writing samples increased it, suggesting that GPT detectors are inadvertently penalizing individuals with limited linguistic proficiency. On the other hand, we found that GPT detectors be easily bypassed by better ChatGPT prompt design. This raises a pivotal question: if AI-generated content can easily evade detection while human text is frequently misclassified, how effective are these detectors truly? // 鉴于生成式语言模型的变革性影响及其潜在的滥用风险，开发可信且准确的检测方法至关重要。在我们的最新预印本中，我们揭露了 GPT 检测器对非英语母语者存在令人担忧的偏见：超过一半的非英语写作样本被错误分类为 AI 生成，而英语母语样本的准确率仍接近完美。我们的分析进一步揭示了一个趋势，即更文学化的语言被分类为更“人类”：非英语写作样本中词汇选择的增强减少了误分类，而简化英语写作样本则增加了误分类，这表明 GPT 检测器无意中在惩罚语言能力有限的人。另一方面，我们发现 GPT 检测器很容易被更好的 ChatGPT 提示设计所绕过。这提出了一个关键问题：如果 AI 生成内容可以轻易逃避检测，而人类文本却经常被误分类，那么这些检测器真的有效吗？ /// Our findings emphasize the need for increased focus on the fairness and robustness of GPT detectors, as overlooking their biases may lead to unintended consequences, such as the marginalization of non-native speakers in evaluative or educational settings. This paper is among the first to systematically examine the biases present in GPT detectors and advocates for further research into addressing these biases and refining the current detection methods to ensure a more equitable and secure digital landscape for all users. // 我们的研究强调了需要更加关注 GPT 检测器的公平性和鲁棒性，因为忽视它们的偏见可能导致意想不到的后果，例如在评估或教育环境中边缘化非母语者。本文是首批系统研究 GPT 检测器中存在偏见并倡导进一步研究以解决这些偏见、改进当前检测方法，以确保所有用户都能在一个更公平、更安全的数字环境中使用。 /// GPT detectors exhibit bias against non-native English authors // GPT 检测器对非英语母语作者存在偏见 /// GPT detectors exhibit significant bias against non-native English authors, as demonstrated by their high misclassification of TOEFL essays written by non-native speakers. In our study, we evaluated the performance of seven widely used GPT detectors on 91 TOEFL (Test of English as a Foreign Language) essays from a Chinese forum and 88 US eighth-grade essays from the Hewlett Foundation’s ASAP dataset. While the detectors accurately classified the US student essays, they incorrectly labeled more than half of the TOEFL essays as \"AI-generated\" (average false-positive rate: 61.3%). All detectors unanimously identified 19.8% of the human-written TOEFL essays as AI authored, and at least one detector flagged 97.8% of TOEFL essays as AI generated. Upon closer inspection, the unanimously identified TOEFL essays exhibited significantly lower text perplexity. Here text perplexity is a measure of how “surprised” or “confused” a generative language model is when trying to guess the next word in a sentence. If a generative language model can predict the next word easily, the text perplexity is low. On the other hand, if the next word is hard to predict, the text perplexity is high. Most GPT detectors use text perplexity to detect AI-generated text, which might inadvertently penalize non-native writers who use a more limited range of linguistic expressions. // GPT 检测器对非英语母语作者存在显著偏见，这一点通过它们对非英语母语者撰写的托福作文的高错误分类率得到了证明。在我们的研究中，我们评估了七种广泛使用的 GPT 检测器在来自中国论坛的 91 篇托福（托福考试）作文和 Hewlett 基金会 ASAP 数据集中的 88 篇美国八年级作文上的表现。虽然检测器准确分类了美国学生的作文，但它们错误地将超过一半的托福作文标记为 \"AI 生成\" （平均假阳性率：61.3%）。所有检测器一致地将 19.8%的人类撰写的托福作文识别为 AI 所写，并且至少有一种检测器将 97.8%的托福作文标记为 AI 生成。仔细检查后，被一致识别的托福作文表现出显著更低的文本困惑度。这里文本困惑度是衡量生成式语言模型在尝试猜测句子中下一个单词时有多 \"惊讶\" 或 \"困惑\" 的指标。如果生成式语言模型能够轻松预测下一个单词，文本困惑度就低。另一方面，如果下一个单词难以预测，文本困惑度就高。 大多数 GPT 检测器使用文本困惑度来检测 AI 生成的文本，这可能会无意中惩罚使用更有限语言表达的母语非写作者。"
[site/ghio]: https://simonpcouch.github.io/detectors/ "(: detectors_plot = data.table::setDT(detectors::detectors)[!is.na(native)] |> ggplot2::ggplot() + ggplot2::aes(x = detector, y = .pred_AI, fill = native) + ggplot2::geom_violin(bw = .05) + ggplot2::labs(x = 'GPT Detector Tool', y = 'Predicted Probability That\nSample Was Written by AI', fill = 'Native\nEnglish\nWriter') + ggplot2::theme_minimal() + ggplot2::scale_fill_brewer(type = 'qual') + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, vjust = 1, hjust = 1)) ;: detectors_plot # show plot)"
[knows_by]: https://simonpcouch.com/software "- detectors // 探测器 /// Prediction Data from GPT Detectors // 来自 GPT 探测器的预测数据"

