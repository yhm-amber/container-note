[src/gh]: https://github.com/modelscope/ms-swift.git "(Apache-2.0) (Languages: Python 99.7%, Other 0.3%) Use PEFT or Full-parameter to CPT/SFT/DPO/GRPO 500+ LLMs (Qwen3, Qwen3-MoE, Llama4, InternLM3, GLM4, Mistral, Yi1.5, DeepSeek-R1, ...) and 200+ MLLMs (Qwen2.5-VL, Qwen2.5-Omni, Qwen2-Audio, Ovis2, InternVL3, Llava, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, DeepSeek-VL2, Phi4, GOT-OCR2, ...). // 使用 PEFT 或全参数 CPT/SFT/DPO/GRPO 500+ LLMs（Qwen3, Qwen3-MoE, Llama4, InternLM3, GLM4, Mistral, Yi1.5, DeepSeek-R1, ...）和 200+ MLLMs（Qwen2.5-VL, Qwen2.5-Omni, Qwen2-Audio, Ovis2, InternVL3, Llava, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, DeepSeek-VL2, Phi4, GOT-OCR2, ...）。 /// SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning) // SWIFT (可扩展轻量级基础设施用于微调) /// 🍲 ms-swift is an official framework provided by the ModelScope community for fine-tuning and deploying large language models and multi-modal large models. It currently supports the training (pre-training, fine-tuning, human alignment), inference, evaluation, quantization, and deployment of 450+ large models and 150+ multi-modal large models. These large language models (LLMs) include models such as Qwen3, Qwen3-MoE, Qwen2.5, InternLM3, GLM4, Mistral, DeepSeek-R1, Yi1.5, TeleChat2, Baichuan2, and Gemma2. The multi-modal LLMs include models such as Qwen2.5-VL, Qwen2-Audio, Llama3.4, Llava, InternVL2.5, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, Yi-VL, DeepSeek-VL2, Phi3.5-Vision, and GOT-OCR2. // ms-swift 是 ModelScope 社区提供的官方框架，用于微调和部署大型语言模型和多模态大型模型。它目前支持 450 多个大型模型和 150 多个多模态大型模型的训练（预训练、微调、人工对齐）、推理、评估、量化以及部署。这些大型语言模型（LLMs）包括 Qwen3、Qwen3-MoE、Qwen2.5、InternLM3、GLM4、Mistral、DeepSeek-R1、Yi1.5、TeleChat2、Baichuan2 和 Gemma2 等模型。多模态 LLMs 包括 Qwen2.5-VL、Qwen2-Audio、Llama3.4、Llava、InternVL2.5、MiniCPM-V-2.6、GLM4v、Xcomposer2.5、Yi-VL、DeepSeek-VL2、Phi3.5-Vision 和 GOT-OCR2 等模型。 /// 🍔 Additionally, ms-swift incorporates the latest training technologies, including lightweight techniques such as LoRA, QLoRA, Llama-Pro, LongLoRA, GaLore, Q-GaLore, LoRA+, LISA, DoRA, FourierFt, ReFT, UnSloth, and Liger, as well as human alignment training methods like DPO, GRPO, RM, PPO, KTO, CPO, SimPO, and ORPO. ms-swift supports acceleration of inference, evaluation, and deployment modules using vLLM and LMDeploy, and it supports model quantization with technologies like GPTQ, AWQ, and BNB. Furthermore, ms-swift offers a Gradio-based Web UI and a wealth of best practices. // 🍔 此外，ms-swift 集成了最新的训练技术，包括轻量级技术如 LoRA、QLoRA、Llama-Pro、LongLoRA、GaLore、Q-GaLore、LoRA+、LISA、DoRA、FourierFt、ReFT、UnSloth 和 Liger，以及人类对齐训练方法如 DPO、GRPO、RM、PPO、KTO、CPO、SimPO 和 ORPO。ms-swift 支持使用 vLLM 和 LMDeploy 加速推理、评估和部署模块，并支持使用 GPTQ、AWQ 和 BNB 等技术进行模型量化。此外，ms-swift 提供基于 Gradio 的 Web UI 和丰富的最佳实践。 /// Why choose ms-swift? // 为什么选择 ms-swift？ /// - 🍎 Model Types: Supports 450+ pure text large models, 150+ multi-modal large models, as well as All-to-All multi-modal models, sequence classification models, and embedding models, covering the entire process from training to deployment. // 🍎 模型类型：支持 450+纯文本大型模型，150+多模态大型模型，以及全全多模态模型、序列分类模型和嵌入模型，涵盖从训练到部署的整个流程。 /// - Dataset Types: Comes with 150+ pre-training, fine-tuning, human alignment, multi-modal datasets, and supports custom datasets. // 数据集类型：包含 150+预训练、微调、人工对齐、多模态数据集，并支持自定义数据集。 /// - Hardware Support: Compatible with CPU, RTX series, T4/V100, A10/A100/H100, Ascend NPU, MPS, etc. // 硬件支持：兼容 CPU、RTX 系列、T4/V100、A10/A100/H100、Ascend NPU、MPS 等。 /// - 🍊 Lightweight Training: Supports lightweight fine-tuning methods like LoRA, QLoRA, DoRA, LoRA+, ReFT, RS-LoRA, LLaMAPro, Adapter, GaLore, Q-Galore, LISA, UnSloth, Liger-Kernel. // 🍊 轻量级训练：支持轻量级微调方法，如 LoRA、QLoRA、DoRA、LoRA+、ReFT、RS-LoRA、LLaMAPro、Adapter、GaLore、Q-Galore、LISA、UnSloth、Liger-Kernel。 /// - Distributed Training: Supports distributed data parallel (DDP), device_map simple model parallelism, DeepSpeed ZeRO2/ZeRO3, FSDP, and other distributed training techniques. // 分布式训练：支持分布式数据并行（DDP）、设备映射简单模型并行、DeepSpeed ZeRO2/ZeRO3、FSDP 以及其他分布式训练技术。 /// - Quantization Training: Supports training quantized models like BNB, AWQ, GPTQ, AQLM, HQQ, EETQ. // 量化训练：支持训练量化模型，如 BNB、AWQ、GPTQ、AQLM、HQQ、EETQ。 /// - RLHF Training: Supports human alignment training methods such as DPO, GRPO, RM, PPO, KTO, CPO, SimPO, ORPO for both pure text and multi-modal large models. // RLHF 训练：支持 DPO、GRPO、RM、PPO、KTO、CPO、SimPO、ORPO 等人类对齐训练方法，适用于纯文本和多模态大型模型。 /// - 🍓 Multi-Modal Training: Supports training on different modalities like images, videos, and audio, for tasks like VQA, captioning, OCR, and grounding. // 🍓 多模态训练：支持在图像、视频和音频等不同模态上进行训练，用于 VQA、字幕、OCR 和定位等任务。 /// - Interface Training: Provides capabilities for training, inference, evaluation, quantization through an interface, completing the whole large model pipeline. // 接口训练：通过接口提供训练、推理、评估、量化等功能，完成整个大模型管道。 /// - Plugin and Extension: Supports custom model and dataset extensions, as well as customization of components like loss, metric, trainer, loss-scale, callback, optimizer. // 插件和扩展：支持自定义模型和数据集扩展，以及组件如损失、度量、训练器、损失缩放、回调、优化器的自定义。 /// - 🍉 Toolbox Capabilities: Offers not only training support for large models and multi-modal large models but also covers the entire process of inference, evaluation, quantization, and deployment. // 🍉 工具箱功能：不仅提供大型模型和多模态大型模型的训练支持，还涵盖推理、评估、量化以及部署的整个过程。 /// - Inference Acceleration: Supports inference acceleration engines like PyTorch, vLLM, LmDeploy, and provides OpenAI API for accelerating inference, deployment, and evaluation modules. // 推理加速：支持 PyTorch、vLLM、LmDeploy 等推理加速引擎，并提供 OpenAI API 以加速推理、部署和评估模块。 /// - Model Evaluation: Uses EvalScope as the evaluation backend and supports evaluation on 100+ datasets for both pure text and multi-modal models. // 模型评估：使用 EvalScope 作为评估后端，支持对 100+数据集进行纯文本和多模态模型的评估。 /// - Model Quantization: Supports AWQ, GPTQ, and BNB quantized exports, with models that can use vLLM/LmDeploy for inference acceleration and continue training. // 模型量化：支持 AWQ、GPTQ 和 BNB 量化导出，支持使用 vLLM/LmDeploy 进行推理加速并继续训练的模型。"

[qs.zh/docs]: https://swift.readthedocs.io/zh-cn/latest/GetStarted/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B.html
