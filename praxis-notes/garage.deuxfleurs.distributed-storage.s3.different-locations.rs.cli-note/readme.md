[src/gh]: https://git.deuxfleurs.fr/Deuxfleurs/garage.git "(AGPL-3.0) (Languages: Rust 94.9%, Shell 1.7%, Clojure 1.6%, Nix 1.1%, Python 0.5%, other 0.2%) S3-compatible object store for small self-hosted geo-distributed deployments // 适用于小型自托管地理分布式部署的 S3 兼容对象存储 /// Garage // 车库"
[mirror.src/gh]: https://github.com/deuxfleurs-org/garage.git "(AGPL-3.0) (Languages: Rust 94.4%, Clojure 1.8%, Shell 1.8%, Nix 1.2%, Python 0.6%, Smarty 0.2%) (Mirror) S3-compatible object store for small self-hosted geo-distributed deployments. // （镜像）适用于小型自托管地理分布式部署的 S3 兼容对象存储。 /// Garage is an S3-compatible distributed object storage service designed for self-hosting at a small-to-medium scale. // Garage 是一款与 S3 兼容的分布式对象存储服务，专为中小规模的自托管而设计。 /// Garage is designed for storage clusters composed of nodes running at different physical locations, in order to easily provide a storage service that replicates data at these different locations and stays available even when some servers are unreachable. Garage also focuses on being lightweight, easy to operate, and highly resilient to machine failures. // Garage 专为由运行在不同物理位置的节点组成的存储集群而设计，旨在轻松提供数据复制服务，确保数据在不同位置的可用性，即使部分服务器无法访问也能保持数据可用。Garage 还注重轻量级、易操作性和高容错性，能够有效应对机器故障。 /// Garage is built by Deuxfleurs (. web: deuxfleurs.fr), an experimental small-scale self hosted service provider, which has been using it in production since its first release in 2020. // Garage 由 Deuxfleurs 构建，Deuxfleurs 是一家实验性的小型自托管服务提供商，自 2020 年首次发布以来一直在生产环境中使用 Garage。"
[site/fr]: https://garagehq.deuxfleurs.fr/ "An S3 object store so reliable you can run it outside datacenters // S3 对象存储非常可靠，可以在数据中心之外运行。 /// - Host a Website // 托管网站 /// - Store Media // 商店媒体 /// - Backup Target // 备份目标 /// Made for redundancy // 为冗余而设计 /// Each chunk of data is replicated in 3 zones // 每个数据块都在 3 个区域中进行复制 /// Our Goals // 我们的目标 /// We made it lightweight and kept the efficiency in mind: // 我们力求轻量化，同时兼顾效率： /// - Self-contained // 自给自足 ///: We ship a single dependency-free binary that runs on all Linux distributions // 我们提供一个无需依赖项的单一二进制文件，可在所有 Linux 发行版上运行。 /// - Fast to deploy, safe to operate // 部署快捷，操作安全 ///: We are sysadmins, we know the value of operator-friendly software // 我们是系统管理员，我们深知操作友好的软件的价值。 /// - Deploy everywhere on every machine // 可部署在所有机器上 ///: We do not have a dedicated backbone, and neither do you, so we made software that run over the Internet across multiple datacenters // 我们没有专门的骨干网，你们也没有。因此，我们开发了可以在多个数据中心通过互联网运行的软件。 /// - Highly resilient // 极强的适应能力 ///: to network failures, network latency, disk failures, sysadmin failures // 在网络故障、网络延迟、磁盘故障、系统管理故障方面 /// Keeping requirements low // 保持低要求 /// We worked hard to keep requirements as low as possible: // 我们努力将要求降到最低： /// - CPU // 中央处理器 ///: Any x86_64 CPU from the last 10 years, ARMv7 or ARMv8 // 过去 10 年内的任何 x86_64 CPU，ARMv7 或 ARMv8 架构均可。 /// - RAM // 内存 ///: 1 GB /// - Disk space // 磁盘空间 ///: At least 16 GB // 至少 16 GB /// - Network // 网络 ///: 200 ms or less, 50 Mbps or more // 200 毫秒延迟或更短， 50Mbps 带宽或更高 /// - Heterogeneous hardware // 异构硬件 ///: Build a cluster with whatever second-hand machines are available // 利用所有可用的二手机器搭建一个集群。"
[cli.cargo/crates]: https://crates.io/crates/garage "(: cargo install -- garage) (AGPL-3.0) (3.5K SLoC) (85.3 KiB) garage // 车库 /// Garage, an S3-compatible distributed object store for self-hosted deployments // Garage，一个与 S3 兼容的分布式对象存储，适用于自托管部署。 (src: git-deuxfleurs: Deuxfleurs/garage.git, gh-mirror: deuxfleurs-org/garage.git)"
[cli.oci/dockerhub]: https://hub.docker.com/r/dxflrs/garage "(: docker pull -- docker.io/dxflrs/garage) (* Sponsored OSS) Deploying and configuring Garage // 部署和配置车库 /// On each machine, we will have a similar setup, especially you must consider the following folders/files: // 每台机器的配置都类似，尤其要注意以下文件夹/文件： /// - /etc/garage.toml: Garage daemon's configuration (see below) // /etc/garage.toml 守护进程的配置文件（见下文） /// - /var/lib/garage/meta/: Folder containing Garage's metadata, put this folder on a SSD if possible // /var/lib/garage/meta/ ：包含 Garage 元数据的文件夹，如果可能，请将此文件夹放在 SSD 上。 /// - /var/lib/garage/data/: Folder containing Garage's data, this folder will be your main data storage and must be on a large storage (e.g. large HDD) // /var/lib/garage/data/ ：包含 Garage 数据的文件夹，此文件夹将是您的主要数据存储位置，必须位于大容量存储设备（例如大容量硬盘）上。 /// (: docker run -d --name garaged --restart always --network host -v /etc/garage.toml:/etc/garage.toml -v /var/lib/garage/meta:/var/lib/garage/meta -v /var/lib/garage/data:/var/lib/garage/data -- docker.io/dxflrs/garage)"
[docs/.site]: https://garagehq.deuxfleurs.fr/documentation/ "Prerequisites // 先决条件 /// To run a real-world deployment, make sure the following conditions are met: // 要进行实际部署，请确保满足以下条件： /// - You have at least three machines with sufficient storage space available. // 您至少有三台机器拥有足够的存储空间。 /// - Each machine has an IP address which makes it directly reachable by all other machines. In many cases, nodes will be behind a NAT and will not each have a public IPv4 addresses. In this case, is recommended that you use IPv6 for this end-to-end connectivity if it is available. Otherwise, using a mesh VPN such as Nebula (. gh: slackhq/nebula.git) or Yggdrasil (. web: yggdrasil-network.github.io) are approaches to consider in addition to building out your own VPN tunneling. // 每台机器都有一个 IP 地址，因此其他所有机器都可以直接访问它。 在许多情况下，节点会位于 NAT 之后，并且并非每个节点都拥有公网 IP 地址。 IPv4 地址。在这种情况下，建议您使用 IPv6。 如果条件允许，请使用端到端连接。否则，请使用网状 VPN，例如： 星云或 除了构建自己的 VPN 隧道之外， Yggdrasil 也是值得考虑的方法。 /// - This guide will assume you are using Docker containers to deploy Garage on each node. Garage can also be run independently, for instance as a Systemd service. You can also use an orchestrator such as Nomad or Kubernetes to automatically manage Docker containers on a fleet of nodes. // 本指南假设您使用 Docker 容器在每个节点上部署 Garage。Garage 也可以独立运行，例如作为 Systemd 服务运行。您还可以使用 Nomad 或 Kubernetes 等编排工具来自动管理节点集群上的 Docker 容器。 /// Note that Garage will always store the three copies of your data on nodes at different locations. This means that in the case of this small example, the usable capacity of the cluster is in fact only 1.5 TB, because nodes in Brussels can't store more than that. This also means that nodes in Paris and London will be under-utilized. To make better use of the available hardware, you should ensure that the capacity available in the different locations of your cluster is roughly the same. For instance, here, the Mercury node could be moved to Brussels; this would allow the cluster to store 2 TB of data in total. // 请注意，Garage 会始终将您的数据以三份副本的形式存储在不同位置的节点上。这意味着，在这个小示例中，集群的可用容量实际上只有 1.5 TB，因为布鲁塞尔的节点无法存储超过这个容量的数据。这也意味着巴黎和伦敦的节点将无法充分利用。为了更好地利用现有硬件，您应该确保集群不同位置的可用容量大致相同。例如，可以将 Mercury 节点迁移到布鲁塞尔；这样集群总共就可以存储 2 TB 的数据。 /// Best practices // 最佳实践 /// - If you have reasonably fast networking between all your nodes, and are planing to store mostly large files, bump the block_size configuration parameter to 10 MB (block_size = '10M'). // 如果您所有节点之间的网络连接速度都相当快，并且计划主要存储大文件，请将 block_size 配置参数增加到 10 MB（ block_size = '10M' ）。 /// - Garage stores its files in two locations: it uses a metadata directory to store frequently-accessed small metadata items, and a data directory to store data blocks of uploaded objects. Ideally, the metadata directory would be stored on an SSD (smaller but faster), and the data directory would be stored on an HDD (larger but slower). // Garage 将文件存储在两个位置：元数据目录用于存储经常访问的小型元数据项，数据目录用于存储已上传对象的数据块。理想情况下，元数据目录应存储在 SSD（容量较小但速度更快）上，而数据目录应存储在 HDD（容量较大但速度较慢）上。 /// - For the data directory, Garage already does checksumming and integrity verification, so there is no need to use a filesystem such as BTRFS or ZFS that does it. We recommend using XFS for the data partition, as it has the best performance. EXT4 is not recommended as it has more strict limitations on the number of inodes, which might cause issues with Garage when large numbers of objects are stored. // 对于数据目录，Garage 已经实现了校验和与完整性验证，因此无需使用 BTRFS 或 ZFS 等提供此功能的文件系统。我们建议数据分区使用 XFS，因为它性能最佳。不建议使用 EXT4，因为它对 inode 数量的限制更为严格，当存储大量对象时可能会导致 Garage 出现问题。 /// - Servers with multiple HDDs are supported natively by Garage without resorting to RAID, see our dedicated documentation page (. {.docs}/operations/multi-hdd). // Garage 原生支持配备多个 HDD 的服务器，无需使用 RAID，请参阅我们的专用文档页面 。 /// - For the metadata storage, Garage does not do checksumming and integrity verification on its own, so it is better to use a robust filesystem such as BTRFS or ZFS. Users have reported that when using the LMDB database engine (the default), database files have a tendency of becoming corrupted after an unclean shutdown (e.g. a power outage), so you should take regular snapshots to be able to recover from such a situation. This can be done using Garage's built-in automatic snapshotting (since v0.9.4), or by using filesystem level snapshots. If you cannot do so, you might want to switch to Sqlite which is more robust. // 对于元数据存储，Garage 本身并不进行校验和及完整性验证，因此最好使用 BTRFS 或 ZFS 等更强大的文件系统。用户反馈，使用 LMDB 数据库引擎（默认引擎）时，数据库文件在非正常关机（例如断电）后容易损坏，因此应定期创建快照以便从此类情况中恢复。您可以使用 Garage 内置的自动快照功能（自 v0.9.4 版本起）或使用文件系统级快照来实现这一点。如果无法做到这一点，您可以考虑切换到更强大的 SQLite 数据库。 /// - LMDB is the fastest and most tested database engine, but it has the following weaknesses: 1/ data files are not architecture-independent, you cannot simply move a Garage metadata directory between nodes running different architectures, and 2/ LMDB is not suited for 32-bit platforms. Sqlite is a viable alternative if any of these are of concern. // LMDB 是速度最快、测试最充分的数据库引擎，但它也存在以下缺点：1/ 数据文件并非架构无关，您无法简单地在运行不同架构的节点之间移动 Garage 元数据目录；2/ LMDB 不适用于 32 位平台。如果您担心上述任何问题，SQLite 是一个可行的替代方案。 /// - If you only have an HDD and no SSD, it's fine to put your metadata alongside the data on the same drive, but then consider your filesystem choice wisely (see above). Having lots of RAM for your kernel to cache the metadata will help a lot with performance. The default LMDB database engine is the most tested and has good performance. // 如果你只有一块机械硬盘 (HDD) 而没有固态硬盘 (SSD)，可以将元数据和数据放在同一块硬盘上，但之后要谨慎选择文件系统（参见上文）。为内核分配足够的内存来缓存元数据，将大大提升性能。默认的 LMDB 数据库引擎经过了最多的测试，性能良好。"
[blog/.site]: https://garagehq.deuxfleurs.fr/blog/ "This is our developer journal // 这是我们的开发者日志"
[ref.paper:Dynamo/acm]: https://dl.acm.org/doi/abs/10.1145/1323293.1294281 "Dynamo: Amazon’s Highly Available Key-value Store by DeCandia et al. // Dynamo：亚马逊的高可用性键值存储 DeCandia 等人 /// Dynamo: amazon's highly available key-value store // Dynamo：亚马逊的高可用性键值存储 /// Reliability at massive scale is one of the biggest challenges we face at Amazon.com, one of the largest e-commerce operations in the world; even the slightest outage has significant financial consequences and impacts customer trust. The Amazon.com platform, which provides services for many web sites worldwide, is implemented on top of an infrastructure of tens of thousands of servers and network components located in many datacenters around the world. At this scale, small and large components fail continuously and the way persistent state is managed in the face of these failures drives the reliability and scalability of the software systems. // 在亚马逊（Amazon.com）——全球最大的电子商务平台之一——面临的最大挑战之一就是大规模可靠性；即使是最轻微的故障也会造成巨大的经济损失，并影响客户信任。亚马逊平台为全球众多网站提供服务，其基础设施由分布在全球各地数据中心的数万台服务器和网络组件构成。在如此庞大的规模下，各种大小组件都会持续发生故障，而如何管理持久状态以应对这些故障，直接决定了软件系统的可靠性和可扩展性。 /// This paper presents the design and implementation of Dynamo, a highly available key-value storage system that some of Amazon's core services use to provide an \"always-on\" experience. To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use. // 本文介绍了 Dynamo 的设计和实现，Dynamo 是一个高可用性的键值存储系统，亚马逊的一些核心服务使用它来提供“始终在线”的体验。为了实现这种高可用性，Dynamo 在某些故障情况下牺牲了数据一致性。它广泛利用对象版本控制和应用辅助冲突解决机制，并为开发人员提供了一种新颖的接口。"
[ref.paper:Conflict-Free-Replicated-Data-Types/hal]: https://inria.hal.science/inria-00609399 "Conflict-Free Replicated Data Types by Shapiro et al. // 无冲突复制数据类型 Shapiro 等人"
[ref.paper:Maglev/usenix]: https://usenix.org/conference/nsdi16/technical-sessions/presentation/eisenbud "Maglev: A Fast and Reliable Software Network Load Balancer by Eisenbud et al. // 磁悬浮：一种快速可靠的软件网络负载均衡器 Eisenbud 等人 /// Maglev is Google’s network load balancer. It is a large distributed software system that runs on commodity Linux servers. Unlike traditional hardware network load balancers, it does not require a specialized physical rack deployment, and its capacity can be easily adjusted by adding or removing servers. Network routers distribute packets evenly to the Maglev machines via Equal Cost Multipath (ECMP); each Maglev machine then matches the packets to their corresponding services and spreads them evenly to the service endpoints. To accommodate high and ever-increasing traffic, Maglev is specifically optimized for packet processing performance. A single Maglev machine is able to saturate a 10Gbps link with small packets. Maglev is also equipped with consistent hashing and connection tracking features, to minimize the negative impact of unexpected faults and failures on connection-oriented protocols. Maglev has been serving Google’s traffic since 2008. It has sustained the rapid global growth of Google services, and it also provides network load balancing for Google Cloud Platform. // Maglev 是谷歌的网络负载均衡器。它是一个运行在通用 Linux 服务器上的大型分布式软件系统。与传统的硬件网络负载均衡器不同，它无需专门的物理机架部署，并且可以通过添加或移除服务器轻松调整其容量。网络路由器通过等价多路径 (ECMP) 将数据包均匀地分发到各个 Maglev 服务器；每个 Maglev 服务器随后将数据包匹配到相应的服务，并将其均匀地分发到各个服务端点。为了应对不断增长的高流量，Maglev 专门针对数据包处理性能进行了优化。单个 Maglev 服务器能够以小数据包饱和 10Gbps 的链路。Maglev 还配备了一致性哈希和连接跟踪功能，以最大限度地减少意外故障对面向连接的协议的负面影响。自 2008 年以来，Maglev 一直为谷歌的流量提供服务。它支撑了谷歌服务的全球快速增长，并为谷歌云平台提供网络负载均衡。"
[mail]: mailto:garagehq@deuxfleurs.fr

