[src/gh]: https://github.com/tidyverse/ellmer.git "(MIT) (Languages: R 100%) Call LLM APIs from R // 从 R 调用 LLM API /// ellmer supports a wide variety of model providers: // ellmer 支持多种模型提供者： /// - Anthropic’s Claude: chat_anthropic(). /// - AWS Bedrock: chat_aws_bedrock(). /// - Azure OpenAI: chat_azure_openai(). /// - Cloudflare: chat_cloudflare(). /// - Databricks: chat_databricks(). /// - DeepSeek: chat_deepseek(). /// - GitHub model marketplace: chat_github(). /// - Google Gemini/Vertex AI: chat_google_gemini(), chat_google_vertex(). /// - Groq: chat_groq(). /// - Hugging Face: chat_huggingface(). /// - Mistral: chat_mistral(). /// - Ollama: chat_ollama(). /// - OpenAI: chat_openai(). /// - OpenRouter: chat_openrouter(). /// - perplexity.ai: chat_perplexity(). /// - Snowflake Cortex: chat_snowflake() and chat_cortex_analyst(). /// - VLLM: chat_vllm(). /// Chat objects are stateful [R6 objects] (. web: r6.r-lib.org): they retain the context of the conversation, so each new query builds on the previous ones. You call their methods with `$`. // 聊天对象是具有状态的 R6 对象：它们保留对话的上下文，因此每个新的查询都建立在之前的基础上。您使用 `$` 调用它们的方法。 /// ellmer comes with a bunch of vignettes to help you learn more: // ellmer 提供了一系列的 vignettes 来帮助你学习更多： /// - Learn key vocabulary and see example use cases in vignette('ellmer'). // 在 vignette('ellmer') 中学习关键词汇并查看示例用例。 /// - Learn how to design your prompt in vignette('prompt-design'). // 在 vignette('prompt-design') 中学习如何设计你的提示。 /// - Learn about tool/function calling in vignette('tool-calling'). // 了解 vignette('tool-calling') 中的工具/函数调用。 /// - Learn how to extract structured data in vignette('structured-data'). // 学习如何在 vignette('structured-data') 中提取结构化数据。 /// - Learn about streaming and async APIs in vignette('streaming-async'). // 了解 vignette('streaming-async') 中的流式和异步 API。"
[site/tidyverse]: https://ellmer.tidyverse.org/ "ellmer makes it easy to use large language models (LLM) from R. It supports a wide variety of LLM providers and implements a rich set of features including streaming outputs, tool/function calling, structured data extraction, and more. // ellmer 可以轻松使用 R 语言中的大型语言模型（LLM）。它支持多种 LLM 提供商，并实现了一系列丰富的功能，包括流式输出、工具/函数调用、结构化数据提取等。 /// ellmer is one of a number of LLM-related packages created by Posit: // ellmer 是 Posit 开发的众多 LLM 相关包之一： /// - Looking for something similar in python? Check out chatlas (. gh: posit-dev/chatlas.git)! // 在 Python 中寻找类似的功能？可以看看 chatlas！ /// - Want to evaluate your LLMs? Try vitals (. web: vitals.tidyverse.org). // 想评估你的 LLMs？试试 vitals。 /// - Need RAG? Take a look at ragnar (. web: ragnar.tidyverse.org). // 需要 RAG？看看 ragnar。 /// - Want to make a beautiful LLM powered chatbot? Consider shinychat (. web: posit-dev.github.io/shinychat). // 想制作一个美丽的 LLM 驱动聊天机器人？考虑 shinychat。 /// - Working with MCP? Check out mcptools (. web: posit-dev.github.io/mcptools). // 使用 MCP？查看 mcptools。"
[package/cran]: https://cran.r-project.org/web/packages/ellmer/ "(Version: 	0.3.2) (Depends: 	R (≥ 4.1)) (Imports: 	cli, coro (≥ 1.1.0), glue, httr2 (≥ 1.2.1), jsonlite, later (≥ 1.4.0), lifecycle, promises (≥ 1.3.1), R6, rlang (≥ 1.1.0), S7 (≥ 0.2.0)) (Suggests: 	connectcreds, curl (≥ 6.0.1), gargle, gitcreds, jose, knitr, magick, openssl, paws.common, rmarkdown, shiny, shinychat (≥ 0.2.0), testthat (≥ 3.0.0), vcr (≥ 2.0.0), withr) (Published: 	2025-09-03) (DOI: 	10.32614/CRAN.package.ellmer) (Author: 	Hadley Wickham ORCID iD [aut, cre], Joe Cheng [aut], Aaron Jacobs [aut], Garrick Aden-Buie ORCID iD [aut], Barret Schloerke ORCID iD [aut], Posit Software, PBC ROR ID [cph, fnd]) (Maintainer: 	Hadley Wickham <hadley at posit.co>) (License: 	MIT + file LICENSE) (NeedsCompilation: 	no) ellmer: Chat with Large Language Models // ellmer：与大型语言模型聊天 /// Chat with large language models from a range of providers including 'Claude' <https://claude.ai>, 'OpenAI' <https://chatgpt.com>, and more. Supports streaming, asynchronous calls, tool calling, and structured data extraction. // 从包括'Claude' < https://claude.ai>、'OpenAI' < https://chatgpt.com>等众多提供者处与大型语言模型聊天。支持流式传输、异步调用、工具调用和结构化数据提取。 (src: gh:tidyverse/ellmer.git)"
