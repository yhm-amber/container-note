[src/gh]: https://github.com/sammyuri/craftgpt.git "(MIT) (Python: 100%) Small language model built in Minecraft. // 在 Minecraft 中构建的小型语言模型。 /// A small language model built to run in Minecraft, trained on the TinyChat dataset (. hf-ds: starhopp3r/TinyChat.git). // 一个为在 Minecraft 中运行而构建的小型语言模型，使用 TinyChat 数据集进行训练。 /// Before attempting to run CraftGPT, please be aware that you shouldn't have high expectations. The model is very prone to going off topic, producing responses that are not grammatically correct, or simply outputting garbage. The model also has a very small context window of only 64 tokens. The conversations in the showcase video show the model at its best, not necessarily at its average performance. // 在尝试运行 CraftGPT 之前，请注意不要抱有太高期望。该模型非常容易跑题，生成的回复可能语法不正确，或者仅仅是输出乱码。此外，该模型的上下文窗口非常小，只有 64 个 token。展示视频中的对话展示了模型的最佳表现，但不一定是其平均性能。 /// MCHPRS (. gh:MCHPR/MCHPRS.git) is essential for running CraftGPT within a reasonable amount of time. It's built using vanilla redstone mechanics, and should work in vanilla, but it could take upwards of 10 years to generate a response without increasing the tick rate. So if you don't have that long to wait, follow the instructions to install MCHPRS first. // MCHPRS 对于在合理时间内运行 CraftGPT 至关重要。它使用原版红石机制构建，应该可以在原版 Minecraft 中运行，但如果不在提高刻度速率的情况下，生成一个回复可能需要长达 10 年的时间。因此，如果你没有那么长时间等待，请先按照说明安装 MCHPRS。 /// Even with MCHPRS it can still take hours to generate a response, so I also strongly recommend you try inputting your prompt on the emulator first (and potentially try some different RNG seeds). // 即使使用 MCHPRS，生成响应仍然可能需要数小时，因此我强烈建议您首先在模拟器中输入您的提示（并可能尝试一些不同的 RNG 种子）。 /// There's no reset or backspace button. If you want to reset it, the quickest way is just to load a fresh copy of the world, although it can be manually reset by pushing the button behind the screen, the buttons at all the attention block token counters, and clearing the input buffers. // 没有重置或退格按钮。如果你想重置它，最快的方法是加载一个全新的世界副本，尽管可以通过按屏幕后面的按钮、所有注意力块令牌计数器的按钮以及清除输入缓冲区来手动重置。"
[intro/gekko.de]: https://gpt.gekko.de/craftgpt-minecraft-redstone-llm/ "An LLM Made of Redstone Bricks: What CraftGPT Really Teaches Us // 一个由红石砖制成的 LLM：CraftGPT 究竟教会了我们什么 /// A few times a decade, someone takes an idea that sounds like a joke and executes it with surgical patience. CraftGPT is one of those moments: a small language model that runs inside Minecraft, wired up from Redstone like a cathedral of logic gates. The project comes from sammyuri, who released the world and code on GitHub. It’s trained on a tiny conversational dataset, runs inference in-game, and—on ordinary, “vanilla” tick rates—would need roughly a decade to answer you once. With the special high-performance Redstone server MCHPRS, the reply still takes hours. That’s not a criticism; it’s the point. // 每隔十年左右，总有人将一个听起来像玩笑的想法，以手术般的耐心付诸实践。CraftGPT 就是这样的时刻之一：一个在 Minecraft 中运行的小型语言模型，像逻辑门的大教堂一样由红石连接起来。该项目来自 sammyuri，他在 GitHub 上发布了世界和代码。它基于一个微小的对话数据集进行训练，在游戏中运行推理，并且在普通的“香草”tick 速率下，回答你一次大约需要十年。使用特殊的红石高性能服务器 MCHPRS，回复仍然需要数小时。这不是批评；这正是其要点。 /// Redstone computers have been part of the culture almost since the ore first glittered. Early on, players built ALUs and memory out of torches and dust—Wired covered a 16-bit arithmetic unit back in 2010. Communities like Open Redstone Engineers turned this tinkering into curricula. And the projects kept escalating: sammyuri’s CHUNGUS II brought “Minecraft in Minecraft,” while other builders got DOOM running on in-game CPUs like IRIS. CraftGPT is the natural, slightly deranged next chapter: “okay, now do an LLM.” // 红石计算机几乎是自从矿石第一次闪耀起就成为了文化的一部分。早期，玩家们用火把和灰尘构建 ALU 和内存——Wired 在 2010 年报道了一个 16 位算术单元。像 Open Redstone Engineers 这样的社区将这种捣鼓变成了课程。而项目不断升级：sammyuri 的 CHUNGUS II 带来了“在 Minecraft 中玩 Minecraft”，而其他建造者则在游戏内的 CPU（如 IRIS）上运行 DOOM。CraftGPT 是自然而略带疯狂的下一章：“好吧，现在做一个 LLM。” /// “When will the LLM Turing machine arrive?” // “LLM 图灵机何时到来？” /// If by that you mean “when will a language model be a general computer?” then the honest answer is: it depends on your definitions and your patience. // 如果你指的是“语言模型何时能成为通用计算机？”那么诚实的答案是：这取决于你的定义和你的耐心。 /// - Minecraft Redstone is widely regarded as Turing-complete—you can, in principle, build machines that compute anything computable. (You’ll run out of time and chunks first.) // Minecraft 红石被广泛认为具有图灵完备性——原则上，你可以建造能够计算任何可计算事物的机器。（首先你会耗尽时间和区块。） /// - Neural networks: classical results show certain recurrent neural nets are Turing-complete under idealized conditions (unbounded precision/time). Whether transformers meet the bar depends on assumptions: some proofs achieve completeness with tweaks (hard attention, unbounded context, or other idealizations), while other work argues vanilla, fixed-precision transformers are not Turing-complete. The debate is lively and technical. // 神经网络：经典结果表明，在理想化条件下（无界精度/时间），某些循环神经网络是图灵完备的。Transformer 是否达到这一标准取决于假设：一些证明通过调整（如硬注意力、无界上下文或其他理想化条件）实现了完备性，而其他研究则认为普通的、固定精度的 Transformer 不是图灵完备的。这场辩论非常活跃且技术性强。 /// So the “LLM Turing machine” is both here and not here: theoretically close under certain formalisms, practically bounded by precision, context, and compute. CraftGPT dramatizes those bounds in the most literal way possible—by making you walk past them at block scale. // 所以，“LLM 图灵机”既在这里又不在：在某种形式化体系下理论上很接近，但在实际中受限于精度、上下文和计算能力。CraftGPT 以最直白的方式戏剧化地展现了这些限制——通过让你以方块规模穿过它们。 /// Why this matters (beyond the spectacle) // 这为何重要（超越轰动效应） /// - Interpretability by construction. When a weight is a physical structure, your intuitions sharpen. That doesn’t make modern frontier models simple—but it teaches the right habit: treat the network as a mechanism you can reason about, optimize, and constrain. // 通过设计实现可解释性。当权重是一个物理结构时，你的直觉会变得更加敏锐。这并不使现代前沿模型变得简单——但它教会了正确的习惯：将网络视为一个你可以推理、优化和约束的机制。 /// - Cost and latency are first-class citizens. After two hours per answer, “fast enough” will never sound like fluff in a design review again. // 成本和延迟是首要考虑因素。每回答两小时后，“足够快”在设计评审中再也不会听起来像空话了。 /// - Respect the substrate. GPUs, TPUs, FPGAs—or Redstone—aren’t interchangeable veneers. They shape what’s feasible, cheap, and observable. CraftGPT is a love letter to substrates. // 尊重基础。GPU、TPU、FPGA——或者红石——都不是可以随意替换的面具。它们决定了什么是可行的、廉价的、可观察的。CraftGPT 是对基础的一种致敬。"
[intro/windowsforum.com]: https://windowsforum.com/threads/craftgpt-a-5-million-parameter-transformer-built-with-minecraft-redstone.383016/ "CraftGPT: A 5 Million Parameter Transformer Built with Minecraft Redstone // CraftGPT: 一个用 Minecraft 红石构建的 500 万参数 Transformer /// Sammyuri’s CraftGPT is more than a stunt — it is a fully working, if glacial, small language model assembled entirely out of Minecraft’s Redstone mechanics, packing roughly 5.09 million parameters into a physical structure of hundreds of millions of blocks and proving, in spectacular fashion, that Minecraft can be pushed into the realm of real computation. // Sammyuri 的 CraftGPT 不仅仅是一个花招——它是一个完全可工作、但运行缓慢的小型语言模型，完全由 Minecraft 的 Redstone 机制组装而成，将大约 5.09 百万个参数打包进数亿个方块构成的物理结构中，并以令人瞩目的方式证明，Minecraft 可以被推向真实计算的领域。 /// The numbers alone are hard to parse on paper. The structure measures roughly 1,020 × 260 × 1,656 blocks, which equates to about 439 million blocks in volume as presented in the developer’s materials and corroborated by multiple outlets. That block count and the physical footprint forced the creator to rely on specialized tools just to record and render the build in a single shot. News coverage and the project notes mention the use of mods like Distant Horizons for visualization and a high-performance redstone server (MCHPRS) to make the machine usable at all. // 仅从数字上看，在纸上很难理解。该结构的尺寸约为 1,020 × 260 × 1,656 个方块，按开发者提供的资料和多家媒体确认，体积约为 4.39 亿个方块。这个方块数量和物理占地面积迫使创作者依赖专业工具，才能一次性记录和渲染整个建筑。新闻报道和项目笔记中提到了使用 Distant Horizons 等模组进行可视化，以及使用高性能红石服务器（MCHPRS）使机器能够运行。 /// For context: at vanilla Minecraft tick rates, a single token’s worth of computation could take years; CraftGPT is only usable because the Minecraft environment is accelerated dramatically on custom servers that increase tick speed by many orders of magnitude. Even with those accelerations, a single short reply typically takes hours to generate. That contrast — an object of incredible engineering that is, for practical purposes, a museum piece rather than a consumer tool — is central to what makes CraftGPT both impressive and pedagogically valuable. // 为了背景信息：在原版 Minecraft 的 tick 速率下，单个 token 的计算量可能需要数年才能完成；CraftGPT 之所以可用，是因为在自定义服务器上，Minecraft 环境通过提高 tick 速度数个数量级得到了显著加速。即便如此，生成单个简短回复通常仍需数小时。这种对比——一个令人难以置信的工程成就，实际上更像是一件博物馆展品而非消费工具——是 CraftGPT 既令人印象深刻又具有教学价值的核心所在。 /// From tokens to circuits​ // 从标记到电路​ ///: At a high level, CraftGPT reproduces the stages of a transformer pipeline: // 从宏观上看，CraftGPT 再现了 transformer 管道的各个阶段： ///; - Tokenization: Input text is converted to binary token indices. The project uses a bespoke tokenizer constrained to the small 1,920-token vocabulary, implemented with in‑game counters and logic gates. // 标记化：输入文本被转换为二进制标记索引。该项目使用一个定制的标记器，限制在较小的 1,920 标记词汇量中，通过游戏内的计数器和逻辑门实现。 ///; - Embedding: Tokens are mapped to 240‑dimensional embedding vectors. Those embedding vectors are stored as circuits whose outputs feed the rest of the network. Because storing floating-point values directly in Minecraft is impossible, the project uses quantized integer encodings mapped onto Redstone amplifier circuits. Developer notes indicate a higher precision for embeddings and normalization layers to preserve dynamic range. // 嵌入：标记被映射到 240 维嵌入向量。这些嵌入向量被存储为电路，其输出为网络的其他部分提供输入。由于直接在 Minecraft 中存储浮点值是不可能的，该项目使用量化整数编码映射到红石放大电路。开发者笔记表明嵌入和归一化层具有更高的精度，以保留动态范围。 ///; - Matrix operations: Matrix multipliers are implemented as arrays of bitwise logic and weighted summation circuits. Multipliers and accumulators are the heart of the build and account for a significant fraction of the block count. Each weight becomes a physical subcircuit whose state contributes to dot products and linear transforms. // 矩阵运算：矩阵乘法器被实现为位逻辑和加权求和电路的数组。乘法器和累加器是整个构建的核心，占用了相当大比例的方块数量。每个权重都变成一个物理子电路，其状态对点积和线性变换做出贡献。 ///; - Attention and layers: The design implements attention-ish operations and per-layer transforms across six layers. The attention mechanism is simplified for tractability but preserves the pattern of token mixing that gives transformer models their conversational power. // 注意力和层：设计实现了六层中的注意力操作和每层变换。注意力机制为了便于处理而简化，但保留了赋予 Transformer 模型对话能力的标记混合模式。 ///; This is not a perfect emulation of modern attention implementations — rather, it is a pragmatic reduction that captures core behaviors within strict in‑game constraints. The developer has documented these design trade-offs and explains which mathematical liberties were taken to make the build feasible within Minecraft’s discrete logic. // 这并非对现代注意力实现的完美模拟——而是基于严格游戏内约束的一种务实简化，它捕捉了核心行为。开发者已记录下这些设计权衡，并解释了为了在 Minecraft 的离散逻辑中实现构建所采取的哪些数学上的自由处理。 /// Precision and quantization​ // 精度和量化 ///: A crucial technique making CraftGPT tractable is quantization. Most weights are stored at 8-bit precision to reduce the size of the circuits. Select components — notably embeddings and LayerNorm weights — are stored at higher bit depths (developer notes mention unusual widths like 18 and 24 bits) to preserve numerical stability. That mix of quantization strategies mirrors real-world engineering trade-offs where some tensors are kept in higher precision while others are aggressively compressed. These choices influence the chatbot’s output quality and its propensity to “go off the rails” on complex prompts. // 使 CraftGPT 变得可行的关键技术是量化。大多数权重以 8 位精度存储以减小电路的尺寸。选择组件——特别是嵌入和 LayerNorm 权重——以更高的位深度存储（开发者笔记提到像 18 位和 24 位这样不寻常的宽度）以保持数值稳定性。这种量化策略的混合反映了现实世界中的工程权衡，其中一些张量保持较高精度，而另一些则被激进压缩。这些选择影响着聊天机器人的输出质量和它在复杂提示下“跑偏”的倾向。 /// Why the speed is still slow​ // 为什么速度仍然很慢 ///: Even with MCHPRS, Minecraft’s Redstone primitives are orders of magnitude slower than silicon. Each arithmetic operation in CraftGPT corresponds to physical state propagation across Redstone wires and repeaters. When repeated across millions of weights and tens of thousands of neurons, the cumulative time cost becomes obvious. That’s why the project is primarily a proof of concept: it shows how a model’s logic can be expressed in a constrained medium rather than providing a practical chat service. // 即使使用 MCHPRS，Minecraft 的红石原语也比硅慢几个数量级。CraftGPT 中的每次算术操作都对应于红石线路和中继器的物理状态传播。当在数百万个权重和数万个神经元中重复时，累积的时间成本变得明显。这就是为什么该项目主要是一个概念验证：它展示了模型的逻辑如何在受限介质中表达，而不是提供实用的聊天服务。 /// Sammyuri’s redstone legacy: why this matters to the community​ // Sammyuri 的红石传承：这为何对社区很重要 ///: Sammyuri’s work sits in the same tradition as other monumental Minecraft engineering projects that translate conventional computation into the game’s mechanics: from CPUs and arithmetic logic units to fully playable versions of classic games built inside Minecraft. Each project raises the bar for what the community thinks is possible inside the sandbox and serves as a source of inspiration for builders, modders, and educators alike. // 山米里的工作与其他宏伟的 Minecraft 工程项目一样，都属于将传统计算转化为游戏机制的传统：从 CPU 和算术逻辑单元到在 Minecraft 中构建的可玩经典游戏版本。每个项目都提高了社区认为在沙盒中可能达到的标准，并为建造者、模组制作者和教育者提供了灵感来源。 ///; CraftGPT is notable for several reasons: // CraftGPT 有几个显著的特点： ///; - It pushes Redstone logic beyond novelty into near‑formal computation, reproducing components like tokenizers, matrix multipliers, and normalization in physical form. // 它将红石逻辑从新奇推向近乎正式的计算，以物理形式重现了分词器、矩阵乘法器和归一化等组件。 ///; - It documents engineering choices and trade‑offs thoroughly, making it a teaching artifact as much as a spectacle. // 它详尽地记录了工程选择和权衡，使其既是一件教学文物，也是一种视觉奇观。 ///; - It highlights the limits of in‑game computation and the huge gap between a clever engineering demo and a practical AI system — an instructive contrast for readers curious about how much of modern AI is math versus raw compute. // 它突出了游戏内计算的局限性，以及一个巧妙的工程演示与实用 AI 系统之间的巨大差距——对于好奇现代 AI 有多少是基于数学而非原始计算能力的读者来说，这是一个有益的对比。 /// Why readers should care (and what they should not expect)​ // 读者为何应关注（以及他们不应期待什么） ///: CraftGPT is worth attention because it reframes how we think about computation, representation, and pedagogical demonstration. It is a high‑visibility example of constraint-driven engineering and a creative translation of machine learning concepts into a medium many millions of players already understand. // CraftGPT 值得关注，因为它重新定义了我们对计算、表示和教学演示的认知。它是约束驱动工程的一个高可见度案例，也是将机器学习概念创造性地转化为数百万玩家已理解媒介的翻译。 ///; What it is not: a practical conversational assistant, a commercial competitor to modern LLMs, or a replacement for efficient hardware. It is, instead, a milestone that sits at the intersection of art, education, and engineering — an object to study and admire rather than to deploy. // 它不是：一个实用的对话助手，现代 LLMs 的商业竞争对手，或高效硬件的替代品。相反，它是一个位于艺术、教育和工程交叉点的里程碑——一个值得研究和欣赏的对象，而非部署的对象。"
