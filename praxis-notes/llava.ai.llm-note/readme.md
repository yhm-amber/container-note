[site/ghio]: https://llava-vl.github.io/
[paper:1]: https://arxiv.org/abs/2304.08485 "Visual Instruction Tuning // è§†è§‰æŒ‡ä»¤è°ƒæ•´"
[paper:1.5]: https://arxiv.org/abs/2310.03744 "Improved Baselines with Visual Instruction Tuning // é€šè¿‡è§†è§‰æŒ‡ä»¤è°ƒæ•´æ”¹è¿›åŸºçº¿"
[datasets/ğŸ¤—]: https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K

[demo]: https://llava.hliu.cc/
[src/gh]: https://github.com/haotian-liu/LLaVA.git "(Apache-2.0) (Languages: Python 85.6%, Shell 8.6%, JavaScript 2.8%, HTML 2.1%, Other 0.9%) [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond. //  [NeurIPS'23 Oral] è§†è§‰æŒ‡ä»¤è°ƒä¼˜ (LLaVA) æ—¨åœ¨å®ç° GPT-4V çº§åˆ«åŠä»¥ä¸Šçš„åŠŸèƒ½ã€‚"
