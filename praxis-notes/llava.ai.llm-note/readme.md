[site/ghio]: https://llava-vl.github.io/
[paper:1]: https://arxiv.org/abs/2304.08485 "Visual Instruction Tuning // 视觉指令调整"
[paper:1.5]: https://arxiv.org/abs/2310.03744 "Improved Baselines with Visual Instruction Tuning // 通过视觉指令调整改进基线"
[datasets/🤗]: https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K

[demo]: https://llava.hliu.cc/
[src/gh]: https://github.com/haotian-liu/LLaVA.git "(Apache-2.0) (Languages: Python 85.6%, Shell 8.6%, JavaScript 2.8%, HTML 2.1%, Other 0.9%) [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond. //  [NeurIPS'23 Oral] 视觉指令调优 (LLaVA) 旨在实现 GPT-4V 级别及以上的功能。"
