[src/gh]: https://github.com/simonpcouch/emlwr.git "(CC-BY-NC-SA-4.0) (Languages: Lua 58.5%, R 16.9%, TeX 15.4%, SCSS 6.3%, CSS 2.9%) Efficient Machine Learning with R /// Source code for the current draft of Efficient Machine Learning with R, a book on making your tidymodels code run faster without sacrificing predictive performance. // å½“å‰ã€ŠEfficient Machine Learning with Rã€‹ä¸€ä¹¦çš„è‰ç¨¿æºä»£ç ï¼Œè¯¥ä¹¦æ—¨åœ¨å¸®åŠ©æ‚¨åœ¨ä¸ç‰ºç‰²é¢„æµ‹æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œä½¿æ‚¨çš„ tidymodels ä»£ç è¿è¡Œå¾—æ›´å¿«ã€‚"
[site/org]: https://emlwr.org/ "Efficient Machine Learning with R // ä½¿ç”¨ R è¿›è¡Œé«˜æ•ˆæœºå™¨å­¦ä¹  /// Low-Compute Predictive Modeling with tidymodels // ä½¿ç”¨ tidymodels è¿›è¡Œä½è®¡ç®—é¢„æµ‹å»ºæ¨¡ /// Author // ä½œè€… /// Simon P. Couch // è¥¿è’™Â·PÂ·åº“å¥‡ /// WelcomeğŸ› // æ¬¢è¿ğŸ› /// Welcome to Efficient Machine Learning with R! This is a book about predictive modeling with tidymodels, focused on reducing the time and memory required to train machine learning models without sacrificing predictive performance. // æ¬¢è¿æ¥åˆ°ã€Šé«˜æ•ˆæœºå™¨å­¦ä¹ ä¸ Rã€‹ï¼è¿™æ˜¯ä¸€æœ¬å…³äºä½¿ç”¨ tidymodels è¿›è¡Œé¢„æµ‹å»ºæ¨¡çš„ä¹¦ç±ï¼Œé‡ç‚¹åœ¨äºåœ¨ä¸ç‰ºç‰²é¢„æµ‹æ€§èƒ½çš„å‰æä¸‹ï¼Œå‡å°‘è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹æ‰€éœ€çš„æ—¶é—´å’Œå†…å­˜ã€‚ /// This book assumes familiarity with data analysis with the tidyverse as well as the basics of machine learning with tidymodels: fitting models with parsnip, resampling data with rsample, and tuning model parameters with tune. For more on tidy data analysis, see Wickham, Ã‡etinkaya-Rundel, and Grolemund (2023). For the basics of predictive modeling with tidymodels, see Kuhn and Silge (2022). // æœ¬ä¹¦å‡è®¾è¯»è€…ç†Ÿæ‚‰ä½¿ç”¨ tidyverse è¿›è¡Œæ•°æ®åˆ†æï¼Œä»¥åŠ tidymodels æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼šä½¿ç”¨ parsnip æ‹Ÿåˆæ¨¡å‹ï¼Œä½¿ç”¨ rsample è¿›è¡Œæ•°æ®é‡é‡‡æ ·ï¼Œä»¥åŠä½¿ç”¨ tune è°ƒæ•´æ¨¡å‹å‚æ•°ã€‚æœ‰å…³æ›´è¯¦ç»†çš„ tidy æ•°æ®åˆ†æå†…å®¹ï¼Œè¯·å‚é˜… Wickhamã€Ã‡etinkaya-Rundel å’Œ Grolemundï¼ˆ2023ï¼‰çš„è‘—ä½œã€‚æœ‰å…³ tidymodels é¢„æµ‹å»ºæ¨¡çš„åŸºç¡€çŸ¥è¯†ï¼Œè¯·å‚é˜… Kuhn å’Œ Silgeï¼ˆ2022ï¼‰çš„è‘—ä½œã€‚ /// Outline // å¤§çº² /// - 1  Introduction demonstrates a 145-fold speedup with an applied example. By adapting a grid search on a canonical model to use a more performant modeling engine, hooking into a parallel computing framework, transitioning to an optimized search strategy, and defining the grid to search over carefully, the section shows that users can drastically cut down on tuning times without sacrificing predictive performance. The following chapters then explore those optimizations in further details. // 1  å¼•è¨€é€šè¿‡ä¸€ä¸ªåº”ç”¨å®ä¾‹å±•ç¤ºäº† 145 å€çš„åŠ é€Ÿæ•ˆæœã€‚é€šè¿‡å°†è§„èŒƒæ¨¡å‹ä¸Šçš„ç½‘æ ¼æœç´¢é€‚é…åˆ°æ›´é«˜æ•ˆçš„å»ºæ¨¡å¼•æ“ã€è¿æ¥åˆ°å¹¶è¡Œè®¡ç®—æ¡†æ¶ã€è¿‡æ¸¡åˆ°ä¼˜åŒ–çš„æœç´¢ç­–ç•¥ï¼Œå¹¶ä»”ç»†å®šä¹‰æœç´¢çš„ç½‘æ ¼ï¼Œè¯¥éƒ¨åˆ†è¡¨æ˜ç”¨æˆ·å¯ä»¥åœ¨ä¸ç‰ºç‰²é¢„æµ‹æ€§èƒ½çš„æƒ…å†µä¸‹å¤§å¹…å‡å°‘è°ƒä¼˜æ—¶é—´ã€‚æ¥ä¸‹æ¥çš„ç« èŠ‚å°†æ›´è¯¦ç»†åœ°æ¢è®¨è¿™äº›ä¼˜åŒ–ã€‚ /// - 2  Models explores timings to resample various different modeling engines. The chapter compares implementations both within and across model types. // 2  æ¨¡å‹æ¢ç´¢äº†é‡æ–°é‡‡æ ·ä¸åŒå»ºæ¨¡å¼•æ“çš„æ—¶é—´ã€‚æœ¬ç« æ¯”è¾ƒäº†åŒä¸€æ¨¡å‹ç±»å‹å†…å’Œä¸åŒæ¨¡å‹ç±»å‹é—´çš„å®ç°ã€‚ /// - 3  Parallel computing compares various approaches to distributing model computations across CPU cores. Weâ€™ll explore two different across-model parallel computing frameworks supported by tidymodelsâ€”process forking and socket clustersâ€”and explore their relationship to within-model parallelization. // 3  å¹¶è¡Œè®¡ç®—æ¯”è¾ƒäº†å°†æ¨¡å‹è®¡ç®—åˆ†å¸ƒåˆ° CPU æ ¸å¿ƒçš„å„ç§æ–¹æ³•ã€‚æˆ‘ä»¬å°†æ¢è®¨ tidymodels æ”¯æŒçš„ä¸¤ç§è·¨æ¨¡å‹å¹¶è¡Œè®¡ç®—æ¡†æ¶â€”â€”è¿›ç¨‹åˆ†å‰å’Œå¥—æ¥å­—é›†ç¾¤ï¼Œå¹¶æ¢è®¨å®ƒä»¬ä¸æ¨¡å‹å†…å¹¶è¡ŒåŒ–çš„å…³ç³»ã€‚ /// - Then, 4  Search explores various alternatives to grid search that can reduce the total number of model fits required to search a given grid space by only resampling models that seem to have a chance at being the â€œbest.â€ // ç„¶åï¼Œç¬¬ 4 ç« æ¢è®¨äº†å„ç§å¯ä»¥å‡å°‘åœ¨ç»™å®šç½‘æ ¼ç©ºé—´ä¸­æœç´¢æ‰€éœ€æ¨¡å‹æ‹Ÿåˆæ€»æ•°çš„æ›¿ä»£æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ä»…é‡æ–°é‡‡æ ·é‚£äº›ä¼¼ä¹æœ‰æˆä¸ºâ€œæœ€ä½³â€æœºä¼šçš„æ¨¡å‹ã€‚ /// - Finally, 5  The submodel trick investigates approaches to designing grids that can further reduce the total number of model fits required to search a given grid space by generating predictions from one model that can be used to evaluate several. // æœ€åï¼Œç¬¬ 5 ç« ä»‹ç»äº†å­æ¨¡å‹æŠ€å·§ï¼Œç ”ç©¶è®¾è®¡ç½‘æ ¼çš„æ–¹æ³•ï¼Œé€šè¿‡ä»ä¸€ä¸ªæ¨¡å‹ç”Ÿæˆé¢„æµ‹æ¥è¿›ä¸€æ­¥å‡å°‘åœ¨ç»™å®šç½‘æ ¼ç©ºé—´ä¸­æœç´¢æ‰€éœ€çš„æ¨¡å‹æ‹Ÿåˆæ€»æ•°ï¼Œè¿™äº›é¢„æµ‹å¯ç”¨äºè¯„ä¼°å¤šä¸ªæ¨¡å‹ã€‚ /// The optimizations discussed in those aforementioned chapters can, on their own, substantially reduce the time to evaluate machine learning models with tidymodels. Depending on the problem context, some modeling workflows may benefit from more specialized optimizations. The following chapters discuss some of those use cases: // å‰é¢ç« èŠ‚ä¸­è®¨è®ºçš„ä¼˜åŒ–æªæ–½ï¼Œå•ç‹¬ä½¿ç”¨å³å¯æ˜¾è‘—å‡å°‘ä½¿ç”¨ tidymodels è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹æ‰€éœ€çš„æ—¶é—´ã€‚æ ¹æ®é—®é¢˜èƒŒæ™¯ï¼ŒæŸäº›å»ºæ¨¡å·¥ä½œæµç¨‹å¯èƒ½å—ç›Šäºæ›´ä¸“ä¸šçš„ä¼˜åŒ–ã€‚æ¥ä¸‹æ¥çš„ç« èŠ‚å°†è®¨è®ºå…¶ä¸­ä¸€äº›ç”¨ä¾‹ï¼š /// - 6  Preprocessing // ç¬¬ 6 ç« ï¼šé¢„å¤„ç† /// - 7  Sparsity // 7  ç¨€ç–æ€§ /// - 8  Stacking // 8  å †å "
[knows_by]: https://simonpcouch.com/software "- emlwr /// Efficient Machine Learning with R // R è¯­è¨€é«˜æ•ˆæœºå™¨å­¦ä¹ "
