[src/gh]: https://github.com/huggingface/candle.git "(Apache-2.0, MIT) (Languages: Rust 75.8%, C++ 7.4%, Metal 7.3%, Cuda 5.4%, Python 1.8%, HTML 1.7%, Other 0.6%) Minimalist ML framework for Rust // Rust 的极简机器学习框架 /// candle // 蜡烛 /// Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) and ease of use. Try our online demos: // Candle 是一个极简的 Rust 机器学习框架，专注于性能（包括 GPU 支持）。 并且易于使用。请尝试我们的在线演示： /// - whisper (. hf-spaces: lmz/candle-whisper): speech recognition // 低语: 语音识别 /// - LLaMA2 (. hf-spaces: lmz/candle-llama2): text generation // LLaMA2: 文本生成 /// - T5 (. hf-spaces: radames/Candle-T5-Generation-Wasm): text generation // T5: 文本生成 /// - yolo (. hf-spaces: lmz/candle-yolo): pose estimation and object recognition // 人生苦短及时行乐: 姿态估计和物体识别 /// - Segment Anything (. hf-spaces: radames/candle-segment-anything-wasm): Image segmentation // 万物可分: 图像分割 /// - Phi-1.5, and Phi-2 (. hf-spaces: radames/Candle-Phi-1.5-Wasm): text generation // Phi-1.5, and Phi-2: 文本生成 /// - BLIP (. hf-spaces: radames/Candle-BLIP-Image-Captioning): image captioning // 图像描述"
[site/ghio]: https://huggingface.github.io/candle/ "Features // 特征 /// - Simple syntax, looks and feels like PyTorch. // 语法简洁，外观和感觉都像 PyTorch。 /// - - Model training. // 模型训练。 /// - - Embed user-defined ops/kernels, such as flash-attention v2. // 嵌入用户自定义的操作/内核，例如 flash-attention v2 。 /// - Backends. // 后端。 /// - - Optimized CPU backend with optional MKL support for x86 and Accelerate for macs. // 针对 x86 架构优化的 CPU 后端，可选 MKL 支持，并针对 Mac 平台提供加速功能。 /// - - CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL. // CUDA 后端可高效地在 GPU 上运行，并通过 NCCL 实现多 GPU 分配。 /// - - WASM support, run your models in a browser. // 支持 WASM，可在浏览器中运行模型。 /// - Included models. // 包含的模型。 /// - - Language Models. // 语言模型。 /// - - - LLaMA v1, v2, and v3 with variants such as SOLAR-10.7B. // LLaMA v1、v2 和 v3 以及 SOLAR-10.7B 等变体。 /// - - - Falcon. // 鹘。 /// - - - StarCoder, StarCoder2.  StarCoder，StarCoder2。 /// - - - Phi 1, 1.5, 2, and 3. /// - - - Mamba, Minimal Mamba // 曼巴，最小曼巴 /// - - - Gemma v1 2b and 7b+, v2 2b and 9b. /// - - - Mistral 7b v0.1.  Mistral 7b v0.1。 /// - - - Mixtral 8x7b v0.1.  Mixtral 8x7b v0.1。 /// - - - StableLM-3B-4E1T, StableLM-2-1.6B, Stable-Code-3B. /// - - - Replit-code-v1.5-3B. /// - - - Bert. // 伯特。 /// - - - Yi-6B and Yi-34B.  Yi-6B 和 Yi-34B。 /// - - - Qwen1.5, Qwen1.5 MoE.  Qwen1.5，Qwen1.5 MoE。 /// - - - RWKV v5 and v6. /// - - Quantized LLMs. // 量化 LLM。 /// - - - Llama 7b, 13b, 70b, as well as the chat and code variants. // Llama 7b、13b、70b，以及聊天和代码变体。 /// - - - Mistral 7b, and 7b instruct. // Mistral 7b，以及 7b 指令。 /// - - - Mixtral 8x7b. // 混合型 8x7b。 /// - - - Zephyr 7b a and b (Mistral-7b based). // Zephyr 7b a 和 b（基于 Mistral-7b）。 /// - - - OpenChat 3.5 (Mistral-7b based). // OpenChat 3.5（基于 Mistral-7b）。 /// - - Text to text. // 文本转文本。 /// - - - T5 and its variants: FlanT5, UL2, MADLAD400 (translation), CoEdit (Grammar correction). // T5 及其变体：FlanT5、UL2、MADLAD400（翻译）、CoEdit（语法校正）。 /// - - - Marian MT (Machine Translation). // Marian MT（机器翻译）。 /// - - Text to image. // 文字转图像。 /// - - - Stable Diffusion v1.5, v2.1, XL v1.0. /// - - - Wurstchen v2. /// - - Image to text. // 图片转文字。 /// - - - BLIP. /// - - - TrOCR. /// - - Audio. /// - - - Whisper, multi-lingual speech-to-text. // Whisper，多语言语音转文本。 /// - - - EnCodec, audio compression model. // EnCodec，音频压缩模型。 /// - - - MetaVoice-1B, text-to-speech model. // MetaVoice-1B，文本转语音模型。 /// - - - Parler-TTS, text-to-speech model. // Parler-TTS，文本转语音模型。 /// - - Computer Vision Models. // 计算机视觉模型。 /// - - - DINOv2, ConvMixer, EfficientNet, ResNet, ViT, VGG, RepVGG, ConvNeXT, ConvNeXTv2, MobileOne, EfficientVit (MSRA), MobileNetv4, Hiera, FastViT. /// - - - yolo-v3, yolo-v8.  yolo-v3，yolo-v8。 /// - - - Segment-Anything Model (SAM). // 切分万物模型（SAM）。 /// - - - SegFormer. // 段形成器。 /// - File formats: load models from safetensors, npz, ggml, or PyTorch files. // 文件格式：从 safetensors、npz、ggml 或 PyTorch 文件加载模型。 /// - Serverless (on CPU), small and fast deployments. // 无服务器（基于 CPU）、小巧快速的部署。 /// - Quantization support using the llama.cpp quantized types. // 使用 llama.cpp 量化类型支持量化。"
[guide:installation/.site]: https://huggingface.github.io/candle/guide/installation.html "(: cargo add --git https://github.com/huggingface/candle.git -- candle-core candle-nn # append option: `--features cuda` if want cuda feature for `candle-core`, or append `--features cudnn` rather than `cuda` for even more speedups if you have cuDNN installed.)"
[guide:hello_world/.site]: https://huggingface.github.io/candle/guide/hello_world.html "... /// most of the classical layers are already implemented in candle-nn. // 大多数经典层已经在 candle-nn 中实现了。 /// ..."
[cheatsheet:torch/.site]: https://huggingface.github.io/candle/guide/cheatsheet.html "Pytorch cheatsheet // PyTorch 速查表"

[api/docs-rs]: https://docs.rs/candle-core/
