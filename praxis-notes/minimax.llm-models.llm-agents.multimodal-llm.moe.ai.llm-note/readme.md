[m2-docs.src/gh]: https://github.com/MiniMax-AI/MiniMax-M2.git "(Modified MIT) MiniMax-M2, a model built for Max coding & agentic workflows. // MiniMax-M2，一个为 Max 编码和代理工作流程构建的模型。"
[m2-llm.model/hf]: https://huggingface.co/MiniMaxAI/MiniMax-M2 "(Modified MIT) (Text Generation) (Transformers) (Safetensors) (Tags: minimax_m2, conversational, custom_code, fp8) (Model size: 229B params) (Tensor type: F32·BF16·F8_E4M3) Meet MiniMax-M2 // 遇见 MiniMax-M2 /// Today, we release and open source MiniMax-M2, a Mini model built for Max coding & agentic workflows. // 今天，我们发布并开源了 MiniMax-M2，这是一个专为 Max 编程和代理工作流程构建的 Mini 模型。 /// MiniMax-M2 redefines efficiency for agents. It's a compact, fast, and cost-effective MoE model (230 billion total parameters with 10 billion active parameters) built for elite performance in coding and agentic tasks, all while maintaining powerful general intelligence. With just 10 billion activated parameters, MiniMax-M2 provides the sophisticated, end-to-end tool use performance expected from today's leading models, but in a streamlined form factor that makes deployment and scaling easier than ever. // MiniMax-M2 为智能体重新定义了效率。它是一个紧凑、快速且经济高效的 MoE 模型（2300 亿总参数，100 亿激活参数），专为编码和智能体任务中的卓越性能而设计，同时保持强大的通用智能。只需 100 亿激活参数，MiniMax-M2 就能提供当今领先模型所期望的复杂、端到端工具使用性能，但其精简的形态使得部署和扩展比以往任何时候都更容易。"
[paper:2504.07164/arxiv]: https://arxiv.org/abs/2504.07164 "(License: CC BY 4.0) [Submitted on 9 Apr 2025] { Software Engineering (cs.SE); Computation and Language (cs.CL); Machine Learning (cs.LG) } Improving open-source models on real-world SWE tasks (solving GITHUB issues) faces two key challenges: 1) scalable curation of execution environments to train these models, and, 2) optimal scaling of test-time compute. We introduce AgentGym, the largest procedurally-curated executable gym environment for training real-world SWE-agents, consisting of more than 8.7K tasks. AgentGym is powered by two main contributions: 1) SYNGEN: a synthetic data curation recipe that enables scalable curation of executable environments using test-generation and back-translation directly from commits, thereby reducing reliance on human-written issues or unit tests. We show that this enables more scalable training leading to pass@1 performance of 34.4% on SWE-Bench Verified benchmark with our 32B model. 2) Hybrid Test-time Scaling: we provide an in-depth analysis of two test-time scaling axes; execution-based and execution-free verifiers, demonstrating that they exhibit complementary strengths and limitations. Test-based verifiers suffer from low distinguishability, while execution-free verifiers are biased and often rely on stylistic features. Surprisingly, we find that while each approach individually saturates around 42-43%, significantly higher gains can be obtained by leveraging their complementary strengths. Overall, our approach achieves 51% on the SWE-Bench Verified benchmark, reflecting a new state-of-the-art for open-weight SWE-agents and for the first time showing competitive performance with proprietary models such as o1, o1-preview and sonnet-3.5-v2 (with tools). We will open-source our environments, models, and agent trajectories. // 在真实世界 SWE 任务（解决 GITHUB 问题）上改进开源模型面临两大关键挑战：1）可扩展地管理用于训练这些模型的执行环境，以及 2）测试时计算的最佳扩展。我们介绍了 AgentGym，这是目前最大的程序化管理的可执行 gym 环境，用于训练真实世界的 SWE 代理，包含超过 8.7K 个任务。AgentGym 基于两大主要贡献：1）SYNGEN：一种合成数据管理方案，通过直接从提交中生成测试和反向翻译，实现可扩展地管理可执行环境，从而减少对人工编写的问题或单元测试的依赖。我们证明这能够实现更可扩展的训练，使我们的 32B 模型在 SWE-Bench Verified 基准测试中达到 34.4%的 pass@1 性能。2）混合测试时扩展：我们深入分析了两个测试时扩展维度；基于执行和无需执行的验证器，证明它们具有互补的优缺点。基于测试的验证器存在区分度低的问题，而无需执行的验证器存在偏差，并且通常依赖于风格特征。 令人惊讶的是，我们发现虽然每种方法单独运行时饱和度在 42-43%左右，但通过利用它们的互补优势，可以获得显著更高的收益。总体而言，我们的方法在 SWE-Bench Verified 基准上达到了 51%，这反映了开源 SWE 代理的新技术状态，并且首次展示了与 o1、o1-preview 和 sonnet-3.5-v2（带工具）等专有模型具有竞争力的性能。我们将开源我们的环境、模型和代理轨迹。 (src: gh:R2E-Gym/R2E-Gym.git)"
[paper:2509.06501/arxiv]: https://arxiv.org/abs/2509.06501 "(License: CC BY 4.0) [Submitted on 8 Sep 2025 (v1), last revised 26 Sep 2025 (this version, v3)] { Computation and Language (cs.CL) } The paradigm of Large Language Models (LLMs) has increasingly shifted toward agentic applications, where web browsing capabilities are fundamental for retrieving information from diverse online sources. However, existing open-source web agents either demonstrate limited information-seeking abilities on complex tasks or lack transparent implementations. In this work, we identify that the key challenge lies in the scarcity of challenging data for information seeking. To address this limitation, we introduce WebExplorer: a systematic data generation approach using model-based exploration and iterative, long-to-short query evolution. This method creates challenging query-answer pairs that require multi-step reasoning and complex web navigation. By leveraging our curated high-quality dataset, we successfully develop advanced web agent WebExplorer-8B through supervised fine-tuning followed by reinforcement learning. Our model supports 128K context length and up to 100 tool calling turns, enabling long-horizon problem solving. Across diverse information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able to effectively search over an average of 16 turns after RL training, achieving higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best performance among models up to 100B parameters on WebWalkerQA and FRAMES. Beyond these information-seeking tasks, our model also achieves strong generalization on the HLE benchmark even though it is only trained on knowledge-intensive QA data. These results highlight our approach as a practical path toward long-horizon web agents. // 大型语言模型（LLMs）的范式正日益转向代理式应用，其中网络浏览能力对于从多样化在线资源中检索信息至关重要。然而，现有的开源网络代理要么在复杂任务上的信息检索能力有限，要么缺乏透明的实现。在本工作中，我们识别出关键挑战在于信息检索挑战数据的稀缺性。为解决这一局限性，我们引入了 WebExplorer：一种基于模型探索和迭代、长至短查询演化的系统化数据生成方法。该方法创建了需要多步推理和复杂网络导航的挑战性查询-答案对。通过利用我们精心策划的高质量数据集，我们成功通过监督微调随后进行强化学习，开发了高级网络代理 WebExplorer-8B。我们的模型支持 128K 上下文长度和高达 100 次工具调用轮次，能够实现长时程问题解决。在多样化的信息检索基准测试中，WebExplorer-8B 在其规模上达到了最先进的性能。 值得注意的是，作为一个 8B 规模的模型，WebExplorer-8B 在 RL 训练后能够有效地搜索平均 16 轮，在 BrowseComp-en/zh 上实现了比 WebSailor-72B 更高的准确率，并在 WebWalkerQA 和 FRAMES 上达到了参数量最高至 100B 的模型中的最佳性能。除了这些信息搜索任务之外，我们的模型在 HLE 基准测试中也取得了很强的泛化能力，尽管它仅是在知识密集型 QA 数据上训练的。这些结果突显了我们的方法作为实现长时程网络代理的实用路径。"
[paper:2509.13160/arxiv]: https://arxiv.org/abs/2509.13160 "[Submitted on 16 Sep 2025] { Machine Learning (cs.LG); Artificial Intelligence (cs.AI) } Search has emerged as core infrastructure for LLM-based agents and is widely viewed as critical on the path toward more general intelligence. Finance is a particularly demanding proving ground: analysts routinely conduct complex, multi-step searches over time-sensitive, domain-specific data, making it ideal for assessing both search proficiency and knowledge-grounded reasoning. Yet no existing open financial datasets evaluate data searching capability of end-to-end agents, largely because constructing realistic, complicated tasks requires deep financial expertise and time-sensitive data is hard to evaluate. We present FinSearchComp, the first fully open-source agent benchmark for realistic, open-domain financial search and reasoning. FinSearchComp comprises three tasks -- Time-Sensitive Data Fetching, Simple Historical Lookup, and Complex Historical Investigation -- closely reproduce real-world financial analyst workflows. To ensure difficulty and reliability, we engage 70 professional financial experts for annotation and implement a rigorous multi-stage quality-assurance pipeline. The benchmark includes 635 questions spanning global and Greater China markets, and we evaluate 21 models (products) on it. Grok 4 (web) tops the global subset, approaching expert-level accuracy. DouBao (web) leads on the Greater China subset. Experimental analyses show that equipping agents with web search and financial plugins substantially improves results on FinSearchComp, and the country origin of models and tools impact performance this http URL aligning with realistic analyst tasks and providing end-to-end evaluation, FinSearchComp offers a professional, high-difficulty testbed for complex financial search and reasoning. // 搜索已成为基于 LLM 的智能体核心基础设施，并被广泛视为迈向更通用智能的关键。金融是一个特别具有挑战性的试验场：分析师常规地执行针对时间敏感、领域特定的复杂数据的多步骤搜索，使其成为评估搜索能力和基于知识的推理的理想环境。然而，现有的公开金融数据集没有评估端到端智能体的数据搜索能力，主要是因为构建真实、复杂的任务需要深厚的金融专业知识，而时间敏感数据难以评估。我们提出了 FinSearchComp，这是首个完全开源的、针对真实开放领域金融搜索和推理的智能体基准。FinSearchComp 包含三个任务——时间敏感数据获取、简单历史查询和复杂历史调查——紧密复现了现实世界金融分析师的工作流程。为确保难度和可靠性，我们聘请了 70 位专业金融专家进行标注，并实施了一个严格的多阶段质量保证流程。 该基准包含涵盖全球和 Greater China 市场的 635 个问题，我们在其上评估了 21 个模型（产品）。Grok 4（网络）在全球子集上位居第一，接近专家级准确率。DouBao（网络）在 Greater China 子集上领先。 实验分析表明，为智能体配备网络搜索和金融插件可以显著提升 FinSearchComp 的结果，并且模型和工具的来源国对性能有影响，这与现实中的分析师任务相一致，并且提供了端到端的评估，FinSearchComp 提供了一个专业、用于复杂金融搜索与推理的高难度测试平台。 (src: gh:randomtutu/FinSearchComp.git) (dataset: hf:datasets/ByteSeedXpert/FinSearchComp)"
[paper:2504.07164/hf]: https://huggingface.co/papers/2504.07164 "R2E-Gym: Procedural Environments and Hybrid Verifiers for Scaling Open-Weights SWE Agents // R2E-Gym：用于扩展 Open-Weights SWE 代理的程序化环境和混合验证器 /// { citing models: (hf:MiniMaxAI/MiniMax-M2 [Text Generation]), (hf:unsloth/MiniMax-M2-GGUF [Text Generation]), (hf:QuantTrio/MiniMax-M2-AWQ [Text Generation]), (hf:StringChaos/R2E-TestgenAgent), (hf:ModelCloud/MiniMax-M2-BF16 [Text Generation]), (hf:cyankiwi/MiniMax-M2-BF16 [Text Generation]), (hf:unsloth/MiniMax-M2 [Text Generation]), (hf:Pavvav/affine-max [Text Generation]), (hf:bullerwins/MiniMax-M2-GGUF [Text Generation]), (hf:redponike/MiniMax-M2-GGUF [Text Generation]), (hf:kesti/affine-minimax [Text Generation]), (hf:ginipick/MiniMax-M2 [Text Generation]), (hf:seawolf2357/MiniMax-M2 [Text Generation]), (hf:a2s-ai/MiniMax-M2-AWQ [Text Generation]), (hf:cyankiwi/MiniMax-M2-AWQ-4bit [Text Generation]), (hf:gayan25/fingerprint-qa [Text Generation]), (hf:fariasultana/MiniMind [Text Generation]) }"
[paper:2509.06501/hf]: https://huggingface.co/papers/2509.06501 "WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents // WebExplorer：探索与进化，用于训练长时程网络代理 /// { citing models: (hf:MiniMaxAI/MiniMax-M2 [Text Generation]), (hf:unsloth/MiniMax-M2-GGUF [Text Generation]), (hf:QuantTrio/MiniMax-M2-AWQ [Text Generation]), (hf:hkust-nlp/WebExplorer-8B [Image-Text-to-Text]), (hf:ModelCloud/MiniMax-M2-BF16 [Text Generation]), (hf:cyankiwi/MiniMax-M2-BF16 [Text Generation]), (hf:unsloth/MiniMax-M2 [Text Generation]), (hf:Pavvav/affine-max [Text Generation]), (hf:bullerwins/MiniMax-M2-GGUF [Text Generation]), (hf:redponike/MiniMax-M2-GGUF [Text Generation]), (hf:kesti/affine-minimax [Text Generation]), (hf:ginipick/MiniMax-M2 [Text Generation]), (hf:seawolf2357/MiniMax-M2 [Text Generation]), (hf:a2s-ai/MiniMax-M2-AWQ [Text Generation]), (hf:cyankiwi/MiniMax-M2-AWQ-4bit [Text Generation]), (hf:gayan25/fingerprint-qa [Text Generation]), (hf:fariasultana/MiniMind [Text Generation]) }"
[paper:2509.13160/hf]: https://huggingface.co/papers/2509.13160 "FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning // FinSearchComp：迈向真实、专家级金融搜索与推理评估 /// { citing models: (hf:MiniMaxAI/MiniMax-M2 [Text Generation]), (hf:unsloth/MiniMax-M2-GGUF [Text Generation]), (hf:QuantTrio/MiniMax-M2-AWQ [Text Generation]), (hf:ModelCloud/MiniMax-M2-BF16 [Text Generation]), (hf:cyankiwi/MiniMax-M2-BF16 [Text Generation]), (hf:unsloth/MiniMax-M2 [Text Generation]), (hf:Pavvav/affine-max [Text Generation]), (hf:bullerwins/MiniMax-M2-GGUF [Text Generation]), (hf:redponike/MiniMax-M2-GGUF [Text Generation]), (hf:kesti/affine-minimax [Text Generation]), (hf:ginipick/MiniMax-M2 [Text Generation]), (hf:seawolf2357/MiniMax-M2 [Text Generation]), (hf:a2s-ai/MiniMax-M2-AWQ [Text Generation]), (hf:cyankiwi/MiniMax-M2-AWQ-4bit [Text Generation]), (hf:gayan25/fingerprint-qa [Text Generation]), (hf:fariasultana/MiniMind [Text Generation]) }"
[blog:what-makes-good-reasoning-data/hf]: https://huggingface.co/blog/MiniMax-AI/what-makes-good-reasoning-data "What makes good reasoning data // 什么是好的推理数据 /// Artificial Analysis is a comprehensive benchmark that reflects the diversity of models’ reasoning abilities. Our newly released model, MiniMax M2, ranks Top-1 among open-source models and Top-5 among all models. // 人工分析是一个全面的基准，反映了模型推理能力的多样性。我们新发布的模型 MiniMax M2 在开源模型中排名第一，在所有模型中排名前五。 /// In the past, community discussions on improving reasoning abilities often focused on optimizing RL algorithms or constructing verifiable data in domains like Math and Code. In the M2 project, we conducted more \"general\" explorations. As a member of the Reasoning team, I'd like to share some of our findings and thoughts on data — what makes good reasoning data. // 过去，社区关于提升推理能力的讨论通常集中在优化 RL 算法或构建数学和代码等领域的可验证数据。在 M2 项目中，我们进行了更多“通用”的探索。作为推理团队的成员，我想分享一些关于数据的发现和思考——什么样的数据是好的推理数据。 /// - Quality of CoT and Response // CoT 质量和响应质量 ///: The quality of CoT is reflected in its logical completeness without excessive redundancy. For instance, in instruction following tasks, overly brief CoT often leads to models skipping steps or being overconfident, causing significant harm to the model's final performance and capability generalization. For responses, we noticed that most open-source work overfits certain benchmark format patterns to achieve better leaderboard scores. While this is effective for single data directions, it severely hinders capability generalization for a general-purpose model. Therefore, when synthesizing data, we introduced format diversity and observed significant gains in multi-directional fusion experiments. Meanwhile, for potential bad cases in CoT and responses, such as hallucinations, instruction-following failures, and logical errors. We performed data cleaning using rules + LLM-as-a-judge. By continuously iterating on this misalignment elimination pipeline, we've become increasingly convinced that every bad case has its corresponding dirty training data, and improvements in data quality will inevitably be reflected in model performance. // CoT 的质量体现在其逻辑完整性上，且不包含过多冗余。例如，在指令跟随任务中，过于简短的 CoT 常常导致模型跳过步骤或变得过度自信，从而对模型的最终性能和泛化能力造成显著损害。对于回复而言，我们注意到大多数开源工作为了在排行榜上获得更好的分数，会过度拟合某些基准格式模式。虽然这在单一数据方向上有效，但严重阻碍了通用模型的泛化能力。因此，在合成数据时，我们引入了格式多样性，并在多方向融合实验中观察到显著提升。同时，针对 CoT 和回复中的潜在不良案例，如幻觉、指令跟随失败和逻辑错误，我们使用规则+LLM 作为裁判进行数据清洗。通过不断迭代这一消除偏差的流程，我们越来越确信每个不良案例都有其对应的脏乱训练数据，数据质量的提升必将反映在模型性能上。 /// - Difficulty and Diversity of Data Distribution // 数据分布的难度和多样性 ///: Like many discussions in the community, our experiments also found that math and code data are critical for improving reasoning capabilities. The reasoning abilities brought by these two types of data often benefit all tasks, such as STEM and IF. However, we also found that we still need sufficiently diverse data to cover more domains, such as logical reasoning, science, instruction following, and open-ended creative tasks. Tasks from different domains have different thinking paradigms, and the diversity of reasoning is the foundation for capability generalization. Additionally, we noticed in our experiments that harder and more complex queries are more effective for model training, so we adjusted data distribution based on pass rate (for verifiable tasks) or complexity scores (for non-verifiable tasks). // 和社区中的许多讨论一样，我们的实验也发现数学和代码数据对于提升推理能力至关重要。这两种类型的数据带来的推理能力通常能惠及所有任务，例如 STEM 和 IF。然而，我们也发现我们仍然需要足够多样化的数据来覆盖更多领域，例如逻辑推理、科学、指令遵循和开放式创造性任务。不同领域的任务具有不同的思维范式，而推理的多样性是能力泛化的基础。此外，我们在实验中注意到，更难、更复杂的查询对于模型训练更有效，因此我们根据通过率（对于可验证任务）或复杂度分数（对于不可验证任务）调整了数据分布。 /// - Data Scaling // 数据缩放 ///: Finally, an old but important topic: Scaling. When data quality and diversity meet the standards, increasing data scale consistently brings significant gains. Whether it's increasing the number of queries, doing 1Q-multiple-A, multi-epoch training, or even mixing data from different directions to bring more training steps, the model steadily improves. In practice, data scaling is a highly engineering-oriented problem, so we attempted to consolidate all data based on task characteristics, dividing them into two data pipelines: Verifiable and Non-Verifiable, for automated data synthesis and processing. In fact, the Reasoning team is almost entirely composed of interns, and this data pipeline effectively ensured team collaboration efficiency and consistency in data output. // 最后，一个古老但重要的话题：规模。当数据质量和多样性达到标准时，增加数据规模始终能带来显著收益。无论是增加查询数量、进行 1Q 多 A、多周期训练，甚至混合不同方向的数据以增加训练步数，模型都能稳步提升。在实践中，数据规模扩展是一个高度工程化的问题，因此我们尝试根据任务特征整合所有数据，将其分为两个数据管道：可验证和不可验证，用于自动化数据合成和处理。实际上，推理团队几乎完全由实习生组成，这个数据管道有效地确保了团队协作效率和数据输出的统一性。 /// Future Work // 未来工作 ///: Moving forward, we will continue to delve deeper in two directions. One is compound capabilities, such as knowledge + reasoning, and the enhancement of reasoning tasks by tools in Agent scenarios. The other is how to integrate Verifiable and Non-Verifiable tasks, such as the fusion of CoT across different domains and the generalization of reasoning capabilities, as well as the unification of training methods. Our team is also continuously progressing and growing. We welcome interested colleagues to join the discussion. Happy to chat! // 接下来，我们将继续在两个方向上深入探索。一是复合能力，例如知识+推理，以及在 Agent 场景中通过工具增强推理任务。二是如何整合可验证和非可验证任务，例如跨不同领域的 CoT 融合以及推理能力的泛化，以及训练方法的统一。我们的团队也在不断进步和成长。我们欢迎感兴趣的同事加入讨论。很乐意聊天！"
[blog:aligning-to-what/hf]: https://huggingface.co/blog/MiniMax-AI/aligning-to-what "Aligning to What? Rethinking Agent Generalization in MiniMax M2 // 对准什么？重新思考 MiniMax M2 中的智能体泛化 /// When we designed M2, we knew we had to tackle this problem head-on. This led us to two core, and sometimes conflicting, objectives: // 当我们设计 M2 时，我们知道必须直面这个问题。这引出了我们两个核心且有时相互矛盾的目标： /// 1. Excel on Open-Source Benchmarks. Benchmarks are essential for measuring \"pure\" capabilities. A benchmark like BrowseComp, for instance, tests for sophisticated search skills. While users will rarely ask a question as contrived as, “Find the paper where the third letter of the nth author’s name is ‘x’,” a model that can solve it proves it has strong foundational abilities. // 在开源基准测试中表现优异。基准测试对于衡量“纯粹”能力至关重要。例如，BrowseComp 这样的基准测试会测试复杂的搜索技能。虽然用户很少会提出像“找到一篇论文，其中第 n 位作者的姓名的第三个字母是‘x’”这样刻意的问题，但一个能够解决这个问题的模型证明了它具有强大的基础能力。 /// 2. Generalize Robustly to the Real World. This is the harder, more important part. A great agent must perform reliably across unfamiliar tools, IDEs/CLIs, agent scaffolding, and user setups. It can't be a one-trick pony; it needs to generalize. // 在真实世界中具有强大的泛化能力。这是更困难、更重要的部分。一个优秀的智能体必须在陌生的工具、IDE/CLI、智能体脚手架和用户设置中可靠地运行。它不能只靠一个技巧吃饭；它需要具备泛化能力。 /// So, who do we align with? The answer is both. We align with benchmarks to build skill, but we must ultimately align with the user by ensuring those skills work everywhere. // 那么，我们应该与谁对齐呢？答案是两者都要。我们通过与基准测试对齐来提升技能，但最终必须通过与用户对齐来确保这些技能在任何地方都能发挥作用。 /// While the methods for acing benchmarks are a deep topic for another day, I want to focus on that second, trickier objective: How do we train an agent for the wild? // 虽然掌握基准测试的方法是另一天要深入探讨的课题，但我想专注于那个更棘手的第二个目标：我们如何训练一个能在“野外”工作的智能体？ /// The Need for Interleaved Thinking // 交错思维的必要性 /// Early in the project, we hit a frustrating wall. Agent performance was inconsistent, and we struggled to diagnose why. After many discussions, especially with Professor @Junxian He and @Wenhu Chen, we arrived at our first major conclusion: Agents require Interleaved Thinking. // 项目初期，我们遇到了一个令人沮丧的瓶颈。智能体的表现不稳定，我们难以诊断原因。经过多次讨论，特别是与何军先教授和陈文华教授的交流，我们得出了第一个重要结论：智能体需要交错思考。 /// This means that an agent's internal monologue—its \"thinking\"—can and should happen at any point during a task, not just once at the beginning like a standard reasoning model. This design is critical for two reasons: // 这意味着智能体的内部独白——它的 \"思考\" ——可以在任务的任何时刻发生，而不仅仅像标准推理模型那样在开始时进行一次。这种设计有两个关键原因： /// 1. Maintaining Focus on Long-Horizon Tasks. Complex agent tasks have extremely long contexts. A single thought process at the start isn't enough to maintain instruction-following and coherence. // 保持对长时程任务的专注。复杂智能体任务具有极长的上下文。单次的初始思考不足以维持指令遵循和连贯性。 /// 2. Adapting to External Perturbations. This is the crucial difference. Agent tasks introduce constant, unpredictable perturbations from the outside world (i.e., tool outputs). The model must be robust enough to handle these perturbations, diagnose errors, and extract useful information. The \"thinking\" process allows the model to constantly re-evaluate and adapt to new information from the environment. // 适应外部扰动。这是关键区别。智能体任务会从外部世界（即工具输出）引入持续且不可预测的扰动。模型必须足够稳健，能够处理这些扰动、诊断错误并提取有用信息。 \"思考\" 过程使模型能够不断重新评估并适应环境中的新信息。 /// This principle became a cornerstone of M2's effectiveness. // 这一原则成为 M2 有效性的基石。 /// > Pro Tip for M2 Users: Because M2 relies on Interleaved Thinking, its context is its memory. For best performance, you must retain the full session history, including the thinking steps. We've noticed that much of the community feedback about performance gaps stems from accidentally discarding this vital context, which is a common practice with simpler reasoning models. // M2 用户小贴士：由于 M2 依赖于交错思考，其上下文就是其记忆。为了获得最佳性能，你必须保留完整的会话历史，包括思考步骤。我们注意到，社区中关于性能差距的许多反馈都源于意外丢弃了这一重要上下文，而这在更简单的推理模型中是一种常见做法。 /// True Generalization is About Perturbation // 真正的泛化关乎扰动 /// Our initial theory was simple: tool scaling is agent generalization. // 我们的最初理论很简单：工具扩展就是智能体泛化。 /// We started with a minimal set of tools (a Python interpreter, search engine, a browser) to build a baseline of tool-calling capability. The roadmap was clear: scale up the number and variety of tools, and the agent's ability to generalize to unseen tools would naturally follow. // 我们从一个最简的工具集（一个 Python 解释器、搜索引擎和一个浏览器）开始，构建了一个工具调用的基准能力。路线图很明确：增加工具的数量和种类，智能体的泛化能力到未见过的新工具自然会随之提升。 /// At first, this worked. Our benchmark scores climbed to respectable levels. But as we dug deeper, we realized we were solving the wrong problem. The model aced the tests, but if we changed the environment even slightly—like swapping to a different scaffolding framework—its performance would plummet. We were still far from our goal of a “practically useful” model. // 最初，这确实有效。我们的基准分数提升到了可接受的水平。但当我们深入挖掘时，意识到我们正在解决错误的问题。模型在测试中表现完美，但如果我们稍微改变环境——比如换用不同的脚手架框架——它的性能就会急剧下降。我们离“实际可用”的目标还很远。 /// This led to our second, more profound realization: Agent generalization is not just about adapting to new tools; it's about adapting to perturbations across the model's entire operational space. // 这引出了我们的第二个、更深刻的认识：智能体的泛化能力并不仅仅是适应新工具，而是适应模型整个操作空间中的扰动。 /// This sounds abstract, so let's break it down. Think about everything that can change in a single agent task: // 这听起来很抽象，让我们来分解一下。想想在单个智能体任务中所有可能发生变化的东西： /// - The Tool Info and available toolset. // 工具信息和可用的工具集。 /// - The System Prompt defining the agent's persona and rules. // 定义智能体角色和规则的系统提示。 /// - The User Prompt and its specific goal. // 用户提示及其具体目标。 /// - The Environment itself (files, codebases, APIs). // 环境本身（文件、代码库、API） /// - The Tool Responses returned at each step. Our old “tool scaling” approach only addressed the first item. It ignored perturbations in all the other parts of the process. Armed with this new understanding, our team built a comprehensive data pipeline designed for full-trajectory generalization. The data it generates trains the model to be stable against perturbations at every step. The results have been incredibly encouraging. In internal tests, we threw obscure, “cold-start” scaffolding at M2—frameworks we'd barely considered—and its performance exceeded our expectations. Both its tool-calling and instruction-following abilities generalized beautifully. // 每一步返回的工具响应。我们旧的“工具扩展”方法仅解决了第一项问题。它忽略了流程中其他部分的扰动。基于这一新认识，我们的团队构建了一个全面的数据管道，专为全轨迹泛化设计。它生成的数据训练模型在每一步都能保持稳定，不受扰动。结果非常令人鼓舞。在内测中，我们向 M2 抛出了晦涩的、“冷启动”的框架——这些框架我们几乎未曾考虑过——它的表现超出了我们的预期。它的工具调用和指令跟随能力都泛化得非常出色。"
[blog:why-m2-full-attention/hf]: https://huggingface.co/blog/MiniMax-AI/why-did-m2-end-up-as-a-full-attention-model "Why Did MiniMax M2 End Up as a Full Attention Model? // 为什么 MiniMax M2 最终成为全注意力模型？ /// To build a model that can practically be deployed and used by the community, we have to start with what users care: Quality, Speed (TPS), and Price. Quality is non-negotiable. A useless model is useless even if it's free. So how do we make a Linear/Sparse/Hybrid Attention model that performs well enough? The biggest challenge here isn’t the architecture design — the real bottleneck is the limitations of evaluation. (As for speed and price, those are heavily influenced by the inference stack—and great models tend to attract great engineers to optimize them.) // 要构建一个能够实际部署并被社区使用的模型，我们必须从用户关心的方面入手：质量、速度（每秒事务处理量）和价格。质量是不可协商的。一个无用的模型即使免费也是无用的。那么，我们如何使线性/稀疏/混合注意力模型的表现足够好呢？这里的最大挑战并非架构设计——真正的瓶颈是评估的局限性。（至于速度和价格，它们受推理堆栈的严重影响——优秀的模型往往会吸引优秀的工程师来优化它们。） /// Benchmarks are a Leaky Abstraction // 基准测试是一种有漏洞的抽象 /// There’s no free lunch. When you reduce the complexity of attention, you pay a price. The question is, where? // 没有免费的午餐。当你降低注意力的复杂性时，你就要付出代价。问题在于，代价在哪里？ /// When we were developing MiniMax-Text-01, everyone was still evaluating MMLU, BBH, MATH, and LongBench (all of which are now saturated). From the perspective of a year ago, a hybrid of Lightning Attention and Full Attention looked just as good as pure full attention. Our own small-scale hybrid models confirmed this on the leaderboards. (Did we find a free lunch?) // 在开发 MiniMax-Text-01 时，大家仍在评估 MMLU、BBH、MATH 和 LongBench（这些现在都已饱和）。从一年前的角度来看，Lightning Attention 和 Full Attention 的混合效果与纯 Full Attention 相当。我们自己的小规模混合模型在排行榜上证实了这一点。（我们找到免费午餐了吗？） /// Not quite. The price paid became obvious at a larger scale: the model had clear deficits in complex, multi-hop reasoning tasks. Okay, once a problem is exposed, you can fix it. We developed proxy metrics for this specific weakness and iterated until the hybrid model seemed to match MHA. But does that proxy metric still correlate with real-world downstream performance at an even larger scale? Are there other hidden weaknesses? Who knows. We haven't run those experiments yet. // 并非如此。付出的代价在更大规模上变得明显：模型在复杂的、多跳推理任务上存在明显缺陷。好吧，一旦问题暴露出来，就可以修复它。我们针对这种特定弱点开发了代理指标，并不断迭代，直到混合模型似乎与 MHA 匹配。但是，这个代理指标是否仍然与更大规模的实际下游性能相关？是否存在其他隐藏的弱点？谁知道呢。我们还没有运行这些实验。 /// The better the models get, the harder they are to evaluate. But that’s a must part of the journey — keep it up, eval teams! // 模型越好，评估就越困难。但这绝对是旅程中必经的一部分——继续加油，评估团队！ /// The High Cost of Knowing Things // 知道事物的代价很高 /// For complex reasoning tasks, we can sometimes find early proxy metrics that correlate well with final performance — but not for all tasks (at least, not yet). As tasks get harder, the amount of experiment compute required just to get a statistically significant signal on your metric grows astronomically — which is ironic, since we study efficient attention because compute is limited. // 对于复杂的推理任务，我们有时能找到与最终性能高度相关的早期替代指标，但并非所有任务都能做到这一点（至少目前还没有）。随着任务变得越难，仅为了在指标上获得统计上显著的信号所需的实验计算量会呈指数级增长——这很讽刺，因为我们研究高效注意力机制，正是因为计算资源有限。 /// And beyond the academic benchmarks, optimization issues often only surface at scale. You never really know what’s going to happen until you scale up. Anyone who read our M1 paper will recall the serious precision issues we hit during RL training — problems that would’ve been spotted earlier. Going back and analyzing Lightning Attention's numerical convergence with that experience in hand was incredibly clarifying. // 并且，超越学术基准，优化问题往往只有在规模化时才会显现。你永远不知道会发生什么，直到你进行规模化。任何读过我们 M1 论文的人都会记得我们在 RL 训练中遇到的严重精度问题——这些问题本可以更早被发现。带着那次经验回顾分析 Lightning Attention 的数值收敛情况，极大地澄清了问题。 /// Discovering the real problems is often far harder than solving them. // 发现真正的问题往往比解决问题要困难得多。"
[agent-app.wui/.site]: https://agent.minimax.io/ "Enter your task and submit it to MiniMax Agent."
[share:remix-CHIMERA-MAINFRAME/.agent-app]: https://agent.minimax.io/share/305500036423948 "Remix of CHIMERA MAINFRAME - MiniMax Agent // CHIMERA MAINFRAME 的混音 - MiniMax Agent"
[space:remix-CHIMERA-MAINFRAME/.site]: https://qnwvdoyumcsp.space.minimax.io/ "(这个页面 Bug 还挺多的 ...)"
[api-platform/.site]: https://platform.minimax.io/login

