[src/gh]: https://github.com/hiyouga/LLaMA-Factory.git "(Apache-2.0) (Languages: Python 99.6%, Other 0.4%) Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) // 《hiyouga/LLaMA-Factory：统一高效地微调 100+ LLMs & VLMs (ACL 2024)》"
[site/rtd]: https://llamafactory.readthedocs.io/ "LLaMA Factory is an easy-to-use and efficient platform for training and fine-tuning large language models. With LLaMA Factory, you can fine-tune hundreds of pre-trained models locally without writing any code. Framework features include: // LLaMA Factory 是一个简单易用且高效的大型语言模型（Large Language Model）训练与微调平台。通过 LLaMA Factory，可以在无需编写任何代码的前提下，在本地完成上百种预训练模型的微调，框架特性包括： /// - Models: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Yi, Gemma, Baichuan, ChatGLM, Phi, etc. // 模型种类：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi 等等。 /// - Trainers: (incremental) pre-training, (multimodal) instruction supervision fine-tuning, reward model training, PPO training, DPO training, KTO training, ORPO training, etc. // 训练算法：（增量）预训练、（多模态）指令监督微调、奖励模型训练、PPO 训练、DPO 训练、KTO 训练、ORPO 训练等等。 /// - Computation Precision: 16-bit full-parameter fine-tuning, frozen fine-tuning, LoRA fine-tuning, and 2/3/4/5/6/8-bit QLoRA fine-tuning based on AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ. // 运算精度：16 比特全参数微调、冻结微调、LoRA 微调和基于 AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ 的 2/3/4/5/6/8 比特 QLoRA 微调。 /// - Optimization Algorithms: GaLore, BAdam, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ, and PiSSA. // 优化算法：GaLore、BAdam、DoRA、LongLoRA、LLaMA Pro、Mixture-of-Depths、LoRA+、LoftQ 和 PiSSA。 /// - Acceleration Operators: FlashAttention-2 and Unsloth. // 加速算子：FlashAttention-2 和 Unsloth。 /// - Inference Engines: Transformers and vLLM. // 推理引擎：Transformers 和 vLLM。 /// - Experiment Monitors: LlamaBoard, TensorBoard, Wandb, MLflow, SwanLab etc. // 实验监控：LlamaBoard、TensorBoard、Wandb、MLflow、SwanLab 等等。"
