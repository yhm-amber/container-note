[app.wui/brave-integrated]: brave://leo-ai/
[site/brave.com]: https://brave.com/leo/ "Brave Leo AI // å‹‡æ•¢ç‹®å­åº§äººå·¥æ™ºèƒ½ /// The smart AI assistant built right into your browser. Ask questions, summarize pages, create new content, and more. Privately. // å†…ç½®äºæµè§ˆå™¨ä¸­çš„æ™ºèƒ½ AI åŠ©æ‰‹ã€‚æé—®ã€æ€»ç»“é¡µé¢å†…å®¹ã€åˆ›å»ºæ–°å†…å®¹ç­‰ç­‰ã€‚ä¸€åˆ‡å°½åœ¨æŒæ§ã€‚ /// Make every page interactive // è®©æ¯ä¸ªé¡µé¢éƒ½å…·æœ‰äº¤äº’æ€§ ///: Chat with Leo about any topic. Ask Leo to summarize webpages, generate content, translate, analyze text, and more. Without leaving the page. // å’Œ Leo ç•…èŠä»»ä½•è¯é¢˜ã€‚è®© Leo å¸®ä½ æ€»ç»“ç½‘é¡µå†…å®¹ã€ç”Ÿæˆå†…å®¹ã€ç¿»è¯‘ã€åˆ†ææ–‡æœ¬ç­‰ç­‰ã€‚æ‰€æœ‰æ“ä½œéƒ½æ— éœ€ç¦»å¼€å½“å‰é¡µé¢ã€‚ /// Private, anonymous, and secure // ç§å¯†ã€åŒ¿åä¸”å®‰å…¨ ///: Leo doesnâ€™t retain or share chats, or use them for additional model training. No account or login is required. Just open and chat. Privately. // Leo ä¸ä¼šä¿å­˜æˆ–åˆ†äº«èŠå¤©è®°å½•ï¼Œä¹Ÿä¸ä¼šå°†å…¶ç”¨äºé¢å¤–çš„æ¨¡å‹è®­ç»ƒã€‚æ— éœ€æ³¨å†Œæˆ–ç™»å½•ã€‚åªéœ€æ‰“å¼€å³å¯ç§å¯†èŠå¤©ã€‚ /// Get insights from docs // ä»æ–‡æ¡£ä¸­è·å–è§è§£ /// Leo can even analyze PDFs, Google Docs & Google Sheets, and more, getting you the info you need. Faster. // Leo ç”šè‡³å¯ä»¥åˆ†æ PDFã€Google æ–‡æ¡£å’Œ Google è¡¨æ ¼ç­‰æ–‡ä»¶ï¼Œæ›´å¿«åœ°ä¸ºæ‚¨æä¾›æ‰€éœ€ä¿¡æ¯ã€‚"
[leo.wiki/gh]: https://github.com/brave/brave-browser/wiki/Brave-Leo "Brave Leo is a private AI smart assistant that enhances your use of the Internet. // Brave Leo æ˜¯ä¸€æ¬¾ç§äººäººå·¥æ™ºèƒ½æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯å¢å¼ºæ‚¨çš„äº’è”ç½‘ä½¿ç”¨ä½“éªŒã€‚ /// Ask Leo to summarize a webpage youâ€™re viewing. Or ask questions about the page, and get answers, clarifications, and other viewpoints. Brave Leo can also create content, translate between different languages, and transcribe audio and video. It can even have back-and-forth conversations. // ä½ å¯ä»¥è®© Leo å¸®ä½ æ€»ç»“æ­£åœ¨æµè§ˆçš„ç½‘é¡µã€‚æˆ–è€…å‘å®ƒæé—®ï¼Œå®ƒä¼šç»™å‡ºç­”æ¡ˆã€è§£é‡Šå’Œå…¶ä»–è§‚ç‚¹ã€‚å‹‡æ•¢çš„ Leo è¿˜èƒ½åˆ›ä½œå†…å®¹ã€è¿›è¡Œè¯­è¨€ç¿»è¯‘ï¼Œä»¥åŠè½¬å½•éŸ³é¢‘å’Œè§†é¢‘ã€‚å®ƒç”šè‡³å¯ä»¥è¿›è¡ŒåŒå‘å¯¹è¯ã€‚"
[byom-intro.blog/brave.site]: https://brave.com/blog/byom-nightly/ "Bring Your Own Model (BYOM): using Brave Leo with your own LLMs // è‡ªå¸¦æ¨¡å‹ï¼ˆBYOMï¼‰ï¼šå°† Brave Leo ä¸æ‚¨è‡ªå·±çš„ LLM ç»“åˆä½¿ç”¨ /// Note: As of August 22, 2024, BYOM is now in general release and available to all desktop users (with browser update version 1.69 or higher). // æ³¨æ„ ï¼šæˆªè‡³ 2024 å¹´ 8 æœˆ 22 æ—¥ï¼ŒBYOM å·²æ­£å¼å‘å¸ƒï¼Œæ‰€æœ‰æ¡Œé¢ç”¨æˆ·å‡å¯ä½¿ç”¨ï¼ˆæµè§ˆå™¨ç‰ˆæœ¬éœ€æ›´æ–°è‡³ 1.69 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰ã€‚ /// Our first step towards that promise is called â€œbring your own modelâ€ (or â€œBYOMâ€ for short). This optional new way of using Leo, Braveâ€™s native browser AI, allows users to link it directly with their own AI models. BYOM allows users to run Leo with local models running safely and privately on their own machines. Users will be able to chat or ask questions on webpages (and docs and PDFs) to Leo without their content ever having to leave the device. // æˆ‘ä»¬å®ç°è¿™ä¸€æ‰¿è¯ºçš„ç¬¬ä¸€æ­¥æ˜¯â€œè‡ªå¸¦æ¨¡å‹â€ï¼ˆç®€ç§°â€œBYOMâ€ï¼‰ã€‚è¿™ç§ä½¿ç”¨ Leoï¼ˆBrave æµè§ˆå™¨çš„åŸç”Ÿ AIï¼‰çš„å…¨æ–°å¯é€‰æ–¹å¼ï¼Œå…è®¸ç”¨æˆ·å°†å…¶ä¸è‡ªå·±çš„ AI æ¨¡å‹ç›´æ¥è¿æ¥ã€‚BYOM ä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨è‡ªå·±çš„è®¾å¤‡ä¸Šå®‰å…¨ç§å¯†åœ°è¿è¡Œæœ¬åœ°æ¨¡å‹ï¼Œä»è€Œå®ç° Leo çš„è¿è¡Œã€‚ç”¨æˆ·å¯ä»¥åœ¨ç½‘é¡µï¼ˆ ä»¥åŠæ–‡æ¡£å’Œ PDF ï¼‰ä¸Šä¸ Leo èŠå¤©æˆ–æé—®ï¼Œè€Œæ— éœ€å°†å†…å®¹ä¼ è¾“åˆ°è®¾å¤‡ä¹‹å¤–ã€‚ /// BYOM isnâ€™t limited to just local models, eitherâ€“BYOM users will also have the flexibility to connect Leo to remote models running on their own servers, or that are run by third-parties (e.g. ChatGPT). This opens new possibilities for users and organizations to leverage proprietary or custom models while still benefiting from the convenience of querying the AI directly within the browser. // BYOM ä¸ä»…é™äºæœ¬åœ°æ¨¡å‹â€”â€”BYOM ç”¨æˆ·è¿˜å¯ä»¥çµæ´»åœ°å°† Leo è¿æ¥åˆ°è¿è¡Œåœ¨ä»–ä»¬è‡ªå·±æœåŠ¡å™¨ä¸Šçš„è¿œç¨‹æ¨¡å‹ï¼Œæˆ–ç”±ç¬¬ä¸‰æ–¹ï¼ˆä¾‹å¦‚ ChatGPTï¼‰è¿è¡Œçš„æ¨¡å‹ã€‚è¿™ä¸ºç”¨æˆ·å’Œç»„ç»‡åˆ©ç”¨ä¸“æœ‰æˆ–è‡ªå®šä¹‰æ¨¡å‹å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ï¼ŒåŒæ—¶è¿˜èƒ½äº«å—ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æŸ¥è¯¢ AI çš„ä¾¿åˆ©ã€‚ /// With BYOM, the requests are made directly from the userâ€™s device to the specified model endpoint, bypassing Brave entirely. Brave does not act as an intermediary and has absolutely no access toâ€”or visibility intoâ€”the traffic between the user and the model. This direct connection ensures end-to-end control for the user. // ä½¿ç”¨ BYOMï¼Œè¯·æ±‚ç›´æ¥ä»ç”¨æˆ·çš„è®¾å¤‡å‘é€åˆ°æŒ‡å®šçš„æ¨¡å‹ç«¯ç‚¹ï¼Œå®Œå…¨ç»•è¿‡ Brave æµè§ˆå™¨ã€‚Brave ä¸å……å½“ä¸­é—´äººï¼Œä¹Ÿå®Œå…¨æ— æ³•è®¿é—®æˆ–æŸ¥çœ‹ç”¨æˆ·ä¸æ¨¡å‹ä¹‹é—´çš„æµé‡ã€‚è¿™ç§ç›´æ¥è¿æ¥ç¡®ä¿ç”¨æˆ·æ‹¥æœ‰ç«¯åˆ°ç«¯çš„æ§åˆ¶æƒã€‚ /// To add your own local model to Leo, open the Brave browser and visit Settings, and then Leo. Scroll to the Bring your own model section and click Add new model. // è¦å°†æ‚¨è‡ªå·±çš„æœ¬åœ°æ¨¡å‹æ·»åŠ åˆ° Leoï¼Œè¯·æ‰“å¼€ Brave æµè§ˆå™¨å¹¶è®¿é—® â€œè®¾ç½®â€ ï¼Œç„¶åé€‰æ‹© â€œLeoâ€ã€‚ æ»šåŠ¨åˆ° â€œè‡ªå¸¦æ¨¡å‹â€ éƒ¨åˆ†ï¼Œç„¶åå•å‡» â€œæ·»åŠ æ–°æ¨¡å‹â€ ã€‚ /// Youâ€™ll then be brought to a new interface where you can add the details of your model. The required fields are the following: // æ¥ä¸‹æ¥æ‚¨å°†è¿›å…¥ä¸€ä¸ªæ–°ç•Œé¢ï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­æ·»åŠ æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ã€‚å¿…å¡«å­—æ®µå¦‚ä¸‹ï¼š /// - Label: The name of the model as it will appear in the model selection menu. // æ ‡ç­¾ ï¼šæ¨¡å‹åç§°ï¼Œå°†æ˜¾ç¤ºåœ¨æ¨¡å‹é€‰æ‹©èœå•ä¸­ã€‚ /// - Model request name: The name of the model as it should appear in the request to the serving framework, e.g. llama-3 (note that if this name doesnâ€™t match exactly what is expected by the serving framework, the integration will not work). // æ¨¡å‹è¯·æ±‚åç§° ï¼šæ¨¡å‹çš„åç§°ï¼Œå®ƒåº”è¯¥å‡ºç°åœ¨å‘é€åˆ°æœåŠ¡æ¡†æ¶çš„è¯·æ±‚ä¸­ï¼Œä¾‹å¦‚ llama-3ï¼ˆè¯·æ³¨æ„ï¼Œå¦‚æœæ­¤åç§°ä¸æœåŠ¡æ¡†æ¶æ‰€æœŸæœ›çš„åç§°ä¸å®Œå…¨åŒ¹é…ï¼Œåˆ™é›†æˆå°†æ— æ³•å·¥ä½œï¼‰ã€‚ /// - Server endpoint: The url where your serving framework is â€œlisteningâ€ for requests. If youâ€™re not sure, check the serving framework documentation (For Ollama, this is always http://localhost:11434/v1/chat/completions). // æœåŠ¡å™¨ç«¯ç‚¹ ï¼šæ‚¨çš„æœåŠ¡æ¡†æ¶â€œç›‘å¬â€è¯·æ±‚çš„ URLã€‚å¦‚æœæ‚¨ä¸ç¡®å®šï¼Œè¯·æŸ¥çœ‹æœåŠ¡æ¡†æ¶çš„æ–‡æ¡£ï¼ˆå¯¹äº Ollamaï¼Œæ­¤å€¼å§‹ç»ˆä¸º http://localhost:11434/v1/chat/completions ï¼‰ã€‚ /// - API Key: third party frameworks may require authentication credentials, such as an API key or an access token. These will be added to the request header. // API å¯†é’¥ ï¼šç¬¬ä¸‰æ–¹æ¡†æ¶å¯èƒ½éœ€è¦èº«ä»½éªŒè¯å‡­æ®ï¼Œä¾‹å¦‚ API å¯†é’¥æˆ–è®¿é—®ä»¤ç‰Œã€‚è¿™äº›ä¿¡æ¯å°†æ·»åŠ åˆ°è¯·æ±‚æ ‡å¤´ä¸­ã€‚ /// Click Add model; your local model should now appear in the Leo model menu. Simply select it to use it to power your browser AI. // ç‚¹å‡» â€œæ·»åŠ æ¨¡å‹â€ ï¼›æ‚¨çš„æœ¬åœ°æ¨¡å‹ç°åœ¨åº”è¯¥ä¼šå‡ºç°åœ¨ Leo æ¨¡å‹èœå•ä¸­ã€‚åªéœ€é€‰æ‹©å®ƒå³å¯ä½¿ç”¨å®ƒæ¥é©±åŠ¨æ‚¨çš„æµè§ˆå™¨ AIã€‚ /// Note that while weâ€™ve used Ollama in this section, as we think itâ€™s one of the most user-friendly frameworks to set up and run local models, the BYOM feature can be used with any local serving framework with an exposed endpoint and that conforms to the OpenAI chat protocol. // è¯·æ³¨æ„ï¼Œè™½ç„¶æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­ä½¿ç”¨äº† Ollamaï¼Œå› ä¸ºæˆ‘ä»¬è®¤ä¸ºå®ƒæ˜¯è®¾ç½®å’Œè¿è¡Œæœ¬åœ°æ¨¡å‹æœ€ç”¨æˆ·å‹å¥½çš„æ¡†æ¶ä¹‹ä¸€ï¼Œä½† BYOM åŠŸèƒ½å¯ä»¥ä¸ä»»ä½•å…·æœ‰å…¬å¼€ç«¯ç‚¹ä¸”ç¬¦åˆ OpenAI èŠå¤©åè®®çš„æœ¬åœ°æœåŠ¡æ¡†æ¶ä¸€èµ·ä½¿ç”¨ã€‚"
[search-chatplg.wui/.search]: https://search.brave.com/ask "Ask Brave"
[tee-news.blog/brave.site]: https://brave.com/blog/browser-ai-tee/ "Verifiable Privacy and Transparency: A new frontier for Brave AI privacy // å¯éªŒè¯çš„éšç§å’Œé€æ˜åº¦ï¼šBrave AI éšç§çš„æ–°å‰æ²¿ /// Today, Brave Leo (. web: brave.com/leo) offers a new capability for cryptographically-verifiable privacy and transparency by deploying LLMs with NEAR AI (. web: docs.near.ai/cloud/private-inference) Nvidia-backed Trusted Execution Environments (aka â€œTEEsâ€, see â€œKnow more about TEEsâ€ section below for details). Brave believes that users must be able to verify that they are having private conversations with the model they expect. This is available in Brave Nightly (our testing and development channel) for early experimentation with DeepSeek V3.1 (we plan to extend this to more models in the future based on feedback). // ä»Šå¤©ï¼Œ Brave Leo æµè§ˆå™¨é€šè¿‡éƒ¨ç½²åŸºäº NEAR AI å’Œè‹±ä¼Ÿè¾¾æ”¯æŒçš„å¯ä¿¡æ‰§è¡Œç¯å¢ƒï¼ˆç®€ç§°â€œTEEâ€ï¼Œè¯¦æƒ…è¯·å‚è§ä¸‹æ–‡â€œäº†è§£æ›´å¤šå…³äº TEE çš„ä¿¡æ¯â€ï¼‰çš„ LLMï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€é¡¹å…¨æ–°çš„ ã€å¯åŠ å¯†éªŒè¯çš„éšç§å’Œé€æ˜åº¦åŠŸèƒ½ã€‚Brave è®¤ä¸ºï¼Œç”¨æˆ·å¿…é¡»èƒ½å¤ŸéªŒè¯ä»–ä»¬æ­£åœ¨ä¸é¢„æœŸçš„æ¨¡å‹è¿›è¡Œç§å¯†å¯¹è¯ã€‚è¿™é¡¹åŠŸèƒ½å·²åœ¨ Brave Nightly ç‰ˆæœ¬ ï¼ˆæˆ‘ä»¬çš„æµ‹è¯•å’Œå¼€å‘æ¸ é“ï¼‰ä¸­æ¨å‡ºï¼Œä¾›ç”¨æˆ·æ—©æœŸä½“éªŒ DeepSeek V3.1 æ¨¡å‹ï¼ˆæˆ‘ä»¬è®¡åˆ’æœªæ¥æ ¹æ®ç”¨æˆ·åé¦ˆå°†å…¶æ‰©å±•åˆ°æ›´å¤šæ¨¡å‹ï¼‰ã€‚ /// By integrating Trusted Execution Environments, Brave Leo moves towards offering unmatched verifiable privacy and transparency in AI assistants, in effect transitioning from the â€œtrust me broâ€ process to the privacy-by-design approach that Brave aspires to: â€œtrust but verify (. web: brendaneich.com/2014/01/trust-but-verify)â€. // é€šè¿‡é›†æˆå¯ä¿¡æ‰§è¡Œç¯å¢ƒï¼ŒBrave Leo æœç€åœ¨ AI åŠ©æ‰‹æ–¹é¢æä¾›æ— ä¸ä¼¦æ¯”çš„å¯éªŒè¯éšç§å’Œé€æ˜åº¦è¿ˆè¿›ï¼Œå®é™…ä¸Šæ˜¯ä»â€œç›¸ä¿¡æˆ‘ï¼Œå…„å¼Ÿâ€çš„è¿‡ç¨‹è¿‡æ¸¡åˆ° Brave æ‰€è¿½æ±‚çš„éšç§è®¾è®¡æ–¹æ³•ï¼šâ€œ ä¿¡ä»»ï¼Œä½†è¦éªŒè¯ â€ã€‚ /// Leo is the Brave browserâ€™s integrated, privacy-preserving AI assistant. It is powered by state-of-the-art LLMs while protecting user privacy through a privacy-preserving subscription model, no chats in the cloud, no context in the cloud, no IP address logging, and no training on usersâ€™ conversations. // Leo æ˜¯ Brave æµè§ˆå™¨é›†æˆçš„ã€ä¿æŠ¤éšç§çš„ AI åŠ©æ‰‹ã€‚å®ƒé‡‡ç”¨æœ€å…ˆè¿›çš„ LLM æŠ€æœ¯ï¼Œå¹¶é€šè¿‡ä¿æŠ¤éšç§çš„è®¢é˜…æ¨¡å¼æ¥ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œä¸è¿›è¡Œäº‘ç«¯èŠå¤©ï¼Œä¸å­˜å‚¨äº‘ç«¯ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸è®°å½• IP åœ°å€ï¼Œä¹Ÿä¸åˆ©ç”¨ç”¨æˆ·å¯¹è¯è¿›è¡Œè®­ç»ƒã€‚ /// Brave believes that users must be able to: // Brave è®¤ä¸ºç”¨æˆ·å¿…é¡»èƒ½å¤Ÿï¼š /// 1. Verifiable Privacyâ€”Users must be able to verify that Leoâ€™s privacy guarantees match public privacy promises. // å¯éªŒè¯çš„éšç§ â€”â€”ç”¨æˆ·å¿…é¡»èƒ½å¤ŸéªŒè¯ Leo çš„éšç§ä¿è¯ä¸å…¬å¼€çš„éšç§æ‰¿è¯ºç›¸ç¬¦ã€‚ /// 2. Verifiable Transparency in Model Selectionâ€”Users must be able to verify that Leoâ€™s responses are, in fact, coming from a machine learning model the user expects (or pays for, in the case of Leo Premium). // æ¨¡å‹é€‰æ‹©ä¸­çš„å¯éªŒè¯é€æ˜åº¦ â€”â€”ç”¨æˆ·å¿…é¡»èƒ½å¤ŸéªŒè¯ Leo çš„å“åº”æ˜¯å¦ç¡®å®æ¥è‡ªç”¨æˆ·æœŸæœ›çš„ï¼ˆæˆ–åœ¨ Leo Premium çš„æƒ…å†µä¸‹ä»˜è´¹çš„ï¼‰æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ /// The absence of these user-first features in other competing chatbot providers introduces a risk of privacy-washing. It has also been shownâ€”both in research (e.g., â€œAre You Getting What You Pay For? Auditing Model Substitution in LLM APIs (. arxiv: 2504.04715)â€) and in practice (e.g., backlash (. web: adversa.ai/blog/promisqroute-gpt-5-ai-router-novel-vulnerability-class) against ChatGPT)â€”that chatbot providers may have incentives to silently replace an expensive LLM with a cheaper-to-run, weaker LLM, and to return the results from the weaker model to the user in order to reduce GPU costs and increase profit margins. // å…¶ä»–ç«äº‰èŠå¤©æœºå™¨äººæä¾›å•†ç¼ºä¹è¿™äº›ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„åŠŸèƒ½ï¼Œè¿™ä¼šå¸¦æ¥éšç§æ´—ç™½çš„é£é™©ã€‚ç ”ç©¶ï¼ˆä¾‹å¦‚ï¼Œâ€œ ä½ ä»˜çš„é’±æ˜¯å¦ç‰©æœ‰æ‰€å€¼ï¼ŸLLM API ä¸­çš„æ¨¡å‹æ›¿æ¢å®¡è®¡ â€ï¼‰å’Œå®è·µï¼ˆä¾‹å¦‚ï¼Œé’ˆå¯¹ ChatGPT çš„å¼ºçƒˆåå¯¹ ï¼‰å‡è¡¨æ˜ï¼ŒèŠå¤©æœºå™¨äººæä¾›å•†å¯èƒ½å‡ºäºé™ä½ GPU æˆæœ¬å’Œæé«˜åˆ©æ¶¦ç‡çš„ç›®çš„ï¼Œæ‚„æ‚„åœ°ç”¨è¿è¡Œæˆæœ¬æ›´ä½ã€æ€§èƒ½æ›´å¼±çš„ LLM æ¨¡å‹æ›¿æ¢æˆæœ¬æ›´é«˜çš„ LLM æ¨¡å‹ï¼Œå¹¶å°†æ€§èƒ½è¾ƒå¼±æ¨¡å‹çš„è¿è¡Œç»“æœè¿”å›ç»™ç”¨æˆ·ã€‚ /// Brave begins this journey by removing the need to trust LLM/API providers, using Confidential LLM Computing on NEAR AI TEEs. Brave uses NEAR AI TEE-enabled Nvidia GPUs to ensure confidentiality and integrity by creating secure enclaves where data and code are processed with encryption. // Brave æµè§ˆå™¨é€šè¿‡ NEAR AI TEE ä¸Šçš„æœºå¯† LLM è®¡ç®— ï¼Œæ¶ˆé™¤äº†å¯¹ LLM/API æä¾›å•†çš„ä¿¡ä»»éœ€æ±‚ï¼Œä»è€Œå¼€å¯äº†è¿™æ®µæ—…ç¨‹ã€‚Brave ä½¿ç”¨æ”¯æŒ NEAR AI TEE çš„ Nvidia GPUï¼Œé€šè¿‡åˆ›å»ºå®‰å…¨åŒºåŸŸæ¥ç¡®ä¿æœºå¯†æ€§å’Œå®Œæ•´æ€§ï¼Œåœ¨è¿™äº›å®‰å…¨åŒºåŸŸå†…ï¼Œæ•°æ®å’Œä»£ç å‡ç»è¿‡åŠ å¯†å¤„ç†ã€‚ /// These TEEs produce a cryptographic attestation report that includes measurements (hashes) of the loaded model and execution code. Such attestation reports can be cryptographically verified to gain absolute assurance that: // è¿™äº›å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE) ä¼šç”Ÿæˆä¸€ä»½åŠ å¯†è®¤è¯æŠ¥å‘Šï¼Œå…¶ä¸­åŒ…å«å·²åŠ è½½æ¨¡å‹å’Œæ‰§è¡Œä»£ç çš„æµ‹é‡å€¼ï¼ˆå“ˆå¸Œå€¼ï¼‰ã€‚æ­¤ç±»è®¤è¯æŠ¥å‘Šå¯ä»¥è¿›è¡ŒåŠ å¯†éªŒè¯ï¼Œä»è€Œè·å¾—ä»¥ä¸‹ç»å¯¹ä¿è¯ï¼š /// 1. A secure environment is created through a genuine Nvidia GPU TEE, which generates cryptographic proofs of its integrity and configuration. // é€šè¿‡çœŸæ­£çš„ Nvidia GPU TEE åˆ›å»ºå®‰å…¨ç¯å¢ƒï¼Œè¯¥ TEE ä¼šç”Ÿæˆå…¶å®Œæ•´æ€§å’Œé…ç½®çš„åŠ å¯†è¯æ˜ã€‚ /// 2. Inference runs in this secure environment with full encryption that keeps user data private â€” no one can see any data passed by the user to the computation, or any results of the computation. // æ¨ç†åœ¨è¿™ä¸ªå®‰å…¨çš„ç¯å¢ƒä¸­è¿è¡Œï¼Œé‡‡ç”¨å®Œå…¨åŠ å¯†ï¼Œç¡®ä¿ç”¨æˆ·æ•°æ®çš„ç§å¯†æ€§â€”â€”ä»»ä½•äººéƒ½çœ‹ä¸åˆ°ç”¨æˆ·ä¼ é€’ç»™è®¡ç®—çš„ä»»ä½•æ•°æ®ï¼Œä¹Ÿçœ‹ä¸åˆ°è®¡ç®—çš„ä»»ä½•ç»“æœã€‚ /// 3. The model and open source code that users expected are running unmodified by cryptographically signing every computation.  // ç”¨æˆ·æ‰€æœŸæœ›çš„æ¨¡å‹å’Œå¼€æºä»£ç æœªç»ä¿®æ”¹åœ°è¿è¡Œï¼Œæ¯æ¬¡è®¡ç®—éƒ½ç»è¿‡åŠ å¯†ç­¾åã€‚ /// In Stage 1 of our development, Brave performs the cryptographic verification, and users can use â€œVerifiably Private with NEAR AI TEEâ€ in Leo as follows: // åœ¨æˆ‘ä»¬çš„å¼€å‘ç¬¬ä¸€é˜¶æ®µï¼ŒBrave æ‰§è¡ŒåŠ å¯†éªŒè¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨ Leo ä¸­ä½¿ç”¨â€œä½¿ç”¨ NEAR AI TEE è¿›è¡Œå¯éªŒè¯çš„éšç§ä¿æŠ¤â€ï¼Œ å…·ä½“æ“ä½œå¦‚ä¸‹ï¼š /// - User selects DeepSeek V3.1 with label of Verifiably Private with NEAR AI TEE available in Leo on Brave Nightly // ç”¨æˆ·é€‰æ‹©å¸¦æœ‰ â€œå¯éªŒè¯éšç§â€æ ‡ç­¾çš„ DeepSeek V3.1ï¼ŒNEAR AI TEE å¯åœ¨ Brave Nightly çš„ Leo ç‰ˆæœ¬ä¸­ä½¿ç”¨ã€‚ /// - Brave performs NEAR AI TEE Verification, validating a cryptographic chain from NEAR open-source code (. gh: nearai/cloud-api.git) to hardware-attestation execution, ensuring responses are generated in a genuine Nvidia TEE running a specific version of the NEAR open-source server // Brave æµè§ˆå™¨æ‰§è¡Œ NEAR AI TEE éªŒè¯ï¼ŒéªŒè¯ä» NEAR å¼€æºä»£ç åˆ°ç¡¬ä»¶è®¤è¯æ‰§è¡Œçš„åŠ å¯†é“¾ï¼Œç¡®ä¿å“åº”æ˜¯åœ¨è¿è¡Œç‰¹å®šç‰ˆæœ¬ NEAR å¼€æºä»£ç æœåŠ¡å™¨çš„çœŸæ­£çš„ Nvidia TEE ä¸Šç”Ÿæˆçš„ã€‚ /// - Brave transmits the outcome of verification to users by showing a verified green label (depicted in the screenshot below) // Brave æµè§ˆå™¨ä¼šå°†éªŒè¯ç»“æœä»¥ç»¿è‰²â€œå·²éªŒè¯â€æ ‡ç­¾çš„å½¢å¼ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰å‘ŠçŸ¥ç”¨æˆ·ã€‚ /// - User starts chatting without having to trust the API provider to see or log their data and responses // ç”¨æˆ·æ— éœ€ä¿¡ä»» API æä¾›å•†å³å¯å¼€å§‹èŠå¤©ï¼Œä¹Ÿæ— éœ€å…è®¸å…¶æŸ¥çœ‹æˆ–è®°å½•ç”¨æˆ·çš„æ•°æ®å’Œå›å¤ã€‚ /// Today, we are excited to release TEE-based Confidential DeepSeek V3.1 Computing in Brave Nightly (our testing and development channel) for early experimentation and feedback. // ä»Šå¤©ï¼Œæˆ‘ä»¬å¾ˆé«˜å…´åœ°åœ¨ Brave Nightlyï¼ˆæˆ‘ä»¬çš„æµ‹è¯•å’Œå¼€å‘æ¸ é“ï¼‰ä¸­å‘å¸ƒåŸºäº TEE çš„ Confidential DeepSeek V3.1 è®¡ç®—ï¼Œä»¥ä¾¿è¿›è¡Œæ—©æœŸå®éªŒå’Œåé¦ˆã€‚ /// Before rolling this out more broadly, weâ€™re focused on two things: // åœ¨æ›´å¹¿æ³›åœ°æ¨å¹¿è¿™é¡¹æªæ–½ä¹‹å‰ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨ä¸¤ä»¶äº‹ï¼š /// 1. No user-facing performance overheadâ€”TEEs introduce some computational overhead on the GPU. However, recent advances significantly reduce this overheadâ€”down to nearly zero in some casesâ€”as shown in Confidential Computing on NVIDIA Hopper GPUs: A Performance Benchmark Study. We want to ensure our users donâ€™t experience performance regressions. // æ— é¢å‘ç”¨æˆ·çš„æ€§èƒ½å¼€é”€ â€”â€”TEE ä¼šåœ¨ GPU ä¸Šå¼•å…¥ä¸€äº›è®¡ç®—å¼€é”€ã€‚ç„¶è€Œï¼Œæ­£å¦‚ ã€ŠNVIDIA Hopper GPU ä¸Šçš„æœºå¯†è®¡ç®—ï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•ç ”ç©¶ã€‹ æ‰€ç¤ºï¼Œæœ€è¿‘çš„æŠ€æœ¯è¿›æ­¥å·²æ˜¾è‘—é™ä½äº†è¿™ç§å¼€é”€ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ç”šè‡³æ¥è¿‘äºé›¶ã€‚æˆ‘ä»¬å¸Œæœ›ç¡®ä¿ç”¨æˆ·ä¸ä¼šé‡åˆ°æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ /// 2. End-to-end verificationâ€”Weâ€™re actively researching how to extend confidential computing in Leo so that users can verify their trust in the entire pipeline, along with Brave open-sourcing all stages. In particular, we are planning to move the verification closer to users so they can reconfirm the API verification on their own in the Brave browser.   // ç«¯åˆ°ç«¯éªŒè¯ â€”â€”æˆ‘ä»¬æ­£åœ¨ç§¯æç ”ç©¶å¦‚ä½•åœ¨ Leo ä¸­æ‰©å±•æœºå¯†è®¡ç®—ï¼Œä»¥ä¾¿ç”¨æˆ·èƒ½å¤ŸéªŒè¯ä»–ä»¬å¯¹æ•´ä¸ªæµç¨‹çš„ä¿¡ä»»ï¼ŒåŒæ—¶ Brave ä¹Ÿå°†å¼€æºæ‰€æœ‰é˜¶æ®µã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è®¡åˆ’å°†éªŒè¯è¿‡ç¨‹æ›´é è¿‘ç”¨æˆ·ï¼Œä»¥ä¾¿ä»–ä»¬å¯ä»¥åœ¨ Brave æµè§ˆå™¨ä¸­è‡ªè¡Œå†æ¬¡ç¡®è®¤ API éªŒè¯ã€‚ /// A Trusted Execution Environment (TEE) is a secure area of a processor that provides an isolated computing environment, separate from traditional rich runtime environments such as an Operating System (OS). A TEE enforces strong hardware-backed guarantees of confidentiality and integrity for the code and data it hosts. These guarantees are achieved through enforcements such as dedicated memory that is accessible only to the TEE. // å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE) æ˜¯å¤„ç†å™¨ä¸­ä¸€ä¸ªå®‰å…¨åŒºåŸŸï¼Œå®ƒæä¾›äº†ä¸€ä¸ªä¸ä¼ ç»Ÿä¸°å¯Œçš„è¿è¡Œæ—¶ç¯å¢ƒï¼ˆä¾‹å¦‚æ“ä½œç³»ç»Ÿ (OS)ï¼‰éš”ç¦»çš„è®¡ç®—ç¯å¢ƒã€‚TEE é€šè¿‡ç¡¬ä»¶å±‚é¢çš„å¼ºå¤§ä¿éšœï¼Œç¡®ä¿å…¶æ‰˜ç®¡çš„ä»£ç å’Œæ•°æ®çš„æœºå¯†æ€§å’Œå®Œæ•´æ€§ã€‚è¿™äº›ä¿éšœæ˜¯é€šè¿‡è¯¸å¦‚ä¸“ç”¨å†…å­˜ç­‰æªæ–½å®ç°çš„ï¼Œè¿™äº›å†…å­˜ä»…ä¾› TEE è®¿é—®ã€‚ /// Hardware isolation ensures that even a fully compromised OS cannot access or tamper with any code or data residing inside the TEE. In addition to this, TEEs expose unique hardware primitives such as secure boot and remote attestation to ensure only trusted code is loaded into the TEE and so that external parties are able to verify the integrity of TEE. // ç¡¬ä»¶éš”ç¦»ç¡®ä¿å³ä½¿æ“ä½œç³»ç»Ÿå®Œå…¨è¢«æ”»ç ´ï¼Œä¹Ÿæ— æ³•è®¿é—®æˆ–ç¯¡æ”¹ TEE å†…éƒ¨çš„ä»»ä½•ä»£ç æˆ–æ•°æ®ã€‚æ­¤å¤–ï¼ŒTEE è¿˜æä¾›å®‰å…¨å¯åŠ¨å’Œè¿œç¨‹è®¤è¯ç­‰ç‹¬ç‰¹çš„ç¡¬ä»¶åŸè¯­ï¼Œä»¥ç¡®ä¿åªæœ‰å¯ä¿¡ä»£ç æ‰èƒ½åŠ è½½åˆ° TEE ä¸­ï¼Œå¹¶ä½¿å¤–éƒ¨å„æ–¹èƒ½å¤ŸéªŒè¯ TEE çš„å®Œæ•´æ€§ã€‚ /// Chip manufacturers have enabled TEEs on CPUs (traditionally) and GPUs (recently). The combination of TEE-enabled CPUs (e.g., Intel TDX) and TEE-enabled GPUs (e.g., Nvidia Hopper) enables end-to-end confidentiality, and integrity-preserving computation of LLM inference with minimal performance penalty. // èŠ¯ç‰‡åˆ¶é€ å•†å·²åœ¨ CPUï¼ˆä¼ ç»Ÿä¸Šï¼‰å’Œ GPUï¼ˆæœ€è¿‘ï¼‰ä¸Šå¯ç”¨äº† TEEï¼ˆç»ˆç«¯å¢å¼ºå®ä½“ï¼‰æŠ€æœ¯ã€‚ç»“åˆä½¿ç”¨æ”¯æŒ TEE çš„ CPUï¼ˆä¾‹å¦‚ Intel TDXï¼‰å’Œæ”¯æŒ TEE çš„ GPUï¼ˆä¾‹å¦‚ Nvidia Hopperï¼‰ï¼Œå¯ä»¥å®ç°ç«¯åˆ°ç«¯çš„æœºå¯†æ€§ï¼Œå¹¶åœ¨æ€§èƒ½æŸå¤±æœ€å°çš„æƒ…å†µä¸‹ï¼Œä»¥ä¿æŒå®Œæ•´æ€§çš„æ–¹å¼è¿›è¡Œ LLM æ¨ç†è®¡ç®—ã€‚"
[tee-news.blog/privacyguides.org]: https://privacyguides.org/news/2025/11/20/brave-announces-verifiable-and-transparent-tee-support-in-leo/ "Brave Announces Verifiable and Transparent TEE Support in Leo // Brave å®£å¸ƒåœ¨ Leo ç‰ˆæœ¬ä¸­æä¾›å¯éªŒè¯ä¸”é€æ˜çš„ TEE æ”¯æŒ /// Today, Brave announced that their Leo AI assistant inside of the Brave browser will utilize NEAR AI Nvidia-backed Trusted Execution Environments (TEE). // ä»Šå¤©ï¼ŒBrave å®£å¸ƒå…¶ Brave æµè§ˆå™¨ä¸­çš„ Leo AI åŠ©æ‰‹å°†åˆ©ç”¨ NEAR AI å’Œ Nvidia æ”¯æŒçš„å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE)ã€‚ /// TEEs provide an isolated, secure environment for processing user requests. The isolation works at the hardware level, and allows users to remotely cryptographically attest that their requests are actually running in a secure environment and that they're using the desired LLM. // TEE ä¸ºå¤„ç†ç”¨æˆ·è¯·æ±‚æä¾›äº†ä¸€ä¸ªéš”ç¦»ã€å®‰å…¨çš„ç¯å¢ƒã€‚è¿™ç§éš”ç¦»åœ¨ç¡¬ä»¶å±‚é¢å®ç°ï¼Œå…è®¸ç”¨æˆ·è¿œç¨‹åŠ å¯†éªŒè¯å…¶è¯·æ±‚ç¡®å®åœ¨å®‰å…¨ç¯å¢ƒä¸­è¿è¡Œï¼Œå¹¶ä¸”æ­£åœ¨ä½¿ç”¨æ‰€éœ€çš„ LLMã€‚ /// The Confidential Computing (. web: confidentialcomputing.io) technology is designed to protect against malicious infrastructure providers, including the owners of the servers the models are running on, and provide strong integrity guarantees, preventing tampering of your results. // æœºå¯†è®¡ç®—æŠ€æœ¯æ—¨åœ¨ä¿æŠ¤ç”¨æˆ·å…å—æ¶æ„åŸºç¡€è®¾æ–½æä¾›å•†ï¼ˆåŒ…æ‹¬è¿è¡Œæ¨¡å‹çš„æœåŠ¡å™¨çš„æ‰€æœ‰è€…ï¼‰çš„ä¾µå®³ï¼Œå¹¶æä¾›å¼ºå¤§çš„å®Œæ•´æ€§ä¿è¯ï¼Œé˜²æ­¢ç¯¡æ”¹ç»“æœã€‚ /// Hardware isolation ensures that even a fully compromised OS cannot access or tamper with any code or data residing inside the TEE. In addition to this, TEEs expose unique hardware primitives such as secure boot and remote attestation to ensure only trusted code is loaded into the TEE and so that external parties are able to verify the integrity of TEE. // ç¡¬ä»¶éš”ç¦»ç¡®ä¿å³ä½¿æ“ä½œç³»ç»Ÿå®Œå…¨è¢«æ”»ç ´ï¼Œä¹Ÿæ— æ³•è®¿é—®æˆ–ç¯¡æ”¹ TEE å†…éƒ¨çš„ä»»ä½•ä»£ç æˆ–æ•°æ®ã€‚æ­¤å¤–ï¼ŒTEE è¿˜æä¾›å®‰å…¨å¯åŠ¨å’Œè¿œç¨‹è®¤è¯ç­‰ç‹¬ç‰¹çš„ç¡¬ä»¶åŸè¯­ï¼Œä»¥ç¡®ä¿åªæœ‰å¯ä¿¡ä»£ç æ‰èƒ½åŠ è½½åˆ° TEE ä¸­ï¼Œå¹¶ä½¿å¤–éƒ¨å„æ–¹èƒ½å¤ŸéªŒè¯ TEE çš„å®Œæ•´æ€§ã€‚ /// The new technology is available in Brave Nightly builds for early testing and feedback. // è¿™é¡¹æ–°æŠ€æœ¯å·²åœ¨ Brave Nightly ç‰ˆæœ¬ä¸­æä¾›ï¼Œä¾›ç”¨æˆ·æ—©æœŸæµ‹è¯•å’Œåé¦ˆã€‚ /// This announcement comes as the latest in a series of announcements from various AI providers who wish to improve the privacy and security of their AI offerings. First was Apple with their Private Cloud Compute (. web: security.apple.com/blog/private-cloud-compute), then Google with their Private AI Compute (. web: blog.google/technology/ai/google-private-ai-compute), then OpenAI announced (. web: openai.com/index/fighting-nyt-user-privacy-invasion) plans to implement â€œclient-side encryptionâ€ for ChatGPT. // æ­¤æ¬¡å…¬å‘Šæ˜¯ä¼—å¤šäººå·¥æ™ºèƒ½æä¾›å•†ä¸ºæå‡å…¶äººå·¥æ™ºèƒ½äº§å“çš„éšç§å’Œå®‰å…¨è€Œå‘å¸ƒçš„ä¸€ç³»åˆ—å…¬å‘Šä¸­çš„æœ€æ–°ä¸€é¡¹ã€‚æ­¤å‰ï¼Œè‹¹æœå…¬å¸ç‡å…ˆæ¨å‡ºäº†ç§æœ‰äº‘è®¡ç®—æœåŠ¡ï¼Œéšåè°·æ­Œæ¨å‡ºäº†ç§æœ‰äººå·¥æ™ºèƒ½è®¡ç®—æœåŠ¡ ï¼ŒOpenAI ä¹Ÿå®£å¸ƒè®¡åˆ’ä¸º ChatGPT å®ç°â€œå®¢æˆ·ç«¯åŠ å¯†â€ã€‚ /// This is another great development for private AI, I hope to see more and more AI providers adopting technologies like this to protect the privacy of their users. // è¿™æ˜¯ç§æœ‰äººå·¥æ™ºèƒ½é¢†åŸŸçš„åˆä¸€é‡å¤§è¿›å±•ï¼Œæˆ‘å¸Œæœ›çœ‹åˆ°è¶Šæ¥è¶Šå¤šçš„äººå·¥æ™ºèƒ½æä¾›å•†é‡‡ç”¨æ­¤ç±»æŠ€æœ¯æ¥ä¿æŠ¤ç”¨æˆ·çš„éšç§ã€‚"
[nearcloud-api.src/gh]: https://github.com/nearai/cloud-api.git "(PolyForm-Strict-1.0.0) (Languages: Rust 98.7%, Other 1.3%) NEAR AI Cloud API // NEAR AI äº‘ API /// A Rust-based cloud API for AI model inference, conversation management, and organization administration. Part of the NEAR AI platform alongside the Chat API. // ä¸€ä¸ªåŸºäº Rust çš„äº‘ç«¯ APIï¼Œç”¨äº AI æ¨¡å‹æ¨ç†ã€å¯¹è¯ç®¡ç†å’Œç»„ç»‡ç®¡ç†ã€‚å®ƒæ˜¯ NEAR AI å¹³å°çš„ä¸€éƒ¨åˆ†ï¼Œä¸èŠå¤© API åŒå±ä¸€ä¸ªå¹³å°ã€‚"
[private-inference.docs/near.ai]: https://docs.near.ai/cloud/private-inference/ "Private Inference // ç§æœ‰æ¨ç† /// When you use traditional AI services, your data passes through systems controlled by cloud providers and AI companies. Your prompts, the AI's responses, and even the processing of your requests are all visible to these third parties. This creates serious security concerns for sensitive applications. // ä½¿ç”¨ä¼ ç»Ÿäººå·¥æ™ºèƒ½æœåŠ¡æ—¶ï¼Œæ‚¨çš„æ•°æ®ä¼šç»è¿‡ç”±äº‘æœåŠ¡æä¾›å•†å’Œäººå·¥æ™ºèƒ½å…¬å¸æ§åˆ¶çš„ç³»ç»Ÿã€‚æ‚¨çš„æç¤ºã€äººå·¥æ™ºèƒ½çš„å“åº”ï¼Œç”šè‡³æ‚¨è¯·æ±‚çš„å¤„ç†è¿‡ç¨‹ï¼Œå¯¹è¿™äº›ç¬¬ä¸‰æ–¹éƒ½æ˜¯å¯è§çš„ã€‚è¿™ä¼šç»™æ•æ„Ÿåº”ç”¨å¸¦æ¥ä¸¥é‡çš„å®‰å…¨éšæ‚£ã€‚ /// Private inference solves this problem. It ensures that AI computations happen in a completely isolated environment where no oneâ€”not the cloud provider, not the model provider, not even NEAR AI can access your data. At the same time, you can independently verify that your requests were actually processed in this secure environment through cryptographic attestation. // ç§æœ‰æ¨ç†è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚ å®ƒç¡®ä¿äººå·¥æ™ºèƒ½è®¡ç®—åœ¨ä¸€ä¸ªå®Œå…¨éš”ç¦»çš„ç¯å¢ƒä¸­è¿›è¡Œï¼Œä»»ä½•äººéƒ½æ— æ³•è®¿é—®æ‚¨çš„æ•°æ®â€”â€”æ— è®ºæ˜¯äº‘æœåŠ¡æä¾›å•†ã€æ¨¡å‹æä¾›å•†ï¼Œè¿˜æ˜¯ NEAR AIã€‚åŒæ—¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡åŠ å¯†è®¤è¯ç‹¬ç«‹éªŒè¯æ‚¨çš„è¯·æ±‚æ˜¯å¦ç¡®å®åœ¨è¿™ä¸ªå®‰å…¨ç¯å¢ƒä¸­å¤„ç†è¿‡ã€‚ /// This guide explains how NEAR AI Cloud implements private inference using Trusted Execution Environments (TEEs), the architecture that protects your data, and the security guarantees you can rely on. // æœ¬æŒ‡å—è§£é‡Šäº† NEAR AI Cloud å¦‚ä½•ä½¿ç”¨å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE) å®ç°ç§æœ‰æ¨ç†ï¼Œè¯¥æ¶æ„å¯ä¿æŠ¤æ‚¨çš„æ•°æ®ï¼Œå¹¶æä¾›æ‚¨å¯ä»¥ä¿¡èµ–çš„å®‰å…¨ä¿è¯ã€‚ /// ## What is Private Inference? // ä»€ä¹ˆæ˜¯ç§æœ‰æ¨ç†ï¼Ÿ /// Private inference is a method of running AI models where both your input data and the model's outputs remain completely hidden from everyone except the user and client even while the computation happens on remote servers you don't control. // ç§æœ‰æ¨ç†æ˜¯ä¸€ç§è¿è¡Œ AI æ¨¡å‹çš„æ–¹æ³•ï¼Œå³ä½¿è®¡ç®—å‘ç”Ÿåœ¨æ‚¨æ— æ³•æ§åˆ¶çš„è¿œç¨‹æœåŠ¡å™¨ä¸Šï¼Œæ‚¨çš„è¾“å…¥æ•°æ®å’Œæ¨¡å‹çš„è¾“å‡ºä¹Ÿä¼šå¯¹é™¤ç”¨æˆ·å’Œå®¢æˆ·ç«¯ä»¥å¤–çš„æ‰€æœ‰äººå®Œå…¨éšè—ã€‚ /// Traditional cloud AI services require you to trust that providers won't access your data. Private inference eliminates this need for trust by using hardware-based security that makes it technically impossible for anyone to see your data, even with physical access to the servers. // ä¼ ç»Ÿçš„äº‘ç«¯äººå·¥æ™ºèƒ½æœåŠ¡éœ€è¦æ‚¨ä¿¡ä»»æœåŠ¡æä¾›å•†ä¸ä¼šè®¿é—®æ‚¨çš„æ•°æ®ã€‚è€Œç§æœ‰æ¨ç†é€šè¿‡ä½¿ç”¨åŸºäºç¡¬ä»¶çš„å®‰å…¨æªæ–½ï¼Œæ¶ˆé™¤äº†è¿™ç§ä¿¡ä»»éœ€æ±‚ï¼Œå³ä½¿æœ‰äººèƒ½å¤Ÿç‰©ç†è®¿é—®æœåŠ¡å™¨ï¼Œä»æŠ€æœ¯ä¸Šè®²ï¼Œä¹Ÿæ ¹æœ¬ä¸å¯èƒ½æŸ¥çœ‹æ‚¨çš„æ•°æ®ã€‚ /// NEAR AI Cloud's private inference provides three core guarantees: // NEAR AI Cloud çš„ç§æœ‰æ¨ç†æä¾›ä¸‰å¤§æ ¸å¿ƒä¿éšœï¼š /// - Complete Privacy // å®Œå…¨éšç§ ///: Your prompts, model weights, and outputs are encrypted and isolated in hardware-secured environments. Infrastructure providers, model providers, and NEAR cannot access your data at any point in the process. // æ‚¨çš„æç¤ºä¿¡æ¯ã€æ¨¡å‹æƒé‡å’Œè¾“å‡ºç»“æœå‡ç»è¿‡åŠ å¯†ï¼Œå¹¶éš”ç¦»åœ¨ç¡¬ä»¶å®‰å…¨çš„ç¯å¢ƒä¸­ã€‚åŸºç¡€è®¾æ–½æä¾›å•†ã€æ¨¡å‹æä¾›å•†å’Œ NEAR åœ¨ä»»ä½•é˜¶æ®µéƒ½æ— æ³•è®¿é—®æ‚¨çš„æ•°æ®ã€‚ /// - Cryptographic Verification // å¯†ç éªŒè¯ ///: Every computation generates cryptographic proof that it occurred inside a genuine, secure TEE. You can independently verify that your AI requests were processed in a protected environment without trusting any third party. // æ¯æ¬¡è®¡ç®—éƒ½ä¼šç”ŸæˆåŠ å¯†è¯æ˜ï¼Œè¯æ˜å…¶å‘ç”Ÿåœ¨çœŸå®ã€å®‰å…¨çš„ç»ˆç«¯ç¯å¢ƒ (TEE) ä¸­ã€‚æ‚¨å¯ä»¥ç‹¬ç«‹éªŒè¯æ‚¨çš„ AI è¯·æ±‚æ˜¯å¦åœ¨å—ä¿æŠ¤çš„ç¯å¢ƒä¸­å¤„ç†ï¼Œè€Œæ— éœ€ä¿¡ä»»ä»»ä½•ç¬¬ä¸‰æ–¹ã€‚ /// - Production Performance // ç”Ÿäº§æ€§èƒ½ ///: Hardware-accelerated TEEs with NVIDIA Confidential Computing deliver high-throughput inference with minimal latency overhead, making private inference practical for real-world applications. // é‡‡ç”¨ NVIDIA Confidential Computing çš„ç¡¬ä»¶åŠ é€Ÿ TEE å¯å®ç°é«˜ååé‡æ¨ç†ï¼ŒåŒæ—¶å°†å»¶è¿Ÿå¼€é”€é™è‡³æœ€ä½ï¼Œä»è€Œä½¿ç§å¯†æ¨ç†åœ¨å®é™…åº”ç”¨ä¸­åˆ‡å®å¯è¡Œã€‚ /// Trusted Execution Environment (TEE) // å¯ä¿¡æ‰§è¡Œç¯å¢ƒï¼ˆTEEï¼‰ /// NEAR AI Cloud combines Intel TDX and NVIDIA TEE technologies to create isolated, secure environments for AI computation: // NEAR AI Cloud ç»“åˆäº† Intel TDX å’Œ NVIDIA TEE æŠ€æœ¯ï¼Œä¸º AI è®¡ç®—åˆ›å»ºéš”ç¦»ã€å®‰å…¨çš„ç¯å¢ƒï¼š /// - Intel TDX(Trust Domain Extensions) (. web: intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html): Creates confidential virtual machines (CVMs) that isolate your AI workloads from the host system, preventing unauthorized access to data in memory. // Intel TDXï¼ˆä¿¡ä»»åŸŸæ‰©å±•ï¼‰ ï¼šåˆ›å»ºæœºå¯†è™šæ‹Ÿæœº (CVM)ï¼Œå°†æ‚¨çš„ AI å·¥ä½œè´Ÿè½½ä¸ä¸»æœºç³»ç»Ÿéš”ç¦»ï¼Œé˜²æ­¢æœªç»æˆæƒè®¿é—®å†…å­˜ä¸­çš„æ•°æ®ã€‚ /// - NVIDIA TEE (. web: nvidia.com/en-us/data-center/solutions/confidential-computing): Provides GPU-level isolation for model inference, ensuring model weights and computations remain completely private during processing. // NVIDIA TEE ï¼šä¸ºæ¨¡å‹æ¨ç†æä¾› GPU çº§éš”ç¦»ï¼Œç¡®ä¿æ¨¡å‹æƒé‡å’Œè®¡ç®—åœ¨å¤„ç†è¿‡ç¨‹ä¸­å®Œå…¨ä¿å¯†ã€‚ /// - Cryptographic Attestation (. web: docs.near.ai/cloud/verification): Each TEE environment generates cryptographic proofs of its integrity and configuration, enabling independent verification of the secure execution environment. // åŠ å¯†è¯æ˜ ï¼šæ¯ä¸ª TEE ç¯å¢ƒéƒ½ä¼šç”Ÿæˆå…¶å®Œæ•´æ€§å’Œé…ç½®çš„åŠ å¯†è¯æ˜ï¼Œä»è€Œå¯ä»¥ç‹¬ç«‹éªŒè¯å®‰å…¨æ‰§è¡Œç¯å¢ƒã€‚ /// Client-Side Encryption // å®¢æˆ·ç«¯åŠ å¯† /// If you're using a standard OpenAI SDK or curl, your prompts are automatically protected by TLS encryptionâ€”no additional setup required. // å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯æ ‡å‡†çš„ OpenAI SDK æˆ– curlï¼Œåˆ™æ‚¨çš„æç¤ºä¿¡æ¯ä¼šè‡ªåŠ¨å—åˆ° TLS åŠ å¯†ä¿æŠ¤â€”â€”æ— éœ€é¢å¤–è®¾ç½®ã€‚ /// [Your Machine] >-(ğŸ”’ Encrypted)--> [Internet] >-(ğŸ”’ Encrypted)--> [TEE: TLS Termination â†’ LLM] /// Key insight: TLS termination happens inside the TEE (green box), not at an external load balancer. Your prompts remain encrypted until they reach the secure enclave. // å…³é”®ä¿¡æ¯ï¼š TLS ç»ˆæ­¢å‘ç”Ÿåœ¨ TEEï¼ˆç»¿è‰²æ¡†ï¼‰å†…éƒ¨ï¼Œè€Œä¸æ˜¯å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨ä¸Šã€‚æ‚¨çš„è¯·æ±‚åœ¨åˆ°è¾¾å®‰å…¨åŒºåŸŸä¹‹å‰å§‹ç»ˆä¿æŒåŠ å¯†çŠ¶æ€ã€‚ /// Here's why this works: // åŸå› å¦‚ä¸‹ï¼š /// 1. Standard HTTPS = TLS encryption: When you make API calls using the OpenAI SDK or curl, you're connecting via HTTPS. This means TLS encryption is applied automatically by your client before any data leaves your machine. // æ ‡å‡† HTTPS = TLS åŠ å¯† ï¼šå½“æ‚¨ä½¿ç”¨ OpenAI SDK æˆ– curl è¿›è¡Œ API è°ƒç”¨æ—¶ï¼Œæ‚¨å°†é€šè¿‡ HTTPS è¿æ¥ã€‚è¿™æ„å‘³ç€åœ¨ä»»ä½•æ•°æ®ç¦»å¼€æ‚¨çš„è®¡ç®—æœºä¹‹å‰ï¼Œæ‚¨çš„å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨åº”ç”¨ TLS åŠ å¯†ã€‚ /// 2. TLS terminates inside the TEE: Unlike traditional cloud services where TLS terminates at an external load balancer, NEAR AI Cloud terminates TLS connections inside the Trusted Execution Environment. Your encrypted data travels from your laptop directly into the secure enclave before being decrypted. // TLS è¿æ¥åœ¨å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE) å†…ç»ˆæ­¢ ï¼šä¸ä¼ ç»Ÿäº‘æœåŠ¡åœ¨å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨å¤„ç»ˆæ­¢ TLS è¿æ¥ä¸åŒï¼ŒNEAR AI Cloud åœ¨å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE) å†…ç»ˆæ­¢ TLS è¿æ¥ã€‚æ‚¨çš„åŠ å¯†æ•°æ®åœ¨è§£å¯†ä¹‹å‰ä¼šç›´æ¥ä»æ‚¨çš„ç¬”è®°æœ¬ç”µè„‘ä¼ è¾“åˆ°å®‰å…¨åŒºåŸŸã€‚ /// 3. No plaintext exposure: Because TLS termination happens within the TEE, your prompts are never exposed in plaintext outside the hardware-secured environmentâ€”not to network infrastructure, not to cloud providers, not to anyone. // ä¸ä¼šæ³„éœ²æ˜æ–‡ ï¼šç”±äº TLS ç»ˆæ­¢å‘ç”Ÿåœ¨ TEE å†…éƒ¨ï¼Œå› æ­¤æ‚¨çš„æç¤ºä¿¡æ¯æ°¸è¿œä¸ä¼šä»¥æ˜æ–‡å½¢å¼æ³„éœ²åˆ°ç¡¬ä»¶å®‰å…¨ç¯å¢ƒä¹‹å¤–â€”â€”ä¸ä¼šæ³„éœ²ç»™ç½‘ç»œåŸºç¡€è®¾æ–½ï¼Œä¸ä¼šæ³„éœ²ç»™äº‘æä¾›å•†ï¼Œä¹Ÿä¸ä¼šæ³„éœ²ç»™ä»»ä½•äººã€‚ /// This means you get the same seamless developer experience as any OpenAI-compatible API, while your data remains encrypted from your machine all the way into the secure TEE. // è¿™æ„å‘³ç€æ‚¨å¯ä»¥è·å¾—ä¸ä»»ä½• OpenAI å…¼å®¹ API ç›¸åŒçš„æ— ç¼å¼€å‘è€…ä½“éªŒï¼ŒåŒæ—¶æ‚¨çš„æ•°æ®ä»æ‚¨çš„è®¡ç®—æœºåˆ°å®‰å…¨çš„ TEE å§‹ç»ˆä¿æŒåŠ å¯†çŠ¶æ€ã€‚"
[cfdcomp.site/io]: https://confidentialcomputing.io/ "Confidential Computing Consortium // æœºå¯†è®¡ç®—è”ç›Ÿ"
[llm-api-audit:2504.04715.paper/arxiv]: https://arxiv.org/abs/2504.04715 "[Submitted on 7 Apr 2025 (v1), last revised 29 Sep 2025 (this version, v2)] { Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG) } (doi: 10.48550/arXiv.2504.04715) Are You Getting What You Pay For? Auditing Model Substitution in LLM APIs // ä½ çœŸçš„ç‰©æœ‰æ‰€å€¼å—ï¼ŸLLM API ä¸­çš„æ¨¡å‹æ›¿æ¢å®¡è®¡ã€‚ /// Commercial Large Language Model (LLM) APIs create a fundamental trust problem: users pay for specific models but have no guarantee that providers deliver them faithfully. Providers may covertly substitute cheaper alternatives (e.g., quantized versions, smaller models) to reduce costs while maintaining advertised pricing. We formalize this model substitution problem and systematically evaluate detection methods under realistic adversarial conditions. Our empirical analysis reveals that software-only methods are fundamentally unreliable: statistical tests on text outputs are query-intensive and fail against subtle substitutions, while methods using log probabilities are defeated by inherent inference nondeterminism in production environments. We argue that this verification gap can be more effectively closed with hardware-level security. We propose and evaluate the use of Trusted Execution Environments (TEEs) as one practical and robust solution. Our findings demonstrate that TEEs can provide provable cryptographic guarantees of model integrity with only a modest performance overhead, offering a clear and actionable path to ensure users get what they pay for. // å•†ä¸šå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) API é€ æˆäº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„ä¿¡ä»»é—®é¢˜ï¼šç”¨æˆ·ä¸ºç‰¹å®šæ¨¡å‹ä»˜è´¹ï¼Œå´æ— æ³•ä¿è¯æä¾›å•†ä¼šå¿ å®åœ°äº¤ä»˜è¿™äº›æ¨¡å‹ã€‚æä¾›å•†å¯èƒ½ä¼šæš—ä¸­ç”¨æ›´ä¾¿å®œçš„æ›¿ä»£æ–¹æ¡ˆï¼ˆä¾‹å¦‚ï¼Œé‡åŒ–ç‰ˆæœ¬ã€æ›´å°çš„æ¨¡å‹ï¼‰æ¥é™ä½æˆæœ¬ï¼ŒåŒæ—¶ç»´æŒå…¶å®£ä¼ çš„ä»·æ ¼ã€‚æˆ‘ä»¬å°†è¿™ç§æ¨¡å‹æ›¿æ¢é—®é¢˜å½¢å¼åŒ–ï¼Œå¹¶åœ¨çœŸå®çš„å¯¹æŠ—æ¡ä»¶ä¸‹ç³»ç»Ÿåœ°è¯„ä¼°äº†å„ç§æ£€æµ‹æ–¹æ³•ã€‚æˆ‘ä»¬çš„å®è¯åˆ†æè¡¨æ˜ï¼Œçº¯è½¯ä»¶æ–¹æ³•ä»æ ¹æœ¬ä¸Šæ¥è¯´æ˜¯ä¸å¯é çš„ï¼šå¯¹æ–‡æœ¬è¾“å‡ºè¿›è¡Œç»Ÿè®¡æµ‹è¯•éœ€è¦å¤§é‡çš„æŸ¥è¯¢ï¼Œå¹¶ä¸”æ— æ³•æ£€æµ‹åˆ°ç»†å¾®çš„æ›¿æ¢ï¼›è€Œä½¿ç”¨å¯¹æ•°æ¦‚ç‡çš„æ–¹æ³•åˆ™ä¼šå› ç”Ÿäº§ç¯å¢ƒä¸­å›ºæœ‰çš„æ¨ç†ä¸ç¡®å®šæ€§è€Œå¤±æ•ˆã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œé€šè¿‡ç¡¬ä»¶çº§å®‰å…¨å¯ä»¥æ›´æœ‰æ•ˆåœ°å¼¥è¡¥è¿™ä¸€éªŒè¯å·®è·ã€‚æˆ‘ä»¬æå‡ºå¹¶è¯„ä¼°äº†å¯ä¿¡æ‰§è¡Œç¯å¢ƒ (TEE) çš„ä½¿ç”¨ï¼Œå°†å…¶ä½œä¸ºä¸€ç§å®ç”¨ä¸”ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒTEE èƒ½å¤Ÿä»¥é€‚åº¦çš„æ€§èƒ½å¼€é”€æä¾›å¯è¯æ˜çš„æ¨¡å‹å®Œæ•´æ€§åŠ å¯†ä¿è¯ï¼Œä»è€Œä¸ºç¡®ä¿ç”¨æˆ·è·å¾—å…¶ä»˜è´¹å†…å®¹æä¾›äº†ä¸€æ¡æ¸…æ™°å¯è¡Œçš„é€”å¾„ã€‚"
[llm-api-audit:2504.04715.src/gh]: https://github.com/sunblaze-ucb/llm-api-audit.git "(MIT) (Languages: Python 94.8%, Jupyter Notebook 4.3%, Other 0.9%) LLM API Audit // LLM API å®¡è®¡ /// This project provides different methods for auditing Large Language Models (LLMs) to verify service integrity. // è¯¥é¡¹ç›®æä¾›äº†ä¸åŒçš„æ–¹æ³•æ¥å®¡æ ¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»¥éªŒè¯æœåŠ¡çš„å®Œæ•´æ€§ã€‚"

