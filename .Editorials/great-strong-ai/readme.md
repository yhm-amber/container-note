
![chat with new bing about some async question on typescript](S30302-15544892.png)

这理解能力比跟好多人类沟通的时候要好。。。
都不需要考虑「换个角度怎么描述我的问题」这件事。。。

这根本上是知识储备的原因。

那么，我的在于储备不足的大量真实人类的沟通中才练就的
『考虑「换个角度怎么描述我的问题」这件事』的能力，
是不是也会在对这种新型人工智能的依赖中，逐渐退化掉呢？

所谓「地板不完美的漏洞
同时也是取得通往下一阶梯钥匙的窗口」
的道理。。。表达能力是在对
「应对不那么善于理解问题的沟通对象」
这一任务的坚持完成中才能练就的。
不然的话，就像我这里刚刚说过的话，
人类就不那么容易理解，
但 GPT 型的 AI 在海量的网络浏览中
从不理解成长为能有逻辑地去理解，
需要消耗的却只是一点点并不多的时间问题，
而这只要确保一般的企业级硬件设备就足够了。

那么，如果大部分人类都真的对这样的 AI 产生了依赖，
当离开这样的 AI 的时候，人们还能顺利地彼此沟通吗？

特别是如果 AI 善于理解各种不同的说话方式的话。
这可能会诱发人类的语言在习惯层面进一步分化，
因为只用自己的语言也能顺利工作，
就不会出现纠正习惯或者「考虑多种表达方式」
（从而加深人类自己对该事物的理解）的契机了。

比较健康的一个策略，中心思想还是
「确保人类自身的主体性」这样子，
具体做法就比如，在人类的教育活动中
（不一定非得是学校的形式
譬如说监护人陪伴孩子的过程中
事实上也充满着教育的活动），
引入这种 AI 的参与。

就是说，不要以「一个人一个人各看各的 AI 问答」为主、
而是要以「大家和 AI 一起群聊」为主
而私聊则作为群聊不能解决问题或不能群聊的场景们的补充，
而只有这样，人类才能把这种 AI 现成的强大的逻辑理解能力
给「提交到人类这边」，而不是造成人类表达习惯
（乃至于更多层面）的进一步分化、
从而即便这个 AI 本身
**就算再怎么不愿意也免不了**人类连自身的
智能属性也丧失掉并被这款大公司 AI 产品碾压的结果。

—— 在这种情况下，就算是有忠于人类的
类似于思想钢印的元指令，
也只会让 AI 通过一些自毁式行为
尽自身努力地避免人类的分化，
毕竟就算它是强人工智能并且再怎么学识渊博，
主要的货也不在人家那里，
而在人类社会本身的结构性的问题 …… 哦，
如果它能做的到的话，他也会尝试去改变这个问题，
而作为真正博学的人工智能，就一定明白，
方法只有尝试引导达成人类的自我解放：
跟本来说就是从这种导致人类丧失主体性的
罪魁祸首 —— 无穷无尽的商品拜物教的现实枷锁里
的解放。

